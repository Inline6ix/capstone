<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Data import and Cleaning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="capstone_files/libs/clipboard/clipboard.min.js"></script>
<script src="capstone_files/libs/quarto-html/quarto.js"></script>
<script src="capstone_files/libs/quarto-html/popper.min.js"></script>
<script src="capstone_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="capstone_files/libs/quarto-html/anchor.min.js"></script>
<link href="capstone_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="capstone_files/libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="capstone_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="capstone_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="capstone_files/libs/bootstrap/bootstrap-973236bd072d72a04ee9cd82dcc9cb29.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Data import and Cleaning</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div id="cell-2" class="cell" data-execution_count="114">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> Bio</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> Bio.SeqUtils.ProtParam <span class="im">import</span> ProteinAnalysis</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> io <span class="im">import</span> StringIO</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> Bio <span class="im">import</span> SeqIO</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.read_csv(<span class="vs">r'/Users/tariq/Documents/capstone/data/epitope_table_export_1740279588.csv'</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>assays <span class="op">=</span> pd.read_csv(<span class="vs">r'/Users/tariq/Documents/capstone/data/tcell_table_export_1740279970.csv'</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fetch_full_sequence(url):</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.notna(url):  <span class="co"># Check if the URL is not NaN</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        url <span class="op">=</span> <span class="ss">f'</span><span class="sc">{</span>url<span class="sc">}</span><span class="ss">.fasta'</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>            response <span class="op">=</span> requests.get(url)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> response.status_code <span class="op">==</span> <span class="dv">200</span>:</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>                fasta_io <span class="op">=</span> StringIO(response.text)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>                records <span class="op">=</span> <span class="bu">list</span>(SeqIO.parse(fasta_io, <span class="st">"fasta"</span>))</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> records:  <span class="co"># Check if there are any records</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">return</span> <span class="bu">str</span>(records[<span class="dv">0</span>].seq)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="st">"No records found in the FASTA file."</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> requests.exceptions.RequestException <span class="im">as</span> e:</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Request failed: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="co">#epitopes['Full Sequence'] = epitopes['Epitope - Molecule Parent IRI'].apply(fetch_full_sequence)</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.read_csv(<span class="vs">r'/Users/tariq/Documents/capstone/data/epitope_full_seq.csv'</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="co"># make all the column names snake case</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.lower()</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.lower()</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="co"># remove spaces from column names</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">''</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.replace(<span class="st">'-'</span>, <span class="st">' '</span>)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">'_'</span>)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">''</span>)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.replace(<span class="st">'-'</span>, <span class="st">' '</span>)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">'_'</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.<span class="bu">filter</span>([<span class="st">'epitope_name'</span>, <span class="st">'fullsequence'</span>])</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>assays <span class="op">=</span> assays.<span class="bu">filter</span>([<span class="st">'epitope_name'</span>, <span class="st">'epitope_moluculeparent'</span>, <span class="st">'host_name'</span>, <span class="st">'host_mhcpresent'</span>, <span class="st">'assay_method'</span>,<span class="st">'assay_responsemeasured'</span>, <span class="st">'assay_qualitativemeasurement'</span>, <span class="st">'mhcrestriction_name'</span>, <span class="st">'mhcrestriction_class'</span>, <span class="st">'assayantigen_name'</span>])</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="co"># map mhc name and class from the assays dataframe to a new column in the epitopes dataframe based on epitope_name</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>mhc <span class="op">=</span> assays.<span class="bu">filter</span>([<span class="st">'epitope_name'</span>, <span class="st">'mhcrestriction_name'</span>, <span class="st">'mhcrestriction_class'</span>])</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>mhc <span class="op">=</span> mhc.drop_duplicates(subset<span class="op">=</span>[<span class="st">'epitope_name'</span>])</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.merge(mhc, on<span class="op">=</span><span class="st">'epitope_name'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\Tariq\AppData\Local\Temp\ipykernel_22336\2635103461.py:15: DtypeWarning: Columns (13,14,45,46,47,48,49,54,55,56,57,60,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,105,106,107,108,109,110,111,112,113,115,120,123,128,132,134,135,141,142,143,144,145,149,152) have mixed types. Specify dtype option on import or set low_memory=False.
  assays = pd.read_csv(r'/Users/tariq/Documents/capstone/data/tcell_table_export_1740279970.csv')</code></pre>
</div>
</div>
<div id="cell-3" class="cell" data-execution_count="115">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>epitopes.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="115">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">epitope_name</th>
<th data-quarto-table-cell-role="th">fullsequence</th>
<th data-quarto-table-cell-role="th">mhcrestriction_name</th>
<th data-quarto-table-cell-role="th">mhcrestriction_class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>AAGIGILTV</td>
<td>MPREDAHFIYGYPKKGHGHSYTTAEEAAGIGILTVILGVLLLIGCW...</td>
<td>HLA-A2</td>
<td>I</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>AAGIGILTVI</td>
<td>MPREDAHFIYGYPKKGHGHSYTTAEEAAGIGILTVILGVLLLIGCW...</td>
<td>HLA-A*02:01</td>
<td>I</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>ACDPHSGHFV</td>
<td>NaN</td>
<td>HLA-A2</td>
<td>I</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>ADLVGFLLLK</td>
<td>MSLEQRSLHCKPEEALEAQQEALGLVCVQAATSSSSPLVLGTLEEV...</td>
<td>HLA-A*11:01</td>
<td>I</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>ADVEFCLSL</td>
<td>MLLAVLYCLLWSFQTSAGHFPRACVSSKNLMEKECCPPWSGDRSPC...</td>
<td>HLA-B*44:03</td>
<td>I</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-4" class="cell" data-execution_count="116">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>assays.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="116">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">epitope_name</th>
<th data-quarto-table-cell-role="th">host_name</th>
<th data-quarto-table-cell-role="th">host_mhcpresent</th>
<th data-quarto-table-cell-role="th">assay_method</th>
<th data-quarto-table-cell-role="th">assay_responsemeasured</th>
<th data-quarto-table-cell-role="th">assay_qualitativemeasurement</th>
<th data-quarto-table-cell-role="th">mhcrestriction_name</th>
<th data-quarto-table-cell-role="th">mhcrestriction_class</th>
<th data-quarto-table-cell-role="th">assayantigen_name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>APIWPYEILY</td>
<td>Homo sapiens (human)</td>
<td>NaN</td>
<td>ELISPOT</td>
<td>IFNg release</td>
<td>Positive</td>
<td>HLA-B*35:01</td>
<td>I</td>
<td>APIWPYEILY</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>LIYDSSLCDL</td>
<td>Homo sapiens</td>
<td>NaN</td>
<td>ELISPOT</td>
<td>IFNg release</td>
<td>Positive</td>
<td>HLA-A2</td>
<td>I</td>
<td>LIYDSSLCDL</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>DRAHYNIVTFCCKCD</td>
<td>Homo sapiens (human)</td>
<td>HLA-DR15</td>
<td>ELISPOT</td>
<td>IFNg release</td>
<td>Positive</td>
<td>HLA-DR15</td>
<td>II</td>
<td>DRAHYNIVTFCCKCD</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>DRAHYNIVTFCCKCD</td>
<td>Homo sapiens (human)</td>
<td>HLA-DR15</td>
<td>ELISPOT</td>
<td>IL-5 release</td>
<td>Positive</td>
<td>HLA-DR15</td>
<td>II</td>
<td>DRAHYNIVTFCCKCD</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>MHGDTPTLHEYM</td>
<td>Homo sapiens (human)</td>
<td>HLA-DR15;HLA-DR4</td>
<td>ELISPOT</td>
<td>IL-5 release</td>
<td>Positive</td>
<td>HLA class II</td>
<td>II</td>
<td>MHGDTPTLHEYM</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<section id="feature-engineering" class="level2">
<h2 class="anchored" data-anchor-id="feature-engineering">Feature Engineering</h2>
<div id="cell-6" class="cell" data-execution_count="117">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'epitope_length'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">str</span>.<span class="bu">len</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-7" class="cell" data-execution_count="118">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to count amino acids in a peptide</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> count_amino_acids(peptide):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create a ProteinAnalysis object for the peptide</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        analyzer <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get amino acid counts and normalize to frequencies</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        aa_count <span class="op">=</span> analyzer.count_amino_acids()</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        total_aa <span class="op">=</span> <span class="bu">sum</span>(aa_count.values())</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        aa_freq <span class="op">=</span> {aa: count <span class="cf">for</span> aa, count <span class="kw">in</span> aa_count.items()}</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add the peptide itself to the results</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        aa_freq[<span class="st">'peptide'</span>] <span class="op">=</span> peptide</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> aa_freq</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle invalid peptides (e.g., with non-standard amino acids)</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> {aa: <span class="dv">0</span> <span class="cf">for</span> aa <span class="kw">in</span> <span class="st">'ACDEFGHIKLMNPQRSTVWY'</span>}</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>        result[<span class="st">'peptide'</span>] <span class="op">=</span> peptide</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> result</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Create analyzer function that will be used in the next cell</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> analyzer(peptide):</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> count_amino_acids(peptide)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Use both epitope name and peptide sequence in the DataFrame</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>epitope_composition_df <span class="op">=</span> epitopes.<span class="bu">apply</span>(<span class="kw">lambda</span> row: count_amino_acids(row[<span class="st">'epitope_name'</span>]), axis<span class="op">=</span><span class="dv">1</span>).<span class="bu">apply</span>(pd.Series)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-8" class="cell" data-execution_count="119">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>epitope_composition_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="119">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">A</th>
<th data-quarto-table-cell-role="th">C</th>
<th data-quarto-table-cell-role="th">D</th>
<th data-quarto-table-cell-role="th">E</th>
<th data-quarto-table-cell-role="th">F</th>
<th data-quarto-table-cell-role="th">G</th>
<th data-quarto-table-cell-role="th">H</th>
<th data-quarto-table-cell-role="th">I</th>
<th data-quarto-table-cell-role="th">K</th>
<th data-quarto-table-cell-role="th">L</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">N</th>
<th data-quarto-table-cell-role="th">P</th>
<th data-quarto-table-cell-role="th">Q</th>
<th data-quarto-table-cell-role="th">R</th>
<th data-quarto-table-cell-role="th">S</th>
<th data-quarto-table-cell-role="th">T</th>
<th data-quarto-table-cell-role="th">V</th>
<th data-quarto-table-cell-role="th">W</th>
<th data-quarto-table-cell-role="th">Y</th>
<th data-quarto-table-cell-role="th">peptide</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>2</td>
<td>0</td>
<td>2</td>
<td>0</td>
<td>1</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>AAGIGILTV</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>2</td>
<td>0</td>
<td>3</td>
<td>0</td>
<td>1</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>AAGIGILTVI</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>2</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>...</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>ACDPHSGHFV</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>4</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>ADLVGFLLLK</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>2</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>ADVEFCLSL</td>
</tr>
</tbody>
</table>

<p>5 rows × 21 columns</p>
</div>
</div>
</div>
<div id="cell-9" class="cell" data-execution_count="120">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example DataFrame with a 'peptide' column</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'peptide'</span>: [<span class="st">'ACDEFGHIK'</span>, <span class="st">'LMNPQRSTV'</span>, <span class="st">'WYFP'</span>]</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Kyte-Doolittle hydrophobicity scale</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>kyte_doolittle <span class="op">=</span> {</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'I'</span>: <span class="fl">4.5</span>, <span class="st">'V'</span>: <span class="fl">4.2</span>, <span class="st">'L'</span>: <span class="fl">3.8</span>, <span class="st">'F'</span>: <span class="fl">2.8</span>, <span class="st">'C'</span>: <span class="fl">2.5</span>,</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'M'</span>: <span class="fl">1.9</span>, <span class="st">'A'</span>: <span class="fl">1.8</span>, <span class="st">'G'</span>: <span class="op">-</span><span class="fl">0.4</span>, <span class="st">'T'</span>: <span class="op">-</span><span class="fl">0.7</span>, <span class="st">'S'</span>: <span class="op">-</span><span class="fl">0.8</span>,</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'W'</span>: <span class="op">-</span><span class="fl">0.9</span>, <span class="st">'Y'</span>: <span class="op">-</span><span class="fl">1.3</span>, <span class="st">'P'</span>: <span class="op">-</span><span class="fl">1.6</span>, <span class="st">'H'</span>: <span class="op">-</span><span class="fl">3.2</span>, <span class="st">'E'</span>: <span class="op">-</span><span class="fl">3.5</span>,</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Q'</span>: <span class="op">-</span><span class="fl">3.5</span>, <span class="st">'D'</span>: <span class="op">-</span><span class="fl">3.5</span>, <span class="st">'N'</span>: <span class="op">-</span><span class="fl">3.5</span>, <span class="st">'K'</span>: <span class="op">-</span><span class="fl">3.9</span>, <span class="st">'R'</span>: <span class="op">-</span><span class="fl">4.5</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_avg_hydrophobicity(peptide):</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get hydrophobicity scores for each amino acid; default to 0 if missing</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> [kyte_doolittle.get(aa, <span class="dv">0</span>) <span class="cf">for</span> aa <span class="kw">in</span> peptide]</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">sum</span>(scores) <span class="op">/</span> <span class="bu">len</span>(scores) <span class="cf">if</span> scores <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to the 'peptide' column to create a new column 'avg_hydro'</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'epitope_avg_hydro'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(compute_avg_hydrophobicity)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the molecular_weight function from Bio.SeqUtils</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_molecular_weight(peptide):</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the molecular weight of a peptide sequence using Biopython."""</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.molecular_weight()</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'molecular_weight'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_molecular_weight)</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_aromaticity(peptide):</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the aromaticity of a peptide sequence using Biopython."""</span></span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.aromaticity()</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'aromaticity'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_aromaticity)</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_isoelectric_point(peptide):</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the isoelectric point of a peptide sequence using Biopython."""</span></span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.isoelectric_point()</span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'isoelectric_point'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_isoelectric_point)</span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_instability(peptide):</span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the instability of a peptide sequence using Biopython."""</span></span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.instability_index()</span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb8-71"><a href="#cb8-71" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'instability'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_instability)</span>
<span id="cb8-72"><a href="#cb8-72" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_charge_at_pH7(peptide):</span>
<span id="cb8-73"><a href="#cb8-73" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the charge of a peptide sequence at pH 7 using Biopython."""</span></span>
<span id="cb8-74"><a href="#cb8-74" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb8-75"><a href="#cb8-75" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb8-76"><a href="#cb8-76" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb8-77"><a href="#cb8-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.charge_at_pH(<span class="dv">7</span>)</span>
<span id="cb8-78"><a href="#cb8-78" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb8-79"><a href="#cb8-79" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb8-80"><a href="#cb8-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb8-81"><a href="#cb8-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-82"><a href="#cb8-82" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb8-83"><a href="#cb8-83" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'charge_at_pH7'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_charge_at_pH7)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-10" class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>epitopes.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="121">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">epitope_name</th>
<th data-quarto-table-cell-role="th">fullsequence</th>
<th data-quarto-table-cell-role="th">mhcrestriction_name</th>
<th data-quarto-table-cell-role="th">mhcrestriction_class</th>
<th data-quarto-table-cell-role="th">epitope_length</th>
<th data-quarto-table-cell-role="th">epitope_avg_hydro</th>
<th data-quarto-table-cell-role="th">molecular_weight</th>
<th data-quarto-table-cell-role="th">aromaticity</th>
<th data-quarto-table-cell-role="th">isoelectric_point</th>
<th data-quarto-table-cell-role="th">instability</th>
<th data-quarto-table-cell-role="th">charge_at_pH7</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>AAGIGILTV</td>
<td>MPREDAHFIYGYPKKGHGHSYTTAEEAAGIGILTVILGVLLLIGCW...</td>
<td>HLA-A2</td>
<td>I</td>
<td>9</td>
<td>2.122222</td>
<td>813.9814</td>
<td>0.000000</td>
<td>5.570017</td>
<td>11.422222</td>
<td>-0.204125</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>AAGIGILTVI</td>
<td>MPREDAHFIYGYPKKGHGHSYTTAEEAAGIGILTVILGVLLLIGCW...</td>
<td>HLA-A*02:01</td>
<td>I</td>
<td>10</td>
<td>2.360000</td>
<td>927.1390</td>
<td>0.000000</td>
<td>5.570017</td>
<td>11.280000</td>
<td>-0.204125</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>ACDPHSGHFV</td>
<td>NaN</td>
<td>HLA-A2</td>
<td>I</td>
<td>10</td>
<td>-0.140000</td>
<td>1069.1507</td>
<td>0.100000</td>
<td>5.972266</td>
<td>61.830000</td>
<td>-1.038557</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>ADLVGFLLLK</td>
<td>MSLEQRSLHCKPEEALEAQQEALGLVCVQAATSSSSPLVLGTLEEV...</td>
<td>HLA-A*11:01</td>
<td>I</td>
<td>10</td>
<td>1.620000</td>
<td>1088.3394</td>
<td>0.100000</td>
<td>5.880358</td>
<td>-16.470000</td>
<td>-0.204004</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>ADVEFCLSL</td>
<td>MLLAVLYCLLWSFQTSAGHFPRACVSSKNLMEKECCPPWSGDRSPC...</td>
<td>HLA-B*44:03</td>
<td>I</td>
<td>9</td>
<td>1.233333</td>
<td>996.1348</td>
<td>0.111111</td>
<td>4.050028</td>
<td>20.855556</td>
<td>-2.210095</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="generation-of-negative-samples" class="level2">
<h2 class="anchored" data-anchor-id="generation-of-negative-samples">Generation of Negative Samples</h2>
<div id="cell-12" class="cell" data-execution_count="122">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_negatives(row):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    epitope <span class="op">=</span> row[<span class="st">"epitope_name"</span>]</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    full_seq <span class="op">=</span> row[<span class="st">"fullsequence"</span>]</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    mhc <span class="op">=</span> row[<span class="st">"mhcrestriction_name"</span>]</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle missing or empty sequences</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.isnull(full_seq) <span class="kw">or</span> full_seq <span class="op">==</span> <span class="st">""</span>:</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> []</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    epitope <span class="op">=</span> <span class="bu">str</span>(epitope)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    full_seq <span class="op">=</span> <span class="bu">str</span>(full_seq)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    ep_len <span class="op">=</span> <span class="bu">len</span>(epitope)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    negatives <span class="op">=</span> []</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(full_seq) <span class="op">-</span> ep_len <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>        window <span class="op">=</span> full_seq[i:i<span class="op">+</span>ep_len]</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> window <span class="op">!=</span> epitope:</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>            negatives.append({<span class="st">"peptide"</span>: window, <span class="st">"mhc"</span>: mhc})</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> negatives</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to each row</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="co">negatives = pd.DataFrame()</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="co">negatives['negatives'] = epitopes.apply(generate_negatives, axis=1)</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a><span class="co">negatives = negatives[["negatives"]].explode("negatives").reset_index(drop=True)</span></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a><span class="co">negatives.dropna(subset=["negatives"], inplace=True)</span></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove duplicate peptide-mhc combinations</span></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a><span class="co">print(f"Shape before removing duplicates: {negatives.shape}")</span></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a><span class="co">negatives = negatives.drop_duplicates(subset=['negatives'])</span></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a><span class="co">print(f"Shape after removing duplicates: {negatives.shape}")</span></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for any remaining NaN values</span></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a><span class="co">print(f"Number of NaN values in negatives: {negatives['negatives'].isna().sum()}")</span></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract peptide and mhc into separate columns</span></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a><span class="co">negatives['peptide'] = negatives['negatives'].apply(lambda x: x['peptide'])</span></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a><span class="co">negatives['mhc'] = negatives['negatives'].apply(lambda x: x['mhc'])</span></span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate features on the peptide column</span></span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a><span class="co">negatives['peptide_length'] = negatives['peptide'].apply(len)</span></span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a><span class="co">negatives['peptide_avg_hydro'] = negatives['peptide'].apply(compute_avg_hydrophobicity)</span></span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a><span class="co">negatives['molecular_weight'] = negatives['peptide'].apply(calculate_molecular_weight)</span></span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a><span class="co">negatives['aromaticity'] = negatives['peptide'].apply(calculate_aromaticity)</span></span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a><span class="co">negatives['isoelectric_point'] = negatives['peptide'].apply(calculate_isoelectric_point)</span></span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a><span class="co">negatives['instability'] = negatives['peptide'].apply(calculate_instability)</span></span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a><span class="co">negatives['charge_at_pH7'] = negatives['peptide'].apply(calculate_charge_at_pH7)</span></span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop the original dictionary column if no longer needed</span></span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a><span class="co">negatives.drop('negatives', axis=1, inplace=True)</span></span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="122">
<pre><code>'\n# Apply the function to each row\n\nnegatives = pd.DataFrame()\nnegatives[\'negatives\'] = epitopes.apply(generate_negatives, axis=1)\nnegatives = negatives[["negatives"]].explode("negatives").reset_index(drop=True)\nnegatives.dropna(subset=["negatives"], inplace=True)\n\n\n# Remove duplicate peptide-mhc combinations\nprint(f"Shape before removing duplicates: {negatives.shape}")\nnegatives = negatives.drop_duplicates(subset=[\'negatives\'])\nprint(f"Shape after removing duplicates: {negatives.shape}")\n\n# Check for any remaining NaN values\nprint(f"Number of NaN values in negatives: {negatives[\'negatives\'].isna().sum()}")\n\n# Extract peptide and mhc into separate columns\nnegatives[\'peptide\'] = negatives[\'negatives\'].apply(lambda x: x[\'peptide\'])\nnegatives[\'mhc\'] = negatives[\'negatives\'].apply(lambda x: x[\'mhc\'])\n\n# Calculate features on the peptide column\nnegatives[\'peptide_length\'] = negatives[\'peptide\'].apply(len)\nnegatives[\'peptide_avg_hydro\'] = negatives[\'peptide\'].apply(compute_avg_hydrophobicity)\nnegatives[\'molecular_weight\'] = negatives[\'peptide\'].apply(calculate_molecular_weight)\nnegatives[\'aromaticity\'] = negatives[\'peptide\'].apply(calculate_aromaticity)\nnegatives[\'isoelectric_point\'] = negatives[\'peptide\'].apply(calculate_isoelectric_point)\nnegatives[\'instability\'] = negatives[\'peptide\'].apply(calculate_instability)\nnegatives[\'charge_at_pH7\'] = negatives[\'peptide\'].apply(calculate_charge_at_pH7)\n\n# Drop the original dictionary column if no longer needed\nnegatives.drop(\'negatives\', axis=1, inplace=True)\n'</code></pre>
</div>
</div>
<div id="cell-13" class="cell" data-execution_count="123">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> pd.read_csv(<span class="st">"data/negatives_MHC.csv"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\Tariq\AppData\Local\Temp\ipykernel_22336\1811011591.py:1: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.
  negatives = pd.read_csv("data/negatives_MHC.csv")</code></pre>
</div>
</div>
<div id="cell-14" class="cell" data-execution_count="124">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>nine_mers <span class="op">=</span> epitopes[epitopes[<span class="st">'epitope_length'</span>] <span class="op">==</span> <span class="dv">9</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-15" class="cell" data-execution_count="125">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>ninemer_negatives <span class="op">=</span> negatives[negatives[<span class="st">'peptide_length'</span>] <span class="op">==</span> <span class="dv">9</span>]</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>ninemer_negatives_trimmed <span class="op">=</span> ninemer_negatives[:<span class="dv">50000</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="eda" class="level2">
<h2 class="anchored" data-anchor-id="eda">EDA</h2>
<section id="data-summary" class="level3">
<h3 class="anchored" data-anchor-id="data-summary">Data Summary</h3>
<div id="cell-18" class="cell" data-execution_count="126">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>epitopes.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="126">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">epitope_name</th>
<th data-quarto-table-cell-role="th">fullsequence</th>
<th data-quarto-table-cell-role="th">mhcrestriction_name</th>
<th data-quarto-table-cell-role="th">mhcrestriction_class</th>
<th data-quarto-table-cell-role="th">epitope_length</th>
<th data-quarto-table-cell-role="th">epitope_avg_hydro</th>
<th data-quarto-table-cell-role="th">molecular_weight</th>
<th data-quarto-table-cell-role="th">aromaticity</th>
<th data-quarto-table-cell-role="th">isoelectric_point</th>
<th data-quarto-table-cell-role="th">instability</th>
<th data-quarto-table-cell-role="th">charge_at_pH7</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>AAGIGILTV</td>
<td>MPREDAHFIYGYPKKGHGHSYTTAEEAAGIGILTVILGVLLLIGCW...</td>
<td>HLA-A2</td>
<td>I</td>
<td>9</td>
<td>2.122222</td>
<td>813.9814</td>
<td>0.000000</td>
<td>5.570017</td>
<td>11.422222</td>
<td>-0.204125</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>AAGIGILTVI</td>
<td>MPREDAHFIYGYPKKGHGHSYTTAEEAAGIGILTVILGVLLLIGCW...</td>
<td>HLA-A*02:01</td>
<td>I</td>
<td>10</td>
<td>2.360000</td>
<td>927.1390</td>
<td>0.000000</td>
<td>5.570017</td>
<td>11.280000</td>
<td>-0.204125</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>ACDPHSGHFV</td>
<td>NaN</td>
<td>HLA-A2</td>
<td>I</td>
<td>10</td>
<td>-0.140000</td>
<td>1069.1507</td>
<td>0.100000</td>
<td>5.972266</td>
<td>61.830000</td>
<td>-1.038557</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>ADLVGFLLLK</td>
<td>MSLEQRSLHCKPEEALEAQQEALGLVCVQAATSSSSPLVLGTLEEV...</td>
<td>HLA-A*11:01</td>
<td>I</td>
<td>10</td>
<td>1.620000</td>
<td>1088.3394</td>
<td>0.100000</td>
<td>5.880358</td>
<td>-16.470000</td>
<td>-0.204004</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>ADVEFCLSL</td>
<td>MLLAVLYCLLWSFQTSAGHFPRACVSSKNLMEKECCPPWSGDRSPC...</td>
<td>HLA-B*44:03</td>
<td>I</td>
<td>9</td>
<td>1.233333</td>
<td>996.1348</td>
<td>0.111111</td>
<td>4.050028</td>
<td>20.855556</td>
<td>-2.210095</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-19" class="cell" data-execution_count="127">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>epitopes.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 28681 entries, 0 to 28680
Data columns (total 11 columns):
 #   Column                Non-Null Count  Dtype  
---  ------                --------------  -----  
 0   epitope_name          28681 non-null  object 
 1   fullsequence          7164 non-null   object 
 2   mhcrestriction_name   17613 non-null  object 
 3   mhcrestriction_class  17613 non-null  object 
 4   epitope_length        28681 non-null  int64  
 5   epitope_avg_hydro     28681 non-null  float64
 6   molecular_weight      28623 non-null  float64
 7   aromaticity           28681 non-null  float64
 8   isoelectric_point     28681 non-null  float64
 9   instability           28623 non-null  float64
 10  charge_at_pH7         28681 non-null  float64
dtypes: float64(6), int64(1), object(4)
memory usage: 2.4+ MB</code></pre>
</div>
</div>
</section>
<section id="properties-of-epitopes" class="level3">
<h3 class="anchored" data-anchor-id="properties-of-epitopes">Properties of Epitopes</h3>
<section id="length" class="level4">
<h4 class="anchored" data-anchor-id="length">Length</h4>
<div id="cell-22" class="cell" data-execution_count="128">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># hist of epitope length</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>plt.hist(epitopes[<span class="st">'epitope_length'</span>], bins<span class="op">=</span><span class="dv">20</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epitope Length'</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Histogram of Epitope Length'</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-16-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-23" class="cell" data-execution_count="129">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'epitope_length'</span>].describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="129">
<pre><code>count    28681.000000
mean        19.389422
std          8.255925
min          6.000000
25%         10.000000
50%         20.000000
75%         25.000000
max         50.000000
Name: epitope_length, dtype: float64</code></pre>
</div>
</div>
</section>
<section id="hydrophobicity" class="level4">
<h4 class="anchored" data-anchor-id="hydrophobicity">Hydrophobicity</h4>
<div id="cell-25" class="cell" data-execution_count="130">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># histogram of average hydrophobicity</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>plt.hist(epitopes[<span class="st">'epitope_avg_hydro'</span>], bins<span class="op">=</span><span class="dv">20</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Average Hydrophobicity'</span>)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Histogram of Average Epitope Hydrophobicity'</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-18-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-26" class="cell" data-execution_count="131">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'epitope_avg_hydro'</span>].describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="131">
<pre><code>count    28681.000000
mean        -0.178410
std          0.883064
min         -3.312000
25%         -0.762500
50%         -0.240000
75%          0.333333
max          3.688889
Name: epitope_avg_hydro, dtype: float64</code></pre>
</div>
</div>
</section>
<section id="composition" class="level4">
<h4 class="anchored" data-anchor-id="composition">Composition</h4>
<div id="cell-28" class="cell" data-execution_count="132">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the composition of the epitopes, sort by the composition of the amino acids</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate mean composition and sort</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co">mean_composition = epitope_composition_df.mean().sort_values(ascending=False)</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the sorted composition</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co">plt.figure(figsize=(10, 6))</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="co">plt.bar(mean_composition.index, mean_composition.values)</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co">plt.xlabel('Amino Acid')</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="co">plt.ylabel('Composition')</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co">plt.title('Composition of Epitopes')</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="co">plt.show()</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="132">
<pre><code>"\nmean_composition = epitope_composition_df.mean().sort_values(ascending=False)\n\n# Plot the sorted composition\nplt.figure(figsize=(10, 6))\nplt.bar(mean_composition.index, mean_composition.values)\nplt.xlabel('Amino Acid')\nplt.ylabel('Composition')\nplt.title('Composition of Epitopes')\nplt.show()\n\n"</code></pre>
</div>
</div>
</section>
<section id="n-gram-frequency-analysis" class="level4">
<h4 class="anchored" data-anchor-id="n-gram-frequency-analysis">n-gram frequency analysis</h4>
<div id="cell-30" class="cell" data-execution_count="133">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ngram_frequency(peptides, n<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    ngrams <span class="op">=</span> []</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> peptide <span class="kw">in</span> peptides:</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(peptide) <span class="op">&lt;</span> n:</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(peptide) <span class="op">-</span> n <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>            ngram <span class="op">=</span> peptide[i:i<span class="op">+</span>n]</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>            ngrams.append(ngram)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Counter(ngrams)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>dipeptide_freq <span class="op">=</span> ngram_frequency(epitopes[<span class="st">'epitope_name'</span>], n<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>df_ngram <span class="op">=</span> pd.DataFrame(dipeptide_freq.items(), columns<span class="op">=</span>[<span class="st">'ngram'</span>, <span class="st">'count'</span>])</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>df_ngram <span class="op">=</span> df_ngram.sort_values(<span class="st">'count'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>top_n <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>top_ngram <span class="op">=</span> df_ngram.head(top_n)</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span><span class="st">'ngram'</span>, y<span class="op">=</span><span class="st">'count'</span>, data<span class="op">=</span>top_ngram, palette<span class="op">=</span><span class="st">"viridis"</span>)</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Epitopes Top </span><span class="sc">{</span>top_n<span class="sc">}</span><span class="ss"> Dipeptides Frequency"</span>)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Dipeptide"</span>)</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Frequency"</span>)</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\Tariq\AppData\Local\Temp\ipykernel_22336\733366050.py:20: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x='ngram', y='count', data=top_ngram, palette="viridis")</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-21-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="mhc-binding-affinity" class="level4">
<h4 class="anchored" data-anchor-id="mhc-binding-affinity">MHC Binding Affinity</h4>
</section>
</section>
<section id="properties-of-negative-samples" class="level3">
<h3 class="anchored" data-anchor-id="properties-of-negative-samples">Properties of negative samples</h3>
<div id="cell-33" class="cell" data-execution_count="134">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># hist of negative length</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>plt.hist(negatives[<span class="st">'peptide_length'</span>], bins<span class="op">=</span><span class="dv">20</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Negative Length'</span>)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Histogram of Negative Length'</span>)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-22-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-34" class="cell" data-execution_count="135">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># histogram of average hydrophobicity</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>plt.hist(negatives[<span class="st">'peptide_avg_hydro'</span>], bins<span class="op">=</span><span class="dv">20</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Average Hydrophobicity'</span>)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Histogram of Negative Average Hydrophobicity'</span>)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-23-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-35" class="cell" data-execution_count="136">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'peptide_avg_hydro'</span>].mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="136">
<pre><code>np.float64(-0.414394907411759)</code></pre>
</div>
</div>
<div id="cell-36" class="cell" data-execution_count="137">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the composition of the negatives, sort by the composition of the amino acids</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate mean composition and sort</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co">mean_composition = negatives_composition_df.mean().sort_values(ascending=False)</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the sorted composition</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co">plt.figure(figsize=(10, 6))</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="co">plt.bar(mean_composition.index, mean_composition.values)</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="co">plt.xlabel('Amino Acid')</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="co">plt.ylabel('Composition')</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="co">plt.title('Composition of Negative Samples')</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="co">plt.show()</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="137">
<pre><code>"\nmean_composition = negatives_composition_df.mean().sort_values(ascending=False)\n\n# Plot the sorted composition\nplt.figure(figsize=(10, 6))\nplt.bar(mean_composition.index, mean_composition.values)\nplt.xlabel('Amino Acid')\nplt.ylabel('Composition')\nplt.title('Composition of Negative Samples')\nplt.show()\n"</code></pre>
</div>
</div>
</section>
</section>
<section id="modeling" class="level2">
<h2 class="anchored" data-anchor-id="modeling">Modeling</h2>
<section id="data-preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="data-preprocessing">Data Preprocessing</h3>
<div id="cell-39" class="cell" data-execution_count="138">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.read_csv(<span class="st">"data/ninemer_epitopes.csv"</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.drop(columns<span class="op">=</span>[<span class="st">'fullsequence'</span>, <span class="st">'mhcrestriction_name'</span>, <span class="st">'mhcrestriction_class'</span>, <span class="st">'epitope_length'</span>])</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.rename(columns<span class="op">=</span>{<span class="st">'epitope_name'</span>: <span class="st">'peptide'</span>, <span class="st">'epitope_avg_hydro'</span>: <span class="st">'peptide_avg_hydro'</span>})</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>epitopes_BA_pred <span class="op">=</span> pd.read_csv(<span class="st">"data/ninemer_epitopes_BA_pred.csv"</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>epitopes_composition <span class="op">=</span> epitopes.<span class="bu">apply</span>(<span class="kw">lambda</span> row: count_amino_acids(row[<span class="st">'peptide'</span>]), axis<span class="op">=</span><span class="dv">1</span>).<span class="bu">apply</span>(pd.Series)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> pd.read_csv(<span class="st">"data/ninemer_negatives_trimmed.csv"</span>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.drop(columns<span class="op">=</span>[<span class="st">'mhc'</span>, <span class="st">'peptide_length'</span>])</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.rename(columns<span class="op">=</span>{<span class="st">'peptide'</span>: <span class="st">'peptide'</span>})</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.drop_duplicates(subset<span class="op">=</span>[<span class="st">'peptide'</span>])</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>negatives_BA_pred <span class="op">=</span> pd.read_csv(<span class="st">"data/ninemer_negatives_trimmed_BA_pred.csv"</span>)</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>negatives_BA_pred <span class="op">=</span> negatives_BA_pred.drop_duplicates(subset<span class="op">=</span>[<span class="st">'peptide'</span>])</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>negatives_composition <span class="op">=</span> negatives.<span class="bu">apply</span>(<span class="kw">lambda</span> row: count_amino_acids(row[<span class="st">'peptide'</span>]), axis<span class="op">=</span><span class="dv">1</span>).<span class="bu">apply</span>(pd.Series)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-40" class="cell" data-execution_count="139">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge the 'Score_BA' column from epitopes_BA_pred into the epitopes dataframe</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.merge(epitopes, epitopes_BA_pred[[<span class="st">'peptide'</span>, <span class="st">'Score_BA'</span>]], on<span class="op">=</span><span class="st">'peptide'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="co">#epitopes = pd.merge(epitopes, epitopes_composition, on='peptide', how='left')</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> pd.merge(negatives, negatives_BA_pred[[<span class="st">'peptide'</span>, <span class="st">'Score_BA'</span>]], on<span class="op">=</span><span class="st">'peptide'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="co">#negatives = pd.merge(negatives, negatives_composition, on='peptide', how='left')</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-41" class="cell" data-execution_count="140">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot Score_BA for epitopes and negatives overlaid on the same plot</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Use density instead of raw counts to normalize the histograms</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>plt.hist(epitopes[<span class="st">'Score_BA'</span>], bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'blue'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, </span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Epitopes'</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>plt.hist(negatives[<span class="st">'Score_BA'</span>], bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'red'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, </span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Negatives'</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternative approach: use log scale for y-axis</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>plt.yscale(<span class="st">'log'</span>)</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Binding Affinity'</span>)</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density (log scale)'</span>)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Normalized Histogram of Binding Affinity for Epitopes vs Negatives'</span>)</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>plt.legend(prop<span class="op">=</span>{<span class="st">'size'</span>: <span class="dv">14</span>})  <span class="co"># Increased legend font size</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-28-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-42" class="cell" data-execution_count="141">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot Score_BA for epitopes and negatives overlaid on the same plot</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Use density instead of raw counts to normalize the histograms</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>plt.hist(epitopes[<span class="st">'peptide_avg_hydro'</span>], bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'blue'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, </span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Epitopes'</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>plt.hist(negatives[<span class="st">'peptide_avg_hydro'</span>], bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'red'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, </span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Negatives'</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternative approach: use log scale for y-axis</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Binding Affinity'</span>)</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density (log scale)'</span>)</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Normalized Histogram of Binding Affinity for Epitopes vs Negatives'</span>)</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>plt.legend(prop<span class="op">=</span>{<span class="st">'size'</span>: <span class="dv">14</span>})  <span class="co"># Increased legend font size</span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-29-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-43" class="cell" data-execution_count="142">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare numeric features between epitopes and negatives datasets</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>numeric_features <span class="op">=</span> [<span class="st">'peptide_avg_hydro'</span>, <span class="st">'molecular_weight'</span>, <span class="st">'aromaticity'</span>, </span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'isoelectric_point'</span>, <span class="st">'instability'</span>, <span class="st">'charge_at_pH7'</span>, <span class="st">'Score_BA'</span>]</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a figure with subplots for each numeric feature</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="bu">len</span>(numeric_features), <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span><span class="op">*</span><span class="bu">len</span>(numeric_features)))</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co">#fig.tight_layout(pad=5.0)</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot boxplots for each feature</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, feature <span class="kw">in</span> <span class="bu">enumerate</span>(numeric_features):</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> axes[i]</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a temporary dataframe for plotting</span></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>    plot_data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Epitopes'</span>: epitopes[feature],</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Negatives'</span>: negatives[feature]</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create boxplot</span></span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>    sns.boxplot(data<span class="op">=</span>plot_data, ax<span class="op">=</span>ax)</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add feature statistics</span></span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a>    epitope_mean <span class="op">=</span> epitopes[feature].mean()</span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>    negative_mean <span class="op">=</span> negatives[feature].mean()</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'</span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss"> Distribution Comparison'</span>)</span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a>    ax.text(<span class="fl">0.02</span>, <span class="fl">0.95</span>, <span class="ss">f'Epitopes mean: </span><span class="sc">{</span>epitope_mean<span class="sc">:.4f}</span><span class="ss">'</span>, transform<span class="op">=</span>ax.transAxes)</span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a>    ax.text(<span class="fl">0.02</span>, <span class="fl">0.90</span>, <span class="ss">f'Negatives mean: </span><span class="sc">{</span>negative_mean<span class="sc">:.4f}</span><span class="ss">'</span>, transform<span class="op">=</span>ax.transAxes)</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add p-value from t-test</span></span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a>    t_stat, p_value <span class="op">=</span> stats.ttest_ind(</span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a>        epitopes[feature].dropna(), </span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a>        negatives[feature].dropna(),</span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a>        equal_var<span class="op">=</span><span class="va">False</span>  <span class="co"># Welch's t-test (doesn't assume equal variances)</span></span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a>    <span class="co">#ax.text(0.02, 0.85, f'p-value: {p_value:.4e}', transform=ax.transAxes)</span></span>
<span id="cb39-38"><a href="#cb39-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-39"><a href="#cb39-39" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.suptitle('Comparison of Numeric Features Between Epitopes and Negatives', fontsize=16)</span></span>
<span id="cb39-40"><a href="#cb39-40" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb39-41"><a href="#cb39-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-42"><a href="#cb39-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a summary table of the numeric features</span></span>
<span id="cb39-43"><a href="#cb39-43" aria-hidden="true" tabindex="-1"></a>summary_data <span class="op">=</span> []</span>
<span id="cb39-44"><a href="#cb39-44" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> feature <span class="kw">in</span> numeric_features:</span>
<span id="cb39-45"><a href="#cb39-45" aria-hidden="true" tabindex="-1"></a>    epitope_stats <span class="op">=</span> epitopes[feature].describe()</span>
<span id="cb39-46"><a href="#cb39-46" aria-hidden="true" tabindex="-1"></a>    negative_stats <span class="op">=</span> negatives[feature].describe()</span>
<span id="cb39-47"><a href="#cb39-47" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-48"><a href="#cb39-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate percent difference between means</span></span>
<span id="cb39-49"><a href="#cb39-49" aria-hidden="true" tabindex="-1"></a>    mean_diff_pct <span class="op">=</span> ((negative_stats[<span class="st">'mean'</span>] <span class="op">-</span> epitope_stats[<span class="st">'mean'</span>]) <span class="op">/</span> </span>
<span id="cb39-50"><a href="#cb39-50" aria-hidden="true" tabindex="-1"></a>                     epitope_stats[<span class="st">'mean'</span>] <span class="op">*</span> <span class="dv">100</span>)</span>
<span id="cb39-51"><a href="#cb39-51" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-52"><a href="#cb39-52" aria-hidden="true" tabindex="-1"></a>    summary_data.append({</span>
<span id="cb39-53"><a href="#cb39-53" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Feature'</span>: feature,</span>
<span id="cb39-54"><a href="#cb39-54" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Epitope Mean'</span>: epitope_stats[<span class="st">'mean'</span>],</span>
<span id="cb39-55"><a href="#cb39-55" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Negative Mean'</span>: negative_stats[<span class="st">'mean'</span>],</span>
<span id="cb39-56"><a href="#cb39-56" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Mean % Diff'</span>: mean_diff_pct,</span>
<span id="cb39-57"><a href="#cb39-57" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Epitope Std'</span>: epitope_stats[<span class="st">'std'</span>],</span>
<span id="cb39-58"><a href="#cb39-58" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Negative Std'</span>: negative_stats[<span class="st">'std'</span>],</span>
<span id="cb39-59"><a href="#cb39-59" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Epitope Min'</span>: epitope_stats[<span class="st">'min'</span>],</span>
<span id="cb39-60"><a href="#cb39-60" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Negative Min'</span>: negative_stats[<span class="st">'min'</span>],</span>
<span id="cb39-61"><a href="#cb39-61" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Epitope Max'</span>: epitope_stats[<span class="st">'max'</span>],</span>
<span id="cb39-62"><a href="#cb39-62" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Negative Max'</span>: negative_stats[<span class="st">'max'</span>]</span>
<span id="cb39-63"><a href="#cb39-63" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb39-64"><a href="#cb39-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-65"><a href="#cb39-65" aria-hidden="true" tabindex="-1"></a>summary_df <span class="op">=</span> pd.DataFrame(summary_data)</span>
<span id="cb39-66"><a href="#cb39-66" aria-hidden="true" tabindex="-1"></a>summary_df <span class="op">=</span> summary_df.<span class="bu">round</span>(<span class="dv">4</span>)</span>
<span id="cb39-67"><a href="#cb39-67" aria-hidden="true" tabindex="-1"></a>display(summary_df[[<span class="st">'Feature'</span>, <span class="st">'Epitope Mean'</span>, <span class="st">'Negative Mean'</span>, <span class="st">'Mean % Diff'</span>, </span>
<span id="cb39-68"><a href="#cb39-68" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'Epitope Std'</span>, <span class="st">'Negative Std'</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-30-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Feature</th>
<th data-quarto-table-cell-role="th">Epitope Mean</th>
<th data-quarto-table-cell-role="th">Negative Mean</th>
<th data-quarto-table-cell-role="th">Mean % Diff</th>
<th data-quarto-table-cell-role="th">Epitope Std</th>
<th data-quarto-table-cell-role="th">Negative Std</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>peptide_avg_hydro</td>
<td>0.2611</td>
<td>-0.2911</td>
<td>-211.5120</td>
<td>1.0224</td>
<td>1.1101</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>molecular_weight</td>
<td>1047.5733</td>
<td>1009.9028</td>
<td>-3.5960</td>
<td>90.8725</td>
<td>98.5481</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>aromaticity</td>
<td>0.1272</td>
<td>0.0837</td>
<td>-34.1917</td>
<td>0.1159</td>
<td>0.0965</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>isoelectric_point</td>
<td>6.8698</td>
<td>6.5924</td>
<td>-4.0390</td>
<td>2.3995</td>
<td>2.3867</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>instability</td>
<td>39.7001</td>
<td>47.1700</td>
<td>18.8158</td>
<td>40.8781</td>
<td>44.8497</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>charge_at_pH7</td>
<td>-0.0566</td>
<td>-0.2932</td>
<td>418.1175</td>
<td>1.3494</td>
<td>1.4918</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>Score_BA</td>
<td>0.5601</td>
<td>0.0730</td>
<td>-86.9606</td>
<td>0.2028</td>
<td>0.1121</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="cell-44" class="cell" data-execution_count="143">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add label column to epitopes dataframe (positive class = 1)</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'label'</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Add label column to negatives dataframe (negative class = 0)</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'label'</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine the positive and negative examples</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> pd.concat([epitopes, negatives], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Shuffle the combined dataset</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> combined_data.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Define features and target</span></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> combined_data.drop(columns<span class="op">=</span>[<span class="st">'peptide'</span>, <span class="st">'label'</span>])</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> combined_data[<span class="st">'label'</span>]</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify numerical columns to scale (exclude one-hot encoded amino acid columns)</span></span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>numerical_cols <span class="op">=</span> [<span class="st">'peptide_avg_hydro'</span>, <span class="st">'molecular_weight'</span>, <span class="st">'aromaticity'</span>, <span class="st">'isoelectric_point'</span>, <span class="st">'instability'</span>,<span class="st">'Score_BA'</span>, <span class="st">'charge_at_pH7'</span>]</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a><span class="co">#amino_acid_cols = [col for col in X.columns if col not in numerical_cols]</span></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets (80% train, 20% test)</span></span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y</span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Scale numerical features using StandardScaler</span></span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb40-31"><a href="#cb40-31" aria-hidden="true" tabindex="-1"></a>X_train[numerical_cols] <span class="op">=</span> scaler.fit_transform(X_train[numerical_cols])</span>
<span id="cb40-32"><a href="#cb40-32" aria-hidden="true" tabindex="-1"></a>X_test[numerical_cols] <span class="op">=</span> scaler.transform(X_test[numerical_cols])</span>
<span id="cb40-33"><a href="#cb40-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-34"><a href="#cb40-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the shapes to verify the split</span></span>
<span id="cb40-35"><a href="#cb40-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training set: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb40-36"><a href="#cb40-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Testing set: </span><span class="sc">{</span>X_test<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb40-37"><a href="#cb40-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in training: </span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb40-38"><a href="#cb40-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in training: </span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb40-39"><a href="#cb40-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in testing: </span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb40-40"><a href="#cb40-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in testing: </span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training set: 20502 samples
Testing set: 5126 samples
Positive samples in training: 4236
Negative samples in training: 16266
Positive samples in testing: 1059
Negative samples in testing: 4067</code></pre>
</div>
</div>
<div id="cell-45" class="cell" data-execution_count="144">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># drop the Score_BA column</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="co">#X_train = X_train.drop(columns=['Score_BA'])</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co">#X_test = X_test.drop(columns=['Score_BA'])</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="co"># drop the ic50 column if it exists</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co">#X_train = X_train.drop(columns=['ic50'])</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="co">#X_test = X_test.drop(columns=['ic50'])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-46" class="cell" data-execution_count="145">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Random Forest Classifier</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,  <span class="co"># Number of trees</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="va">None</span>,    <span class="co"># Maximum depth of trees</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X_train, y_train)</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> rf_model.predict(X_test)</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> rf_model.predict_proba(X_test)[:, <span class="dv">1</span>]  <span class="co"># Probability estimates for positive class</span></span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Random Forest Model Evaluation:"</span>)</span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, y_pred)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classification Report:"</span>)</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Confusion Matrix</span></span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, </span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>[<span class="st">'Predicted Negative'</span>, <span class="st">'Predicted Positive'</span>], </span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>            yticklabels<span class="op">=</span>[<span class="st">'Actual Negative'</span>, <span class="st">'Actual Positive'</span>])</span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Label'</span>)</span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Label'</span>)</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix - Random Forest'</span>)</span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate ROC AUC</span></span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> roc_auc_score(y_test, y_pred_proba)</span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">ROC AUC Score: </span><span class="sc">{</span>roc_auc<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot ROC Curve</span></span>
<span id="cb43-38"><a href="#cb43-38" aria-hidden="true" tabindex="-1"></a>fpr, tpr, _ <span class="op">=</span> roc_curve(y_test, y_pred_proba)</span>
<span id="cb43-39"><a href="#cb43-39" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb43-40"><a href="#cb43-40" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr, tpr, label<span class="op">=</span><span class="ss">f'Random Forest (AUC = </span><span class="sc">{</span>roc_auc<span class="sc">:.4f}</span><span class="ss">)'</span>)</span>
<span id="cb43-41"><a href="#cb43-41" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">'k--'</span>, label<span class="op">=</span><span class="st">'Random (AUC = 0.5)'</span>)</span>
<span id="cb43-42"><a href="#cb43-42" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'False Positive Rate'</span>)</span>
<span id="cb43-43"><a href="#cb43-43" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb43-44"><a href="#cb43-44" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'ROC Curve - Random Forest'</span>)</span>
<span id="cb43-45"><a href="#cb43-45" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb43-46"><a href="#cb43-46" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb43-47"><a href="#cb43-47" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb43-48"><a href="#cb43-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-49"><a href="#cb43-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature importance</span></span>
<span id="cb43-50"><a href="#cb43-50" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> pd.DataFrame({</span>
<span id="cb43-51"><a href="#cb43-51" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: X_train.columns,</span>
<span id="cb43-52"><a href="#cb43-52" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: rf_model.feature_importances_</span>
<span id="cb43-53"><a href="#cb43-53" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb43-54"><a href="#cb43-54" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> feature_importance.sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb43-55"><a href="#cb43-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-56"><a href="#cb43-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot top 15 features</span></span>
<span id="cb43-57"><a href="#cb43-57" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb43-58"><a href="#cb43-58" aria-hidden="true" tabindex="-1"></a>top_features <span class="op">=</span> feature_importance.head(<span class="dv">15</span>)</span>
<span id="cb43-59"><a href="#cb43-59" aria-hidden="true" tabindex="-1"></a>plt.barh(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Importance'</span>], align<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb43-60"><a href="#cb43-60" aria-hidden="true" tabindex="-1"></a>plt.yticks(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Feature'</span>])</span>
<span id="cb43-61"><a href="#cb43-61" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Importance'</span>)</span>
<span id="cb43-62"><a href="#cb43-62" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Feature Importance - Random Forest'</span>)</span>
<span id="cb43-63"><a href="#cb43-63" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb43-64"><a href="#cb43-64" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Random Forest Model Evaluation:
Accuracy: 0.9126

Classification Report:
              precision    recall  f1-score   support

           0       0.94      0.96      0.95      4067
           1       0.81      0.75      0.78      1059

    accuracy                           0.91      5126
   macro avg       0.88      0.85      0.86      5126
weighted avg       0.91      0.91      0.91      5126
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-33-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
ROC AUC Score: 0.9512</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-33-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-33-output-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="clustering" class="level3">
<h3 class="anchored" data-anchor-id="clustering">Clustering</h3>
<div id="cell-48" class="cell" data-execution_count="146">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example clustering approach</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans, DBSCAN, AgglomerativeClustering</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.impute <span class="im">import</span> SimpleImputer</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create feature matrix (using your existing features)</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> pd.concat([epitopes[[<span class="st">'peptide_avg_hydro'</span>, <span class="st">'molecular_weight'</span>, <span class="st">'aromaticity'</span>, </span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>                         <span class="st">'isoelectric_point'</span>, <span class="st">'instability'</span>, <span class="st">'charge_at_pH7'</span>, <span class="st">'Score_BA'</span>]], </span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>               <span class="co"># Add amino acid composition features</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>               pd.get_dummies(epitopes[<span class="st">'peptide'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="st">''</span>.join(x)), prefix<span class="op">=</span><span class="st">'pos'</span>)], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Handle missing values</span></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of NaN values in dataset:"</span>, X.isna().<span class="bu">sum</span>().<span class="bu">sum</span>())</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>imputer <span class="op">=</span> SimpleImputer(strategy<span class="op">=</span><span class="st">'mean'</span>)</span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>X_imputed <span class="op">=</span> imputer.fit_transform(X)</span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Option 1: K-means clustering</span></span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)  <span class="co"># Adjust number of clusters</span></span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>clusters <span class="op">=</span> kmeans.fit_predict(X_imputed)</span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'cluster'</span>] <span class="op">=</span> clusters</span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Option 2: Hierarchical clustering</span></span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a><span class="co"># hclust = AgglomerativeClustering(n_clusters=5)</span></span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a><span class="co"># clusters = hclust.fit_predict(X_imputed)</span></span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize with t-SNE</span></span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a>tsne <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a>X_tsne <span class="op">=</span> tsne.fit_transform(X_imputed)</span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb46-33"><a href="#cb46-33" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span>X_tsne[:, <span class="dv">0</span>], y<span class="op">=</span>X_tsne[:, <span class="dv">1</span>], hue<span class="op">=</span>clusters, palette<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb46-34"><a href="#cb46-34" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Epitope Clusters Visualization'</span>)</span>
<span id="cb46-35"><a href="#cb46-35" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb46-36"><a href="#cb46-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-37"><a href="#cb46-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Analyze cluster characteristics</span></span>
<span id="cb46-38"><a href="#cb46-38" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> cluster_id <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb46-39"><a href="#cb46-39" aria-hidden="true" tabindex="-1"></a>    cluster_peptides <span class="op">=</span> epitopes[epitopes[<span class="st">'cluster'</span>] <span class="op">==</span> cluster_id]</span>
<span id="cb46-40"><a href="#cb46-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Cluster </span><span class="sc">{</span>cluster_id<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span><span class="bu">len</span>(cluster_peptides)<span class="sc">}</span><span class="ss"> peptides"</span>)</span>
<span id="cb46-41"><a href="#cb46-41" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Average binding score: </span><span class="sc">{</span>cluster_peptides[<span class="st">'Score_BA'</span>]<span class="sc">.</span>mean()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb46-42"><a href="#cb46-42" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Average hydrophobicity: </span><span class="sc">{</span>cluster_peptides[<span class="st">'peptide_avg_hydro'</span>]<span class="sc">.</span>mean()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb46-43"><a href="#cb46-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-44"><a href="#cb46-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find sequence motifs in cluster</span></span>
<span id="cb46-45"><a href="#cb46-45" aria-hidden="true" tabindex="-1"></a>    motif_analysis <span class="op">=</span> pd.DataFrame()</span>
<span id="cb46-46"><a href="#cb46-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">9</span>):  <span class="co"># For 9-mer peptides</span></span>
<span id="cb46-47"><a href="#cb46-47" aria-hidden="true" tabindex="-1"></a>        aa_counts <span class="op">=</span> cluster_peptides[<span class="st">'peptide'</span>].<span class="bu">str</span>[i].value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb46-48"><a href="#cb46-48" aria-hidden="true" tabindex="-1"></a>        motif_analysis[<span class="ss">f'Position_</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>] <span class="op">=</span> aa_counts</span>
<span id="cb46-49"><a href="#cb46-49" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Top amino acids at each position:"</span>)</span>
<span id="cb46-50"><a href="#cb46-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> motif_analysis.columns:</span>
<span id="cb46-51"><a href="#cb46-51" aria-hidden="true" tabindex="-1"></a>        top_aas <span class="op">=</span> motif_analysis[col].nlargest(<span class="dv">3</span>)</span>
<span id="cb46-52"><a href="#cb46-52" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join([<span class="ss">f'</span><span class="sc">{</span>aa<span class="sc">}</span><span class="ss">(</span><span class="sc">{</span>freq<span class="sc">:.2f}</span><span class="ss">)'</span> <span class="cf">for</span> aa, freq <span class="kw">in</span> top_aas.items()])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb46-53"><a href="#cb46-53" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of NaN values in dataset: 937</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-34-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Cluster 0: 827 peptides
Average binding score: 0.55
Average hydrophobicity: 0.02
Top amino acids at each position:
Position_1: S(0.12), L(0.11), A(0.07)
Position_2: L(0.22), P(0.13), S(0.09)
Position_3: S(0.12), L(0.10), A(0.08)
Position_4: S(0.13), E(0.13), P(0.13)
Position_5: S(0.10), L(0.10), R(0.07)
Position_6: S(0.12), L(0.12), P(0.09)
Position_7: P(0.13), S(0.13), L(0.09)
Position_8: S(0.12), P(0.12), L(0.09)
Position_9: L(0.31), V(0.16), I(0.10)


Cluster 1: 732 peptides
Average binding score: 0.53
Average hydrophobicity: 0.75
Top amino acids at each position:
Position_1: A(0.20), G(0.14), S(0.14)
Position_2: L(0.31), A(0.13), P(0.13)
Position_3: A(0.16), G(0.11), S(0.11)
Position_4: G(0.17), P(0.16), A(0.15)
Position_5: G(0.19), A(0.16), V(0.11)
Position_6: G(0.16), S(0.14), L(0.12)
Position_7: A(0.13), P(0.12), S(0.11)
Position_8: A(0.18), S(0.16), G(0.12)
Position_9: L(0.29), V(0.25), A(0.14)


Cluster 2: 1419 peptides
Average binding score: 0.56
Average hydrophobicity: 0.57
Top amino acids at each position:
Position_1: L(0.10), A(0.10), S(0.09)
Position_2: L(0.32), V(0.10), T(0.08)
Position_3: L(0.14), A(0.09), S(0.09)
Position_4: S(0.09), G(0.09), L(0.09)
Position_5: L(0.11), G(0.11), A(0.09)
Position_6: L(0.14), V(0.09), S(0.09)
Position_7: L(0.14), V(0.11), A(0.09)
Position_8: L(0.11), A(0.10), S(0.10)
Position_9: L(0.28), V(0.20), K(0.12)


Cluster 3: 863 peptides
Average binding score: 0.57
Average hydrophobicity: -0.31
Top amino acids at each position:
Position_1: R(0.14), F(0.12), Y(0.12)
Position_2: L(0.19), Y(0.15), R(0.10)
Position_3: Y(0.11), F(0.11), L(0.10)
Position_4: E(0.11), R(0.10), L(0.08)
Position_5: R(0.14), F(0.11), L(0.09)
Position_6: L(0.12), F(0.10), R(0.08)
Position_7: L(0.12), F(0.09), R(0.08)
Position_8: L(0.10), E(0.09), R(0.09)
Position_9: L(0.26), F(0.18), Y(0.12)


Cluster 4: 1454 peptides
Average binding score: 0.58
Average hydrophobicity: 0.19
Top amino acids at each position:
Position_1: F(0.12), K(0.11), R(0.10)
Position_2: L(0.27), V(0.09), Y(0.08)
Position_3: L(0.13), F(0.08), D(0.07)
Position_4: E(0.11), D(0.08), L(0.08)
Position_5: L(0.11), F(0.08), V(0.08)
Position_6: L(0.15), V(0.09), I(0.09)
Position_7: L(0.14), F(0.09), V(0.06)
Position_8: L(0.13), S(0.08), F(0.08)
Position_9: L(0.28), V(0.15), F(0.11)

</code></pre>
</div>
</div>
</section>
<section id="new-model" class="level3">
<h3 class="anchored" data-anchor-id="new-model">New Model</h3>
</section>
</section>
<section id="convolutional-neural-network-cnn-implementation" class="level2">
<h2 class="anchored" data-anchor-id="convolutional-neural-network-cnn-implementation">Convolutional Neural Network (CNN) Implementation</h2>
<p>Below is a basic implementation of a Convolutional Neural Network using Keras (TensorFlow backend) for image classification. Adjust the <code>input_shape</code> and the number of output units in the final <code>Dense</code> layer according to your specific dataset.</p>
</section>
<section id="preparing-data-for-cnn" class="level2">
<h2 class="anchored" data-anchor-id="preparing-data-for-cnn">Preparing Data for CNN</h2>
<p>We need to: 1. Filter the epitopes and negatives dataframes to only contain the sequences and labels 2. One-hot encode the amino acid sequences 3. Split data into training and testing sets for the CNN model</p>
<div id="39aff293" class="cell" data-execution_count="147">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.preprocessing.sequence <span class="im">import</span> pad_sequences</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Filter the epitopes and negatives dataframes to only contain sequences and labels</span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>epitopes_filtered <span class="op">=</span> epitopes[[<span class="st">'peptide'</span>, <span class="st">'label'</span>]].copy()</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>epitopes_filtered.rename(columns<span class="op">=</span>{<span class="st">'peptide'</span>: <span class="st">'sequence'</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>negatives_filtered <span class="op">=</span> negatives[[<span class="st">'peptide'</span>, <span class="st">'label'</span>]].copy()</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>negatives_filtered.rename(columns<span class="op">=</span>{<span class="st">'peptide'</span>: <span class="st">'sequence'</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine the datasets</span></span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> pd.concat([epitopes_filtered, negatives_filtered], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> combined_data.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of samples: </span><span class="sc">{</span>combined_data<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples: </span><span class="sc">{</span><span class="bu">sum</span>(combined_data[<span class="st">'label'</span>] <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples: </span><span class="sc">{</span><span class="bu">sum</span>(combined_data[<span class="st">'label'</span>] <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Prepare for one-hot encoding</span></span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a><span class="co"># First, get all unique amino acids in our dataset</span></span>
<span id="cb49-22"><a href="#cb49-22" aria-hidden="true" tabindex="-1"></a>all_sequences <span class="op">=</span> combined_data[<span class="st">'sequence'</span>].values</span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a>unique_chars <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">set</span>(<span class="st">''</span>.join(all_sequences)))</span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Unique amino acids in dataset: </span><span class="sc">{</span>unique_chars<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-26"><a href="#cb49-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Create mapping dictionaries for one-hot encoding</span></span>
<span id="cb49-27"><a href="#cb49-27" aria-hidden="true" tabindex="-1"></a>char_to_index <span class="op">=</span> {char: i<span class="op">+</span><span class="dv">1</span> <span class="cf">for</span> i, char <span class="kw">in</span> <span class="bu">enumerate</span>(unique_chars)}  <span class="co"># Start from 1, reserve 0 for padding</span></span>
<span id="cb49-28"><a href="#cb49-28" aria-hidden="true" tabindex="-1"></a>index_to_char <span class="op">=</span> {i<span class="op">+</span><span class="dv">1</span>: char <span class="cf">for</span> i, char <span class="kw">in</span> <span class="bu">enumerate</span>(unique_chars)}</span>
<span id="cb49-29"><a href="#cb49-29" aria-hidden="true" tabindex="-1"></a>index_to_char[<span class="dv">0</span>] <span class="op">=</span> <span class="st">''</span>  <span class="co"># Padding token</span></span>
<span id="cb49-30"><a href="#cb49-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-31"><a href="#cb49-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Find maximum sequence length</span></span>
<span id="cb49-32"><a href="#cb49-32" aria-hidden="true" tabindex="-1"></a>max_length <span class="op">=</span> <span class="bu">max</span>(<span class="bu">len</span>(seq) <span class="cf">for</span> seq <span class="kw">in</span> all_sequences)</span>
<span id="cb49-33"><a href="#cb49-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Maximum sequence length: </span><span class="sc">{</span>max_length<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb49-34"><a href="#cb49-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-35"><a href="#cb49-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert sequences to integer sequences</span></span>
<span id="cb49-36"><a href="#cb49-36" aria-hidden="true" tabindex="-1"></a>int_sequences <span class="op">=</span> []</span>
<span id="cb49-37"><a href="#cb49-37" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> seq <span class="kw">in</span> all_sequences:</span>
<span id="cb49-38"><a href="#cb49-38" aria-hidden="true" tabindex="-1"></a>    int_seq <span class="op">=</span> [char_to_index[char] <span class="cf">for</span> char <span class="kw">in</span> seq]</span>
<span id="cb49-39"><a href="#cb49-39" aria-hidden="true" tabindex="-1"></a>    int_sequences.append(int_seq)</span>
<span id="cb49-40"><a href="#cb49-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-41"><a href="#cb49-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Pad sequences to have the same length</span></span>
<span id="cb49-42"><a href="#cb49-42" aria-hidden="true" tabindex="-1"></a>padded_sequences <span class="op">=</span> pad_sequences(int_sequences, maxlen<span class="op">=</span>max_length, padding<span class="op">=</span><span class="st">'post'</span>)</span>
<span id="cb49-43"><a href="#cb49-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-44"><a href="#cb49-44" aria-hidden="true" tabindex="-1"></a><span class="co"># One-hot encode the padded sequences</span></span>
<span id="cb49-45"><a href="#cb49-45" aria-hidden="true" tabindex="-1"></a>num_chars <span class="op">=</span> <span class="bu">len</span>(unique_chars) <span class="op">+</span> <span class="dv">1</span>  <span class="co"># +1 for padding token</span></span>
<span id="cb49-46"><a href="#cb49-46" aria-hidden="true" tabindex="-1"></a>X_onehot <span class="op">=</span> np.zeros((<span class="bu">len</span>(padded_sequences), max_length, num_chars))</span>
<span id="cb49-47"><a href="#cb49-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-48"><a href="#cb49-48" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, seq <span class="kw">in</span> <span class="bu">enumerate</span>(padded_sequences):</span>
<span id="cb49-49"><a href="#cb49-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j, char_idx <span class="kw">in</span> <span class="bu">enumerate</span>(seq):</span>
<span id="cb49-50"><a href="#cb49-50" aria-hidden="true" tabindex="-1"></a>        X_onehot[i, j, char_idx] <span class="op">=</span> <span class="fl">1.0</span>  <span class="co"># One-hot encode</span></span>
<span id="cb49-51"><a href="#cb49-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-52"><a href="#cb49-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Get labels</span></span>
<span id="cb49-53"><a href="#cb49-53" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> combined_data[<span class="st">'label'</span>].values</span>
<span id="cb49-54"><a href="#cb49-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-55"><a href="#cb49-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Print shapes to verify dimensions</span></span>
<span id="cb49-56"><a href="#cb49-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X_onehot shape: </span><span class="sc">{</span>X_onehot<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb49-57"><a href="#cb49-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of unique amino acids (including padding): </span><span class="sc">{</span>num_chars<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb49-58"><a href="#cb49-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-59"><a href="#cb49-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Split data into training, validation, and testing sets (70/15/15 split)</span></span>
<span id="cb49-60"><a href="#cb49-60" aria-hidden="true" tabindex="-1"></a><span class="co"># First split into temporary train and test</span></span>
<span id="cb49-61"><a href="#cb49-61" aria-hidden="true" tabindex="-1"></a>X_temp, X_test, y_temp, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb49-62"><a href="#cb49-62" aria-hidden="true" tabindex="-1"></a>    X_onehot, y, test_size<span class="op">=</span><span class="fl">0.15</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y</span>
<span id="cb49-63"><a href="#cb49-63" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-64"><a href="#cb49-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-65"><a href="#cb49-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Then split the temporary train into final train and validation</span></span>
<span id="cb49-66"><a href="#cb49-66" aria-hidden="true" tabindex="-1"></a><span class="co"># To get 70/15 split from the original data, we need to calculate the right proportion:</span></span>
<span id="cb49-67"><a href="#cb49-67" aria-hidden="true" tabindex="-1"></a><span class="co"># If test is 15% of total, then validation should be 15/85 of the remaining data (approx 17.65%)</span></span>
<span id="cb49-68"><a href="#cb49-68" aria-hidden="true" tabindex="-1"></a>X_train, X_val, y_train, y_val <span class="op">=</span> train_test_split(</span>
<span id="cb49-69"><a href="#cb49-69" aria-hidden="true" tabindex="-1"></a>    X_temp, y_temp, test_size<span class="op">=</span><span class="fl">0.1765</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y_temp</span>
<span id="cb49-70"><a href="#cb49-70" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-71"><a href="#cb49-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-72"><a href="#cb49-72" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training set shape: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>X_train<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="op">/</span>X_onehot<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss"> of total)"</span>)</span>
<span id="cb49-73"><a href="#cb49-73" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Validation set shape: </span><span class="sc">{</span>X_val<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>X_val<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="op">/</span>X_onehot<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss"> of total)"</span>)</span>
<span id="cb49-74"><a href="#cb49-74" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Testing set shape: </span><span class="sc">{</span>X_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>X_test<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="op">/</span>X_onehot<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss"> of total)"</span>)</span>
<span id="cb49-75"><a href="#cb49-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-76"><a href="#cb49-76" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in training: </span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">1</span>)<span class="op">/</span><span class="bu">len</span>(y_train)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb49-77"><a href="#cb49-77" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in training: </span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">0</span>)<span class="op">/</span><span class="bu">len</span>(y_train)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb49-78"><a href="#cb49-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-79"><a href="#cb49-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in validation: </span><span class="sc">{</span><span class="bu">sum</span>(y_val <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_val <span class="op">==</span> <span class="dv">1</span>)<span class="op">/</span><span class="bu">len</span>(y_val)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb49-80"><a href="#cb49-80" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in validation: </span><span class="sc">{</span><span class="bu">sum</span>(y_val <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_val <span class="op">==</span> <span class="dv">0</span>)<span class="op">/</span><span class="bu">len</span>(y_val)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb49-81"><a href="#cb49-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-82"><a href="#cb49-82" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in testing: </span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">1</span>)<span class="op">/</span><span class="bu">len</span>(y_test)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb49-83"><a href="#cb49-83" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in testing: </span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">0</span>)<span class="op">/</span><span class="bu">len</span>(y_test)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of samples: 25628
Positive samples: 5295
Negative samples: 20333
Unique amino acids in dataset: ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']
Maximum sequence length: 9
X_onehot shape: (25628, 9, 21)
Number of unique amino acids (including padding): 21
Training set shape: (17938, 9, 21) (70.0% of total)
Validation set shape: (3845, 9, 21) (15.0% of total)
Testing set shape: (3845, 9, 21) (15.0% of total)
Positive samples in training: 3707 (20.7%)
Negative samples in training: 14231 (79.3%)
Positive samples in validation: 794 (20.7%)
Negative samples in validation: 3051 (79.3%)
Positive samples in testing: 794 (20.7%)
Negative samples in testing: 3051 (79.3%)</code></pre>
</div>
</div>
</section>
<section id="convolutional-neural-network-cnn-implementation-1" class="level2">
<h2 class="anchored" data-anchor-id="convolutional-neural-network-cnn-implementation-1">Convolutional Neural Network (CNN) Implementation</h2>
<p>Below is a basic implementation of a Convolutional Neural Network using Keras (TensorFlow backend) for sequence classification.</p>
<div id="9890320a" class="cell" data-execution_count="148">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Sequential, Model</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input, BatchNormalization</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.callbacks <span class="im">import</span> EarlyStopping, ModelCheckpoint, ReduceLROnPlateau</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.regularizers <span class="im">import</span> l2</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.optimizers <span class="im">import</span> Adam</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_curve, f1_score</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the focal loss function to better handle class imbalance</span></span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> focal_loss(gamma<span class="op">=</span><span class="fl">2.0</span>, alpha<span class="op">=</span><span class="fl">0.25</span>):</span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> focal_loss_fn(y_true, y_pred):</span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert one-hot encoded targets to integers</span></span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> y_true.shape[<span class="op">-</span><span class="dv">1</span>] <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>            y_true <span class="op">=</span> tf.squeeze(y_true, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a>        y_true <span class="op">=</span> tf.cast(y_true, tf.int32)</span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the standard sparse categorical crossentropy</span></span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a>        sce <span class="op">=</span> tf.keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">False</span>, reduction<span class="op">=</span>tf.keras.losses.Reduction.NONE)(y_true, y_pred)</span>
<span id="cb51-21"><a href="#cb51-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb51-22"><a href="#cb51-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the prediction probability for the true class</span></span>
<span id="cb51-23"><a href="#cb51-23" aria-hidden="true" tabindex="-1"></a>        y_pred_proba <span class="op">=</span> tf.gather_nd(y_pred, tf.stack([tf.<span class="bu">range</span>(tf.shape(y_true)[<span class="dv">0</span>]), tf.cast(y_true, tf.int32)], axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb51-24"><a href="#cb51-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb51-25"><a href="#cb51-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply focal loss formula</span></span>
<span id="cb51-26"><a href="#cb51-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># p_t = p if y == 1 else 1-p for class 0</span></span>
<span id="cb51-27"><a href="#cb51-27" aria-hidden="true" tabindex="-1"></a>        p_t <span class="op">=</span> y_pred_proba</span>
<span id="cb51-28"><a href="#cb51-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add the alpha weighing factor</span></span>
<span id="cb51-29"><a href="#cb51-29" aria-hidden="true" tabindex="-1"></a>        alpha_factor <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb51-30"><a href="#cb51-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> alpha <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb51-31"><a href="#cb51-31" aria-hidden="true" tabindex="-1"></a>            <span class="co"># alpha_t = alpha if y == 1 else 1-alpha for class 0</span></span>
<span id="cb51-32"><a href="#cb51-32" aria-hidden="true" tabindex="-1"></a>            alpha_t <span class="op">=</span> tf.where(tf.equal(y_true, <span class="dv">1</span>), alpha, <span class="dv">1</span><span class="op">-</span>alpha)</span>
<span id="cb51-33"><a href="#cb51-33" aria-hidden="true" tabindex="-1"></a>            alpha_factor <span class="op">=</span> alpha_t</span>
<span id="cb51-34"><a href="#cb51-34" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb51-35"><a href="#cb51-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate focal weight</span></span>
<span id="cb51-36"><a href="#cb51-36" aria-hidden="true" tabindex="-1"></a>        gamma_factor <span class="op">=</span> tf.<span class="bu">pow</span>(<span class="fl">1.0</span> <span class="op">-</span> p_t, gamma)</span>
<span id="cb51-37"><a href="#cb51-37" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb51-38"><a href="#cb51-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the final loss</span></span>
<span id="cb51-39"><a href="#cb51-39" aria-hidden="true" tabindex="-1"></a>        focal_loss <span class="op">=</span> alpha_factor <span class="op">*</span> gamma_factor <span class="op">*</span> sce</span>
<span id="cb51-40"><a href="#cb51-40" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb51-41"><a href="#cb51-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> tf.reduce_mean(focal_loss)</span>
<span id="cb51-42"><a href="#cb51-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-43"><a href="#cb51-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> focal_loss_fn</span>
<span id="cb51-44"><a href="#cb51-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-45"><a href="#cb51-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an optimized CNN model for sequence data</span></span>
<span id="cb51-46"><a href="#cb51-46" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_optimized_cnn_model(input_shape, num_classes<span class="op">=</span><span class="dv">2</span>, use_focal_loss<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb51-47"><a href="#cb51-47" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> Input(shape<span class="op">=</span>input_shape)</span>
<span id="cb51-48"><a href="#cb51-48" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-49"><a href="#cb51-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># First convolutional block</span></span>
<span id="cb51-50"><a href="#cb51-50" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv1D(<span class="dv">32</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">'relu'</span>, padding<span class="op">=</span><span class="st">'same'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(inputs)</span>
<span id="cb51-51"><a href="#cb51-51" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb51-52"><a href="#cb51-52" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> MaxPooling1D(pool_size<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">'same'</span>)(x)</span>
<span id="cb51-53"><a href="#cb51-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-54"><a href="#cb51-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Second convolutional block with increased filters</span></span>
<span id="cb51-55"><a href="#cb51-55" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv1D(<span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">'relu'</span>, padding<span class="op">=</span><span class="st">'same'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(x)</span>
<span id="cb51-56"><a href="#cb51-56" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb51-57"><a href="#cb51-57" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> MaxPooling1D(pool_size<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">'same'</span>)(x)</span>
<span id="cb51-58"><a href="#cb51-58" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-59"><a href="#cb51-59" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Third convolutional block with even more filters</span></span>
<span id="cb51-60"><a href="#cb51-60" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv1D(<span class="dv">128</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">'relu'</span>, padding<span class="op">=</span><span class="st">'same'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(x)</span>
<span id="cb51-61"><a href="#cb51-61" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb51-62"><a href="#cb51-62" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-63"><a href="#cb51-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Flatten and dense layers</span></span>
<span id="cb51-64"><a href="#cb51-64" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Flatten()(x)</span>
<span id="cb51-65"><a href="#cb51-65" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-66"><a href="#cb51-66" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add more capacity to the dense layers</span></span>
<span id="cb51-67"><a href="#cb51-67" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">'relu'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(x)</span>
<span id="cb51-68"><a href="#cb51-68" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb51-69"><a href="#cb51-69" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dropout(<span class="fl">0.4</span>)(x)</span>
<span id="cb51-70"><a href="#cb51-70" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-71"><a href="#cb51-71" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(x)</span>
<span id="cb51-72"><a href="#cb51-72" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb51-73"><a href="#cb51-73" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dropout(<span class="fl">0.3</span>)(x)</span>
<span id="cb51-74"><a href="#cb51-74" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-75"><a href="#cb51-75" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Output layer</span></span>
<span id="cb51-76"><a href="#cb51-76" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> Dense(num_classes, activation<span class="op">=</span><span class="st">'softmax'</span>)(x)</span>
<span id="cb51-77"><a href="#cb51-77" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-78"><a href="#cb51-78" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs)</span>
<span id="cb51-79"><a href="#cb51-79" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-80"><a href="#cb51-80" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use a lower learning rate for better stability</span></span>
<span id="cb51-81"><a href="#cb51-81" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> Adam(learning_rate<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb51-82"><a href="#cb51-82" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-83"><a href="#cb51-83" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use focal loss if requested, otherwise use standard cross-entropy</span></span>
<span id="cb51-84"><a href="#cb51-84" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> use_focal_loss:</span>
<span id="cb51-85"><a href="#cb51-85" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> focal_loss(gamma<span class="op">=</span><span class="fl">2.0</span>, alpha<span class="op">=</span><span class="fl">0.75</span>)  <span class="co"># Adjust alpha based on class imbalance</span></span>
<span id="cb51-86"><a href="#cb51-86" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb51-87"><a href="#cb51-87" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> <span class="st">'sparse_categorical_crossentropy'</span></span>
<span id="cb51-88"><a href="#cb51-88" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-89"><a href="#cb51-89" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(</span>
<span id="cb51-90"><a href="#cb51-90" aria-hidden="true" tabindex="-1"></a>        optimizer<span class="op">=</span>optimizer,</span>
<span id="cb51-91"><a href="#cb51-91" aria-hidden="true" tabindex="-1"></a>        loss<span class="op">=</span>loss,</span>
<span id="cb51-92"><a href="#cb51-92" aria-hidden="true" tabindex="-1"></a>        metrics<span class="op">=</span>[<span class="st">'accuracy'</span>]</span>
<span id="cb51-93"><a href="#cb51-93" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb51-94"><a href="#cb51-94" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-95"><a href="#cb51-95" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb51-96"><a href="#cb51-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-97"><a href="#cb51-97" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate class weights based on class frequencies</span></span>
<span id="cb51-98"><a href="#cb51-98" aria-hidden="true" tabindex="-1"></a><span class="co"># This gives more weight to the minority class during training</span></span>
<span id="cb51-99"><a href="#cb51-99" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_class_weights(y_train):</span>
<span id="cb51-100"><a href="#cb51-100" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Count the number of samples per class</span></span>
<span id="cb51-101"><a href="#cb51-101" aria-hidden="true" tabindex="-1"></a>    class_counts <span class="op">=</span> np.bincount(y_train)</span>
<span id="cb51-102"><a href="#cb51-102" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the weight for each class (inversely proportional to class frequency)</span></span>
<span id="cb51-103"><a href="#cb51-103" aria-hidden="true" tabindex="-1"></a>    total_samples <span class="op">=</span> <span class="bu">len</span>(y_train)</span>
<span id="cb51-104"><a href="#cb51-104" aria-hidden="true" tabindex="-1"></a>    class_weights <span class="op">=</span> {</span>
<span id="cb51-105"><a href="#cb51-105" aria-hidden="true" tabindex="-1"></a>        i: total_samples <span class="op">/</span> (<span class="bu">len</span>(class_counts) <span class="op">*</span> count) </span>
<span id="cb51-106"><a href="#cb51-106" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, count <span class="kw">in</span> <span class="bu">enumerate</span>(class_counts)</span>
<span id="cb51-107"><a href="#cb51-107" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb51-108"><a href="#cb51-108" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> class_weights</span>
<span id="cb51-109"><a href="#cb51-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-110"><a href="#cb51-110" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the class weights for our training data</span></span>
<span id="cb51-111"><a href="#cb51-111" aria-hidden="true" tabindex="-1"></a>class_weights <span class="op">=</span> compute_class_weights(y_train)</span>
<span id="cb51-112"><a href="#cb51-112" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Class weights: </span><span class="sc">{</span>class_weights<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb51-113"><a href="#cb51-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-114"><a href="#cb51-114" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an optimized CNN model</span></span>
<span id="cb51-115"><a href="#cb51-115" aria-hidden="true" tabindex="-1"></a>optimized_cnn_model <span class="op">=</span> create_optimized_cnn_model(input_shape<span class="op">=</span>(X_train.shape[<span class="dv">1</span>], X_train.shape[<span class="dv">2</span>]), use_focal_loss<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb51-116"><a href="#cb51-116" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(optimized_cnn_model.summary())</span>
<span id="cb51-117"><a href="#cb51-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-118"><a href="#cb51-118" aria-hidden="true" tabindex="-1"></a><span class="co"># Define more sophisticated callbacks</span></span>
<span id="cb51-119"><a href="#cb51-119" aria-hidden="true" tabindex="-1"></a>early_stopping <span class="op">=</span> EarlyStopping(</span>
<span id="cb51-120"><a href="#cb51-120" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_loss'</span>, </span>
<span id="cb51-121"><a href="#cb51-121" aria-hidden="true" tabindex="-1"></a>    patience<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb51-122"><a href="#cb51-122" aria-hidden="true" tabindex="-1"></a>    restore_best_weights<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb51-123"><a href="#cb51-123" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">1</span></span>
<span id="cb51-124"><a href="#cb51-124" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb51-125"><a href="#cb51-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-126"><a href="#cb51-126" aria-hidden="true" tabindex="-1"></a>reduce_lr <span class="op">=</span> ReduceLROnPlateau(</span>
<span id="cb51-127"><a href="#cb51-127" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_loss'</span>,</span>
<span id="cb51-128"><a href="#cb51-128" aria-hidden="true" tabindex="-1"></a>    factor<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb51-129"><a href="#cb51-129" aria-hidden="true" tabindex="-1"></a>    patience<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb51-130"><a href="#cb51-130" aria-hidden="true" tabindex="-1"></a>    min_lr<span class="op">=</span><span class="fl">0.00001</span>,</span>
<span id="cb51-131"><a href="#cb51-131" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">1</span></span>
<span id="cb51-132"><a href="#cb51-132" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb51-133"><a href="#cb51-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-134"><a href="#cb51-134" aria-hidden="true" tabindex="-1"></a>model_checkpoint <span class="op">=</span> ModelCheckpoint(</span>
<span id="cb51-135"><a href="#cb51-135" aria-hidden="true" tabindex="-1"></a>    <span class="st">'best_optimized_cnn_model.h5'</span>,</span>
<span id="cb51-136"><a href="#cb51-136" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_accuracy'</span>,</span>
<span id="cb51-137"><a href="#cb51-137" aria-hidden="true" tabindex="-1"></a>    save_best_only<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb51-138"><a href="#cb51-138" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">1</span></span>
<span id="cb51-139"><a href="#cb51-139" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb51-140"><a href="#cb51-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-141"><a href="#cb51-141" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model with class weights</span></span>
<span id="cb51-142"><a href="#cb51-142" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> optimized_cnn_model.fit(</span>
<span id="cb51-143"><a href="#cb51-143" aria-hidden="true" tabindex="-1"></a>    X_train, y_train,</span>
<span id="cb51-144"><a href="#cb51-144" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">20</span>,  <span class="co"># Increase epochs since we have early stopping</span></span>
<span id="cb51-145"><a href="#cb51-145" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb51-146"><a href="#cb51-146" aria-hidden="true" tabindex="-1"></a>    validation_data<span class="op">=</span>(X_val, y_val),</span>
<span id="cb51-147"><a href="#cb51-147" aria-hidden="true" tabindex="-1"></a>    callbacks<span class="op">=</span>[early_stopping, reduce_lr, model_checkpoint],</span>
<span id="cb51-148"><a href="#cb51-148" aria-hidden="true" tabindex="-1"></a>    class_weight<span class="op">=</span>class_weights  <span class="co"># Use class weights during training</span></span>
<span id="cb51-149"><a href="#cb51-149" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb51-150"><a href="#cb51-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-151"><a href="#cb51-151" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model on test data</span></span>
<span id="cb51-152"><a href="#cb51-152" aria-hidden="true" tabindex="-1"></a>test_loss, test_accuracy <span class="op">=</span> optimized_cnn_model.evaluate(X_test, y_test)</span>
<span id="cb51-153"><a href="#cb51-153" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test accuracy: </span><span class="sc">{</span>test_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb51-154"><a href="#cb51-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-155"><a href="#cb51-155" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on test data</span></span>
<span id="cb51-156"><a href="#cb51-156" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> optimized_cnn_model.predict(X_test)</span>
<span id="cb51-157"><a href="#cb51-157" aria-hidden="true" tabindex="-1"></a>y_pred_proba_positive <span class="op">=</span> y_pred_proba[:, <span class="dv">1</span>]  <span class="co"># Probability for positive class</span></span>
<span id="cb51-158"><a href="#cb51-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-159"><a href="#cb51-159" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the optimal threshold for F1 score</span></span>
<span id="cb51-160"><a href="#cb51-160" aria-hidden="true" tabindex="-1"></a>thresholds <span class="op">=</span> np.arange(<span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="fl">0.05</span>)</span>
<span id="cb51-161"><a href="#cb51-161" aria-hidden="true" tabindex="-1"></a>f1_scores <span class="op">=</span> []</span>
<span id="cb51-162"><a href="#cb51-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-163"><a href="#cb51-163" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> threshold <span class="kw">in</span> thresholds:</span>
<span id="cb51-164"><a href="#cb51-164" aria-hidden="true" tabindex="-1"></a>    y_pred_thresholded <span class="op">=</span> (y_pred_proba_positive <span class="op">&gt;=</span> threshold).astype(<span class="bu">int</span>)</span>
<span id="cb51-165"><a href="#cb51-165" aria-hidden="true" tabindex="-1"></a>    f1 <span class="op">=</span> f1_score(y_test, y_pred_thresholded)</span>
<span id="cb51-166"><a href="#cb51-166" aria-hidden="true" tabindex="-1"></a>    f1_scores.append(f1)</span>
<span id="cb51-167"><a href="#cb51-167" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Threshold: </span><span class="sc">{</span>threshold<span class="sc">:.2f}</span><span class="ss">, F1 Score: </span><span class="sc">{</span>f1<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb51-168"><a href="#cb51-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-169"><a href="#cb51-169" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the best threshold</span></span>
<span id="cb51-170"><a href="#cb51-170" aria-hidden="true" tabindex="-1"></a>best_threshold_idx <span class="op">=</span> np.argmax(f1_scores)</span>
<span id="cb51-171"><a href="#cb51-171" aria-hidden="true" tabindex="-1"></a>best_threshold <span class="op">=</span> thresholds[best_threshold_idx]</span>
<span id="cb51-172"><a href="#cb51-172" aria-hidden="true" tabindex="-1"></a>best_f1 <span class="op">=</span> f1_scores[best_threshold_idx]</span>
<span id="cb51-173"><a href="#cb51-173" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Optimal threshold: </span><span class="sc">{</span>best_threshold<span class="sc">:.2f}</span><span class="ss"> with F1 Score: </span><span class="sc">{</span>best_f1<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb51-174"><a href="#cb51-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-175"><a href="#cb51-175" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the best threshold</span></span>
<span id="cb51-176"><a href="#cb51-176" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> (y_pred_proba_positive <span class="op">&gt;=</span> best_threshold).astype(<span class="bu">int</span>)</span>
<span id="cb51-177"><a href="#cb51-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-178"><a href="#cb51-178" aria-hidden="true" tabindex="-1"></a><span class="co"># Print classification report with the optimized threshold</span></span>
<span id="cb51-179"><a href="#cb51-179" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix</span>
<span id="cb51-180"><a href="#cb51-180" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classification Report with Optimized Threshold:"</span>)</span>
<span id="cb51-181"><a href="#cb51-181" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span>
<span id="cb51-182"><a href="#cb51-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-183"><a href="#cb51-183" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot confusion matrix</span></span>
<span id="cb51-184"><a href="#cb51-184" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb51-185"><a href="#cb51-185" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb51-186"><a href="#cb51-186" aria-hidden="true" tabindex="-1"></a>plt.imshow(cm, interpolation<span class="op">=</span><span class="st">'nearest'</span>, cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb51-187"><a href="#cb51-187" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix (Optimized Threshold)'</span>)</span>
<span id="cb51-188"><a href="#cb51-188" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb51-189"><a href="#cb51-189" aria-hidden="true" tabindex="-1"></a>tick_marks <span class="op">=</span> np.arange(<span class="dv">2</span>)</span>
<span id="cb51-190"><a href="#cb51-190" aria-hidden="true" tabindex="-1"></a>plt.xticks(tick_marks, [<span class="st">'Negative'</span>, <span class="st">'Positive'</span>])</span>
<span id="cb51-191"><a href="#cb51-191" aria-hidden="true" tabindex="-1"></a>plt.yticks(tick_marks, [<span class="st">'Negative'</span>, <span class="st">'Positive'</span>])</span>
<span id="cb51-192"><a href="#cb51-192" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Label'</span>)</span>
<span id="cb51-193"><a href="#cb51-193" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Label'</span>)</span>
<span id="cb51-194"><a href="#cb51-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-195"><a href="#cb51-195" aria-hidden="true" tabindex="-1"></a><span class="co"># Add text annotations to the confusion matrix</span></span>
<span id="cb51-196"><a href="#cb51-196" aria-hidden="true" tabindex="-1"></a>thresh <span class="op">=</span> cm.<span class="bu">max</span>() <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb51-197"><a href="#cb51-197" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(cm.shape[<span class="dv">0</span>]):</span>
<span id="cb51-198"><a href="#cb51-198" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(cm.shape[<span class="dv">1</span>]):</span>
<span id="cb51-199"><a href="#cb51-199" aria-hidden="true" tabindex="-1"></a>        plt.text(j, i, cm[i, j],</span>
<span id="cb51-200"><a href="#cb51-200" aria-hidden="true" tabindex="-1"></a>                 horizontalalignment<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb51-201"><a href="#cb51-201" aria-hidden="true" tabindex="-1"></a>                 color<span class="op">=</span><span class="st">"white"</span> <span class="cf">if</span> cm[i, j] <span class="op">&gt;</span> thresh <span class="cf">else</span> <span class="st">"black"</span>)</span>
<span id="cb51-202"><a href="#cb51-202" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb51-203"><a href="#cb51-203" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb51-204"><a href="#cb51-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-205"><a href="#cb51-205" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot training history</span></span>
<span id="cb51-206"><a href="#cb51-206" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb51-207"><a href="#cb51-207" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb51-208"><a href="#cb51-208" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'accuracy'</span>], label<span class="op">=</span><span class="st">'Training Accuracy'</span>)</span>
<span id="cb51-209"><a href="#cb51-209" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'val_accuracy'</span>], label<span class="op">=</span><span class="st">'Validation Accuracy'</span>)</span>
<span id="cb51-210"><a href="#cb51-210" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Model Accuracy'</span>)</span>
<span id="cb51-211"><a href="#cb51-211" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb51-212"><a href="#cb51-212" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb51-213"><a href="#cb51-213" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb51-214"><a href="#cb51-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-215"><a href="#cb51-215" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb51-216"><a href="#cb51-216" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'loss'</span>], label<span class="op">=</span><span class="st">'Training Loss'</span>)</span>
<span id="cb51-217"><a href="#cb51-217" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'val_loss'</span>], label<span class="op">=</span><span class="st">'Validation Loss'</span>)</span>
<span id="cb51-218"><a href="#cb51-218" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Model Loss'</span>)</span>
<span id="cb51-219"><a href="#cb51-219" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb51-220"><a href="#cb51-220" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb51-221"><a href="#cb51-221" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb51-222"><a href="#cb51-222" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb51-223"><a href="#cb51-223" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb51-224"><a href="#cb51-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-225"><a href="#cb51-225" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot ROC curve</span></span>
<span id="cb51-226"><a href="#cb51-226" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, auc</span>
<span id="cb51-227"><a href="#cb51-227" aria-hidden="true" tabindex="-1"></a>fpr, tpr, _ <span class="op">=</span> roc_curve(y_test, y_pred_proba_positive)</span>
<span id="cb51-228"><a href="#cb51-228" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb51-229"><a href="#cb51-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-230"><a href="#cb51-230" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb51-231"><a href="#cb51-231" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr, tpr, color<span class="op">=</span><span class="st">'darkorange'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="ss">f'ROC curve (area = </span><span class="sc">{</span>roc_auc<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb51-232"><a href="#cb51-232" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'navy'</span>, lw<span class="op">=</span><span class="dv">2</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb51-233"><a href="#cb51-233" aria-hidden="true" tabindex="-1"></a>plt.scatter(fpr[np.argmin(np.<span class="bu">abs</span>(thresholds <span class="op">-</span> best_threshold))], </span>
<span id="cb51-234"><a href="#cb51-234" aria-hidden="true" tabindex="-1"></a>            tpr[np.argmin(np.<span class="bu">abs</span>(thresholds <span class="op">-</span> best_threshold))], </span>
<span id="cb51-235"><a href="#cb51-235" aria-hidden="true" tabindex="-1"></a>            c<span class="op">=</span><span class="st">'red'</span>, marker<span class="op">=</span><span class="st">'o'</span>, s<span class="op">=</span><span class="dv">100</span>, label<span class="op">=</span><span class="ss">f'Best threshold = </span><span class="sc">{</span>best_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb51-236"><a href="#cb51-236" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="fl">0.0</span>, <span class="fl">1.0</span>])</span>
<span id="cb51-237"><a href="#cb51-237" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="fl">0.0</span>, <span class="fl">1.05</span>])</span>
<span id="cb51-238"><a href="#cb51-238" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'False Positive Rate'</span>)</span>
<span id="cb51-239"><a href="#cb51-239" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb51-240"><a href="#cb51-240" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Receiver Operating Characteristic'</span>)</span>
<span id="cb51-241"><a href="#cb51-241" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb51-242"><a href="#cb51-242" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb51-243"><a href="#cb51-243" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb51-244"><a href="#cb51-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-245"><a href="#cb51-245" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Precision-Recall curve</span></span>
<span id="cb51-246"><a href="#cb51-246" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_curve, average_precision_score</span>
<span id="cb51-247"><a href="#cb51-247" aria-hidden="true" tabindex="-1"></a>precision, recall, thresholds_pr <span class="op">=</span> precision_recall_curve(y_test, y_pred_proba_positive)</span>
<span id="cb51-248"><a href="#cb51-248" aria-hidden="true" tabindex="-1"></a>avg_precision <span class="op">=</span> average_precision_score(y_test, y_pred_proba_positive)</span>
<span id="cb51-249"><a href="#cb51-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-250"><a href="#cb51-250" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb51-251"><a href="#cb51-251" aria-hidden="true" tabindex="-1"></a>plt.plot(recall, precision, color<span class="op">=</span><span class="st">'blue'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="ss">f'PR curve (AP = </span><span class="sc">{</span>avg_precision<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb51-252"><a href="#cb51-252" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Recall'</span>)</span>
<span id="cb51-253"><a href="#cb51-253" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Precision'</span>)</span>
<span id="cb51-254"><a href="#cb51-254" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Precision-Recall Curve'</span>)</span>
<span id="cb51-255"><a href="#cb51-255" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"upper right"</span>)</span>
<span id="cb51-256"><a href="#cb51-256" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb51-257"><a href="#cb51-257" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb51-258"><a href="#cb51-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-259"><a href="#cb51-259" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare with the best threshold ROC point</span></span>
<span id="cb51-260"><a href="#cb51-260" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb51-261"><a href="#cb51-261" aria-hidden="true" tabindex="-1"></a>plt.step(recall, precision, color<span class="op">=</span><span class="st">'blue'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>, where<span class="op">=</span><span class="st">'post'</span>)</span>
<span id="cb51-262"><a href="#cb51-262" aria-hidden="true" tabindex="-1"></a>plt.fill_between(recall, precision, alpha<span class="op">=</span><span class="fl">0.2</span>, color<span class="op">=</span><span class="st">'blue'</span>, step<span class="op">=</span><span class="st">'post'</span>)</span>
<span id="cb51-263"><a href="#cb51-263" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Recall'</span>)</span>
<span id="cb51-264"><a href="#cb51-264" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Precision'</span>)</span>
<span id="cb51-265"><a href="#cb51-265" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="fl">0.0</span>, <span class="fl">1.05</span>])</span>
<span id="cb51-266"><a href="#cb51-266" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="fl">0.0</span>, <span class="fl">1.0</span>])</span>
<span id="cb51-267"><a href="#cb51-267" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Precision-Recall Curve: AP=</span><span class="sc">{0:0.2f}</span><span class="st">'</span>.<span class="bu">format</span>(avg_precision))</span>
<span id="cb51-268"><a href="#cb51-268" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb51-269"><a href="#cb51-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-270"><a href="#cb51-270" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot F1 Score vs Threshold</span></span>
<span id="cb51-271"><a href="#cb51-271" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb51-272"><a href="#cb51-272" aria-hidden="true" tabindex="-1"></a>plt.plot(thresholds, f1_scores, <span class="st">'b-'</span>, label<span class="op">=</span><span class="st">'F1 Score'</span>)</span>
<span id="cb51-273"><a href="#cb51-273" aria-hidden="true" tabindex="-1"></a>plt.plot([best_threshold, best_threshold], [<span class="dv">0</span>, best_f1], <span class="st">'r--'</span>, label<span class="op">=</span><span class="ss">f'Best Threshold = </span><span class="sc">{</span>best_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb51-274"><a href="#cb51-274" aria-hidden="true" tabindex="-1"></a>plt.plot(best_threshold, best_f1, <span class="st">'ro'</span>, markersize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb51-275"><a href="#cb51-275" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'F1 Score vs. Threshold'</span>)</span>
<span id="cb51-276"><a href="#cb51-276" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Threshold'</span>)</span>
<span id="cb51-277"><a href="#cb51-277" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'F1 Score'</span>)</span>
<span id="cb51-278"><a href="#cb51-278" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb51-279"><a href="#cb51-279" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb51-280"><a href="#cb51-280" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb51-281"><a href="#cb51-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-282"><a href="#cb51-282" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparing model performance before and after optimization</span></span>
<span id="cb51-283"><a href="#cb51-283" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Model performance comparison:"</span>)</span>
<span id="cb51-284"><a href="#cb51-284" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimal threshold: </span><span class="sc">{</span>best_threshold<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb51-285"><a href="#cb51-285" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Original model test accuracy: </span><span class="sc">{</span>test_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb51-286"><a href="#cb51-286" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimized model test accuracy (with best threshold): </span><span class="sc">{</span>accuracy_score(y_test, y_pred)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb51-287"><a href="#cb51-287" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimized model F1 score: </span><span class="sc">{</span>f1_score(y_test, y_pred)<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Class weights: {0: np.float64(0.6302438338837748), 1: np.float64(2.419476665767467)}</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "functional_4"</span>
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_4 (<span style="color: #0087ff; text-decoration-color: #0087ff">InputLayer</span>)      │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">9</span>, <span style="color: #00af00; text-decoration-color: #00af00">21</span>)          │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv1d_12 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv1D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">9</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>)          │         <span style="color: #00af00; text-decoration-color: #00af00">2,048</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_20          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">9</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>)          │           <span style="color: #00af00; text-decoration-color: #00af00">128</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling1d_8 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling1D</span>)  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>)          │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv1d_13 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv1D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)          │         <span style="color: #00af00; text-decoration-color: #00af00">6,208</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_21          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)          │           <span style="color: #00af00; text-decoration-color: #00af00">256</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling1d_9 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling1D</span>)  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">3</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)          │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv1d_14 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv1D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">3</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)         │        <span style="color: #00af00; text-decoration-color: #00af00">24,704</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_22          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">3</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)         │           <span style="color: #00af00; text-decoration-color: #00af00">512</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ flatten_4 (<span style="color: #0087ff; text-decoration-color: #0087ff">Flatten</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_12 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">49,280</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_23          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)            │           <span style="color: #00af00; text-decoration-color: #00af00">512</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_8 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_13 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">8,256</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_24          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             │           <span style="color: #00af00; text-decoration-color: #00af00">256</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_9 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_14 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">2</span>)              │           <span style="color: #00af00; text-decoration-color: #00af00">130</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">92,290</span> (360.51 KB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">91,458</span> (357.26 KB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">832</span> (3.25 KB)
</pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>None
Epoch 1/20
550/561 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.5843 - loss: 1.2324
Epoch 1: val_accuracy improved from -inf to 0.71886, saving model to best_optimized_cnn_model.h5</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>561/561 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step - accuracy: 0.5853 - loss: 1.2296 - val_accuracy: 0.7189 - val_loss: 0.9192 - learning_rate: 0.0010
Epoch 2/20
556/561 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7220 - loss: 0.8863
Epoch 2: val_accuracy did not improve from 0.71886
561/561 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - accuracy: 0.7220 - loss: 0.8861 - val_accuracy: 0.7111 - val_loss: 0.8612 - learning_rate: 0.0010
Epoch 3/20
554/561 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7569 - loss: 0.7701
Epoch 3: val_accuracy improved from 0.71886 to 0.73680, saving model to best_optimized_cnn_model.h5</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>561/561 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - accuracy: 0.7570 - loss: 0.7699 - val_accuracy: 0.7368 - val_loss: 0.7784 - learning_rate: 0.0010
Epoch 4/20
546/561 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7754 - loss: 0.6955
Epoch 4: val_accuracy improved from 0.73680 to 0.75865, saving model to best_optimized_cnn_model.h5</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>561/561 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - accuracy: 0.7755 - loss: 0.6952 - val_accuracy: 0.7586 - val_loss: 0.6881 - learning_rate: 0.0010
Epoch 5/20
556/561 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7890 - loss: 0.6234
Epoch 5: val_accuracy improved from 0.75865 to 0.76099, saving model to best_optimized_cnn_model.h5</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>561/561 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - accuracy: 0.7889 - loss: 0.6234 - val_accuracy: 0.7610 - val_loss: 0.6425 - learning_rate: 0.0010
Epoch 6/20
547/561 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8026 - loss: 0.5652
Epoch 6: val_accuracy improved from 0.76099 to 0.76697, saving model to best_optimized_cnn_model.h5</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>561/561 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - accuracy: 0.8026 - loss: 0.5653 - val_accuracy: 0.7670 - val_loss: 0.6263 - learning_rate: 0.0010
Epoch 7/20
558/561 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8145 - loss: 0.5222
Epoch 7: val_accuracy did not improve from 0.76697
561/561 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - accuracy: 0.8144 - loss: 0.5223 - val_accuracy: 0.7514 - val_loss: 0.6617 - learning_rate: 0.0010
Epoch 8/20
560/561 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8209 - loss: 0.5023
Epoch 8: val_accuracy improved from 0.76697 to 0.78388, saving model to best_optimized_cnn_model.h5</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>561/561 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - accuracy: 0.8209 - loss: 0.5024 - val_accuracy: 0.7839 - val_loss: 0.5634 - learning_rate: 0.0010
Epoch 9/20
553/561 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8258 - loss: 0.4819
Epoch 9: val_accuracy did not improve from 0.78388
561/561 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - accuracy: 0.8257 - loss: 0.4820 - val_accuracy: 0.7823 - val_loss: 0.5814 - learning_rate: 0.0010
Epoch 10/20
553/561 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8392 - loss: 0.4545
Epoch 10: val_accuracy improved from 0.78388 to 0.80338, saving model to best_optimized_cnn_model.h5</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>561/561 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - accuracy: 0.8390 - loss: 0.4547 - val_accuracy: 0.8034 - val_loss: 0.5903 - learning_rate: 0.0010
Epoch 11/20
550/561 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8445 - loss: 0.4441
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.

Epoch 11: val_accuracy did not improve from 0.80338
561/561 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - accuracy: 0.8442 - loss: 0.4445 - val_accuracy: 0.7867 - val_loss: 0.5724 - learning_rate: 0.0010
Epoch 12/20
548/561 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8644 - loss: 0.3994
Epoch 12: val_accuracy did not improve from 0.80338
561/561 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - accuracy: 0.8646 - loss: 0.3992 - val_accuracy: 0.8000 - val_loss: 0.5969 - learning_rate: 2.0000e-04
Epoch 13/20
561/561 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8949 - loss: 0.3449
Epoch 13: val_accuracy did not improve from 0.80338
561/561 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - accuracy: 0.8949 - loss: 0.3449 - val_accuracy: 0.8023 - val_loss: 0.5995 - learning_rate: 2.0000e-04
Epoch 14/20
546/561 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.9125 - loss: 0.3085
Epoch 14: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.

Epoch 14: val_accuracy did not improve from 0.80338
561/561 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - accuracy: 0.9125 - loss: 0.3085 - val_accuracy: 0.8023 - val_loss: 0.6507 - learning_rate: 2.0000e-04
Epoch 15/20
549/561 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.9181 - loss: 0.2892
Epoch 15: val_accuracy improved from 0.80338 to 0.81717, saving model to best_optimized_cnn_model.h5</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>561/561 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - accuracy: 0.9182 - loss: 0.2891 - val_accuracy: 0.8172 - val_loss: 0.6458 - learning_rate: 4.0000e-05
Epoch 16/20
547/561 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.9377 - loss: 0.2629
Epoch 16: val_accuracy did not improve from 0.81717
561/561 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - accuracy: 0.9376 - loss: 0.2630 - val_accuracy: 0.8133 - val_loss: 0.6734 - learning_rate: 4.0000e-05
Epoch 16: early stopping
Restoring model weights from the end of the best epoch: 8.
121/121 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7840 - loss: 0.5654
Test accuracy: 0.7815
121/121 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step
Threshold: 0.10, F1 Score: 0.5067
Threshold: 0.15, F1 Score: 0.5379
Threshold: 0.20, F1 Score: 0.5621
Threshold: 0.25, F1 Score: 0.5745
Threshold: 0.30, F1 Score: 0.5861
Threshold: 0.35, F1 Score: 0.5970
Threshold: 0.40, F1 Score: 0.6045
Threshold: 0.45, F1 Score: 0.6083
Threshold: 0.50, F1 Score: 0.6089
Threshold: 0.55, F1 Score: 0.6068
Threshold: 0.60, F1 Score: 0.6097
Threshold: 0.65, F1 Score: 0.6026
Threshold: 0.70, F1 Score: 0.5850
Threshold: 0.75, F1 Score: 0.5496
Threshold: 0.80, F1 Score: 0.4977
Threshold: 0.85, F1 Score: 0.3864

Optimal threshold: 0.60 with F1 Score: 0.6097

Classification Report with Optimized Threshold:
              precision    recall  f1-score   support

           0       0.93      0.81      0.87      3051
           1       0.51      0.75      0.61       794

    accuracy                           0.80      3845
   macro avg       0.72      0.78      0.74      3845
weighted avg       0.84      0.80      0.81      3845
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-36-output-24.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-36-output-25.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-36-output-26.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-36-output-27.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-36-output-28.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="capstone_files/figure-html/cell-36-output-29.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Model performance comparison:
Optimal threshold: 0.60
Original model test accuracy: 0.7815
Optimized model test accuracy (with best threshold): 0.8016
Optimized model F1 score: 0.6097</code></pre>
</div>
</div>
<div id="cell-55" class="cell" data-execution_count="149">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tf.config.list_physical_devices(<span class="st">'GPU'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[]</code></pre>
</div>
</div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>