# Cancer T-Cell Epitope Classification

## Project Goal

This project explores the use of machine learning techniques to classify short amino acid sequences (peptides) as T-cell epitopes or non-epitopes, specifically focusing on human cancer antigens. Accurate epitope prediction is crucial for designing targeted immunotherapies, such as personalized cancer vaccines.

## Data

*   **Source:** Data primarily originates from the [Immune Epitope Database (IEDB)](https://www.iedb.org).
*   **Selection:** Focused on experimentally validated human cancer T-cell epitopes (primarily 9-mers for MHC Class I presentation). The MHC allele distribution shows a significant skew towards HLA-A*02:01.
*   **Negative Samples:** Generated by sampling non-epitope 9-mer sequences from the full antigen sequences corresponding to the known epitopes.
*   **Key Data Files:** Located in the `data/` directory (e.g., `ninemer_epitopes.csv`, `ninemer_negatives_trimmed.csv`, prediction files).

## Methodology

1.  **Data Preprocessing:** Cleaning and formatting data downloaded from IEDB, including fetching full antigen sequences and examining MHC allele distribution.
2.  **Feature Engineering:**
    *   Calculation of various physicochemical properties (hydrophobicity, molecular weight, aromaticity, etc.) using BioPython.
    *   Prediction of MHC class I binding affinity (`Score_BA`) using the external tool `netMHCpan` (v4.1). The script `binding_affinity_prediction.py` is used for this.
3.  **Exploratory Data Analysis:**
    *   Statistical comparison of features between epitopes and non-epitopes.
    *   Analysis of sequence motifs (tripeptide frequencies, sequence logos).
4.  **Modeling:**
    *   **Baseline Model:** Random Forest (RF) classifier trained on physicochemical features *including* `netMHCpan` binding affinity scores (`Score_BA`).
    *   **Sequence-Based Model:** Convolutional Neural Network (CNN) trained *directly* on one-hot encoded peptide sequences.
5.  **Model Evaluation & Interpretation:**
    *   Standard classification metrics (Accuracy, Precision, Recall, F1-score, Confusion Matrix).
    *   Feature importance analysis for the RF model (with and without `Score_BA`).
    *   Saliency map analysis (single and aggregated) for the CNN model to identify influential sequence positions.

## Key Findings (Summary)

*   Predicted binding affinity (`Score_BA` from `netMHCpan`) is a dominant predictor for the Random Forest model. The model's performance drops significantly without it, especially its recall for true epitopes (from ~75% to ~18%).
*   The CNN model, learning directly from sequence, achieves better balanced performance (82% accuracy, 65% epitope recall) than the RF model *without* the binding affinity feature, demonstrating its ability to capture relevant sequence patterns.
*   Sequence motif analysis (tripeptides, logos) and CNN saliency maps suggest certain positional preferences, particularly a strong influence of the C-terminal residue (position 8) in distinguishing epitopes, and potentially position 1 for non-epitopes. Leucine-rich motifs appear more prevalent in epitopes.

## Directory Structure

```
capstone/
├── .venv/               # Virtual environment directory
├── data/                # Raw and processed data files (.csv)
├── doc/                 # Quarto document source (blog.qmd) and references
├── results/             # (Optional) Saved model files, detailed results
├── src/                 # (Optional) Source code for helper functions/modules
├── .gitignore
├── binding_affinity_prediction.py # Script to run NetMHCpan
├── best_cnn_model_len9.keras # Saved CNN model (from blog.qmd)
├── capstone.html        # Rendered HTML report (from blog.qmd)
├── capstone.ipynb       # (Potentially older version or scratchpad)
├── capstone.pdf         # Rendered PDF report (if generated)
├── environment.yml      # Conda environment file (may be outdated)
├── fetch_full_seq.ipynb # Notebook for fetching sequences
├── README.md            # This file
├── requirements.txt     # Python package dependencies
└── visualize_predictions.py # Script to visualize prediction results
```

## Setup and Installation

1.  **Clone the Repository:**
    ```bash
    git clone <repository_url>
    cd capstone
    ```
2.  **Python Environment:** It is highly recommended to use a virtual environment.
    *   **Using `venv`:**
        ```bash
        python -m venv .venv
        # Activate the environment (use appropriate command for your OS/shell)
        # e.g., source .venv/bin/activate (Linux/macOS) or .\.venv\Scripts\activate (Windows)
        ```
    *   **Using Conda:** (If `environment.yml` is preferred/up-to-date)
        ```bash
        conda env create -f environment.yml
        conda activate <your_env_name>
        ```
3.  **Install Dependencies:** Use UV (recommended) or pip.
    ```bash
    uv pip install -r requirements.txt
    # or
    # pip install -r requirements.txt
    ```
    *Note: Ensure `logomaker` and `tensorflow` are included for the full analysis in `blog.qmd`.*
4.  **Install `netMHCpan`:** This tool needs to be installed separately following instructions from its source (DTU Health Tech). The `binding_affinity_prediction.py` script uses this. Update the path in the script or provide it via the `--netmhcpan` argument if necessary. Ensure the script (`run_netMHCpan.sh` or equivalent) is executable.
5.  **Quarto:** Ensure you have Quarto installed to render the main report. See [quarto.org](https://quarto.org/).

## How to Run

1.  **Generate Binding Predictions (if needed):**
    *   The analysis in `blog.qmd` loads pre-computed binding affinity scores from CSV files (e.g., `ninemer_epitopes_BA_pred.csv`).
    *   To regenerate these predictions, ensure your input peptide/allele data is ready (e.g., in `data/peptides_for_prediction.csv`).
    *   Run the prediction script, adjusting paths as needed:
        ```bash
        python ./binding_affinity_prediction.py --input data/peptides_for_prediction.csv --output data/predictions_output.csv --netmhcpan /path/to/your/netMHCpan-4.1/run_netMHCpan.sh
        ```
    *   *Note: This requires a functional `netMHCpan` installation.*
2.  **Render the Report:**
    *   Open a terminal in the project root directory (`capstone/`).
    *   Activate your Python environment.
    *   Render the Quarto document:
        ```bash
        quarto render doc/blog.qmd
        ```
    *   This will execute the code cells within the document (unless marked `eval: false`) and generate `doc/blog.html`. The `.qmd` is currently set up to load most data from pre-existing CSVs.

## Report

The main analysis, results, and discussion are presented in the Quarto document:
*   Source: `doc/blog.qmd`
*   Rendered HTML: `doc/blog.html`
