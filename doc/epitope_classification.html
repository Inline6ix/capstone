<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tariq Alagha">

<title>Cancer T-Cell Epitope Classification</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="epitope_classification_files/libs/clipboard/clipboard.min.js"></script>
<script src="epitope_classification_files/libs/quarto-html/quarto.js"></script>
<script src="epitope_classification_files/libs/quarto-html/popper.min.js"></script>
<script src="epitope_classification_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="epitope_classification_files/libs/quarto-html/anchor.min.js"></script>
<link href="epitope_classification_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="epitope_classification_files/libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="epitope_classification_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="epitope_classification_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="epitope_classification_files/libs/bootstrap/bootstrap-973236bd072d72a04ee9cd82dcc9cb29.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data">Data</a>
  <ul class="collapse">
  <li><a href="#dataset" id="toc-dataset" class="nav-link" data-scroll-target="#dataset">Dataset</a></li>
  <li><a href="#preprocessing" id="toc-preprocessing" class="nav-link" data-scroll-target="#preprocessing">Preprocessing</a></li>
  <li><a href="#mhc-allele-distribution" id="toc-mhc-allele-distribution" class="nav-link" data-scroll-target="#mhc-allele-distribution">MHC Allele Distribution</a></li>
  <li><a href="#negative-sample-generation" id="toc-negative-sample-generation" class="nav-link" data-scroll-target="#negative-sample-generation">Negative Sample Generation</a></li>
  <li><a href="#feature-engineering" id="toc-feature-engineering" class="nav-link" data-scroll-target="#feature-engineering">Feature Engineering</a></li>
  </ul></li>
  <li><a href="#what-distinguishes-an-epitope-from-any-other-peptide" id="toc-what-distinguishes-an-epitope-from-any-other-peptide" class="nav-link" data-scroll-target="#what-distinguishes-an-epitope-from-any-other-peptide">What Distinguishes an epitope from any other peptide?</a>
  <ul class="collapse">
  <li><a href="#statistical-comparison" id="toc-statistical-comparison" class="nav-link" data-scroll-target="#statistical-comparison">Statistical Comparison</a></li>
  <li><a href="#sequence-motifs" id="toc-sequence-motifs" class="nav-link" data-scroll-target="#sequence-motifs">Sequence Motifs</a></li>
  </ul></li>
  <li><a href="#can-we-predict" id="toc-can-we-predict" class="nav-link" data-scroll-target="#can-we-predict">Can we predict?</a>
  <ul class="collapse">
  <li><a href="#model-selection-a-baseline-with-state-of-the-art-binding-prediction" id="toc-model-selection-a-baseline-with-state-of-the-art-binding-prediction" class="nav-link" data-scroll-target="#model-selection-a-baseline-with-state-of-the-art-binding-prediction">Model Selection: A Baseline with State-of-the-Art Binding Prediction</a></li>
  <li><a href="#preprocessing-1" id="toc-preprocessing-1" class="nav-link" data-scroll-target="#preprocessing-1">Preprocessing</a></li>
  <li><a href="#training-evaluation" id="toc-training-evaluation" class="nav-link" data-scroll-target="#training-evaluation">Training + Evaluation</a></li>
  <li><a href="#quantifying-the-impact-of-binding-affinity-prediction" id="toc-quantifying-the-impact-of-binding-affinity-prediction" class="nav-link" data-scroll-target="#quantifying-the-impact-of-binding-affinity-prediction">Quantifying the Impact of Binding Affinity Prediction</a></li>
  <li><a href="#a-different-approach-learning-directly-from-sequence-with-cnns" id="toc-a-different-approach-learning-directly-from-sequence-with-cnns" class="nav-link" data-scroll-target="#a-different-approach-learning-directly-from-sequence-with-cnns">A Different Approach: Learning Directly from Sequence with CNNs</a></li>
  <li><a href="#what-did-the-cnn-learn" id="toc-what-did-the-cnn-learn" class="nav-link" data-scroll-target="#what-did-the-cnn-learn">What did the CNN learn?</a></li>
  <li><a href="#what-about-the-whole-dataset" id="toc-what-about-the-whole-dataset" class="nav-link" data-scroll-target="#what-about-the-whole-dataset">What about the whole dataset?</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Cancer T-Cell Epitope Classification</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
<p class="subtitle lead">Identifying key target antigens for cancer immunotherapy</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Tariq Alagha </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.cell.com/cms/10.1016/j.ccell.2022.08.003/asset/eb36c8cd-3880-4d48-8a8b-f10accd01fba/main.assets/fx1_lrg.jpg" class="img-fluid figure-img" style="width:50.0%" alt="End to end personalized peptide vaccine cancer treatment"></p>
<figcaption><span class="citation" data-cites="AWAD20221010">Awad et al. (<a href="#ref-AWAD20221010" role="doc-biblioref">2022</a>)</span></figcaption>
</figure>
</div>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>At the heart of immune defense are tiny molecular “flags” called epitopes. These short sequences of amino acids, like “ADVEFCLSL”, sit on larger proteins and tell immune cells whether something is a threat. When an immune cell recognizes an epitope on a virus or a cancer cell, it can launch a protective attack.</p>
<p>Being able to reliably identify these epitopes in creating new vaccines and cancer treatments is crucial. Think of epitopes as the precise handshake between the immune system and a threat. Finding the right ones means smarter therapies can be designed. Unlike older treatments like chemotherapy that harm healthy cells, therapies targeting specific epitopes can attack diseases with more accuracy. This promises better results for patients, with fewer debilitating side effects.</p>
<p>This project is all about teaching computers to do this vital identification work. Machine learning models are being built and tested that can look at an amino acid sequence and its properties and decide if it’s an epitope or not. By making this process faster and more accurate, the discovery of new vaccine and immunotherapy candidates can be sped up, ultimately leading to more effective and kinder treatments.</p>
</section>
<section id="data" class="level1">
<h1>Data</h1>
<section id="dataset" class="level3">
<h3 class="anchored" data-anchor-id="dataset">Dataset</h3>
<p>To train these models, the main source is the <a href="https://www.iedb.org/">Immune Epitope Database</a>(IEDB), the largest public library of knowledge about how the immune system sees and reacts to epitopes on different molecules. It tells which sequences are known to be recognized by T-cells or antibodies.</p>
<p>For this project, the focus has been put on epitopes found on human cancer cells that have been proven in experiments to activate T-cell immune defenses. For each epitope, its unique amino acid sequence and the specific MHC allele it interacts with will be used.</p>
<p>Importantly, to train a good model, it doesn’t just need to learn what an epitope is; it also needs to learn what it isn’t. Many epitope records in the IEDB link to the full protein they come from. These full proteins are used to carefully select sequences that are not currently known epitopes. This provides a set of epitope and non-epitope examples.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Libraries and packages">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Libraries and packages
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<div id="f5c071c3" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Importing libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> Bio</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> Bio <span class="im">import</span> SeqIO</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> Bio.SeqUtils.ProtParam <span class="im">import</span> ProteinAnalysis</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> io <span class="im">import</span> StringIO</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logomaker</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> (</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    accuracy_score, auc, average_precision_score, classification_report,</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.utils.class_weight <span class="im">import</span> compute_class_weight</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> metrics</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.callbacks <span class="im">import</span> EarlyStopping, ModelCheckpoint, ReduceLROnPlateau</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> (</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input, BatchNormalization</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Model</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.optimizers <span class="im">import</span> Adam</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.regularizers <span class="im">import</span> l2</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> (</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    classification_report, confusion_matrix, roc_curve, auc,</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    precision_recall_curve, average_precision_score, accuracy_score</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
</div>
</section>
<section id="preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="preprocessing">Preprocessing</h3>
<p>Retrieving the data from IEDB was as simple as doing a search and clicking export. Using the requests python library, the full antigen sequence was downloaded and appended to the epitope dataset. Next, simple formatting was done to standardize the column names. Finally, the epitope dataset was merged with the assays dataset and filtered to include the following columns:</p>
<div id="887a4c36" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.read_csv(<span class="vs">r'/Users/tariq/Documents/capstone/data/epitope_table_export_1740279588.csv'</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>assays <span class="op">=</span> pd.read_csv(<span class="vs">r'/Users/tariq/Documents/capstone/data/tcell_table_export_1740279970.csv'</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fetch_full_sequence(url):</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.notna(url):  <span class="co"># Check if the URL is not NaN</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        url <span class="op">=</span> <span class="ss">f'</span><span class="sc">{</span>url<span class="sc">}</span><span class="ss">.fasta'</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>            response <span class="op">=</span> requests.get(url)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> response.status_code <span class="op">==</span> <span class="dv">200</span>:</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>                fasta_io <span class="op">=</span> StringIO(response.text)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>                records <span class="op">=</span> <span class="bu">list</span>(SeqIO.parse(fasta_io, <span class="st">"fasta"</span>))</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> records:  <span class="co"># Check if there are any records</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">return</span> <span class="bu">str</span>(records[<span class="dv">0</span>].seq)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="st">"No records found in the FASTA file."</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> requests.exceptions.RequestException <span class="im">as</span> e:</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Request failed: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="co">#epitopes['Full Sequence'] = epitopes['Epitope - Molecule Parent IRI'].apply(fetch_full_sequence)</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.read_csv(<span class="vs">r'/Users/tariq/Documents/capstone/data/epitope_full_seq.csv'</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="co"># make all column names snake case</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.lower()</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.lower()</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="co"># remove spaces from column names</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">''</span>)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.replace(<span class="st">'-'</span>, <span class="st">' '</span>)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">'_'</span>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">''</span>)</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.replace(<span class="st">'-'</span>, <span class="st">' '</span>)</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">'_'</span>)</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.<span class="bu">filter</span>([<span class="st">'epitope_name'</span>, <span class="st">'fullsequence'</span>])</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>assays <span class="op">=</span> assays.<span class="bu">filter</span>([<span class="st">'epitope_name'</span>, <span class="st">'epitope_moluculeparent'</span>, <span class="st">'host_name'</span>, <span class="st">'host_mhcpresent'</span>, <span class="st">'assay_method'</span>,<span class="st">'assay_responsemeasured'</span>, <span class="st">'assay_qualitativemeasurement'</span>, <span class="st">'mhcrestriction_name'</span>, <span class="st">'mhcrestriction_class'</span>, <span class="st">'assayantigen_name'</span>])</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a><span class="co"># map mhc name and class from the assays dataframe to a new column in the epitopes dataframe based on epitope_name</span></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>mhc <span class="op">=</span> assays.<span class="bu">filter</span>([<span class="st">'epitope_name'</span>, <span class="st">'mhcrestriction_name'</span>, <span class="st">'mhcrestriction_class'</span>])</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>mhc <span class="op">=</span> mhc.drop_duplicates(subset<span class="op">=</span>[<span class="st">'epitope_name'</span>])</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.merge(mhc, on<span class="op">=</span><span class="st">'epitope_name'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>epitopes.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="21">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">epitope_name</th>
<th data-quarto-table-cell-role="th">fullsequence</th>
<th data-quarto-table-cell-role="th">mhcrestriction_name</th>
<th data-quarto-table-cell-role="th">mhcrestriction_class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>AAGIGILTV</td>
<td>MPREDAHFIYGYPKKGHGHSYTTAEEAAGIGILTVILGVLLLIGCW...</td>
<td>HLA-A2</td>
<td>I</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>AAGIGILTVI</td>
<td>MPREDAHFIYGYPKKGHGHSYTTAEEAAGIGILTVILGVLLLIGCW...</td>
<td>HLA-A*02:01</td>
<td>I</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>ACDPHSGHFV</td>
<td>NaN</td>
<td>HLA-A2</td>
<td>I</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>ADLVGFLLLK</td>
<td>MSLEQRSLHCKPEEALEAQQEALGLVCVQAATSSSSPLVLGTLEEV...</td>
<td>HLA-A*11:01</td>
<td>I</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>ADVEFCLSL</td>
<td>MLLAVLYCLLWSFQTSAGHFPRACVSSKNLMEKECCPPWSGDRSPC...</td>
<td>HLA-B*44:03</td>
<td>I</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="mhc-allele-distribution" class="level3">
<h3 class="anchored" data-anchor-id="mhc-allele-distribution">MHC Allele Distribution</h3>
<p>It’s important to understand the distribution of MHC alleles associated with the epitopes in our dataset, as MHC molecules are responsible for presenting these peptides to T-cells. A skewed distribution could influence later analysis and create bias towards more represented alleles.</p>
<div id="cell-fig-mhc-dist" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming 'epitopes' DataFrame with 'mhcrestriction_name' column is available</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># from the previous preprocessing cell.</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Count MHC allele frequencies, dropping any NaNs first</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>mhc_counts <span class="op">=</span> epitopes[<span class="st">'mhcrestriction_name'</span>].dropna().value_counts()</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Select top N for visualization</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">20</span> <span class="co"># Show the top 20 alleles</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>top_mhc_counts <span class="op">=</span> mhc_counts.head(N)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span>top_mhc_counts.values, y<span class="op">=</span>top_mhc_counts.index, palette<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f'Top </span><span class="sc">{</span>N<span class="sc">}</span><span class="ss"> Most Frequent MHC Alleles in Epitope Dataset'</span>)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Frequency (Number of Epitopes)'</span>)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'MHC Allele'</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Optionally, print some stats for context</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Total unique alleles found: {len(mhc_counts)}")</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="co"># print("Top 5 allele counts:\n", top_mhc_counts.head())</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-mhc-dist" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mhc-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="epitope_classification_files/figure-html/fig-mhc-dist-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mhc-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Top 20 Most Frequent MHC Alleles in Epitope Dataset
</figcaption>
</figure>
</div>
</div>
</div>
<p>The plot reveals a skew in the MHC allele distribution within the initial epitope dataset. The allele <strong>HLA-A*02:01</strong> is much more common compared to all others. This skew towards HLA-A*02:01, is critical to acknowledge. It implies that later analyses and models might be heavily influenced by, or perform best on, peptides presented by this specific allele.</p>
</section>
<section id="negative-sample-generation" class="level3">
<h3 class="anchored" data-anchor-id="negative-sample-generation">Negative Sample Generation</h3>
<div id="035a2cc2" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_negatives(row):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    epitope <span class="op">=</span> row[<span class="st">"epitope_name"</span>]</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    full_seq <span class="op">=</span> row[<span class="st">"fullsequence"</span>]</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    mhc <span class="op">=</span> row[<span class="st">"mhcrestriction_name"</span>]</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle missing or empty sequences</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.isnull(full_seq) <span class="kw">or</span> full_seq <span class="op">==</span> <span class="st">""</span>:</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> []</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    epitope <span class="op">=</span> <span class="bu">str</span>(epitope)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    full_seq <span class="op">=</span> <span class="bu">str</span>(full_seq)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    ep_len <span class="op">=</span> <span class="bu">len</span>(epitope)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    negatives <span class="op">=</span> []</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(full_seq) <span class="op">-</span> ep_len <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        window <span class="op">=</span> full_seq[i:i<span class="op">+</span>ep_len]</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> window <span class="op">!=</span> epitope:</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>            negatives.append({<span class="st">"peptide"</span>: window, <span class="st">"mhc"</span>: mhc})</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> negatives</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to each row</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> pd.DataFrame()</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'negatives'</span>] <span class="op">=</span> epitopes.<span class="bu">apply</span>(generate_negatives, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives[[<span class="st">"negatives"</span>]].explode(<span class="st">"negatives"</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>negatives.dropna(subset<span class="op">=</span>[<span class="st">"negatives"</span>], inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove duplicates</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Shape before removing duplicates: </span><span class="sc">{</span>negatives<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.drop_duplicates(subset<span class="op">=</span>[<span class="st">'negatives'</span>])</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Shape after removing duplicates: </span><span class="sc">{</span>negatives<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for any remaining NaN values</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of NaN values in negatives: </span><span class="sc">{</span>negatives[<span class="st">'negatives'</span>]<span class="sc">.</span>isna()<span class="sc">.</span><span class="bu">sum</span>()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract peptide and mhc into separate columns</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'peptide'</span>] <span class="op">=</span> negatives[<span class="st">'negatives'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x[<span class="st">'peptide'</span>])</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'mhc'</span>] <span class="op">=</span> negatives[<span class="st">'negatives'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x[<span class="st">'mhc'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Although the IEDB database provided a substantial amount of epitopes, in order to draw visual comparisons and create models to classify epitopes, samples of non-epitope peptides are needed. These can be generated by shuffling and sampling amino acid sequences from the full antigen sequences of the epitopes, ensuring that the sampled sequences did not overlap with the epitope sequences.</p>
<p>There are pros and cons to this methodology. As opposed to generating completely random sequences of amino acids — sampling from larger sequences allows for natural patterns and physiochemical motifs to be retained. That is not to say the performance of statistical models or qualitative analysis will be better. Random sequences are more likely to be highly irregular, or even biologically implausible. Sampling from the full antigen sequences eliminates this potential bias.</p>
<p>Conversely, it is possible for a randomly sampled peptide to be an epitope that has not been tested yet, or simply isn’t in the subset of data used for this analysis — resulting in an increase in the number of false negatives in our data.</p>
</section>
<section id="feature-engineering" class="level3">
<h3 class="anchored" data-anchor-id="feature-engineering">Feature Engineering</h3>
<div id="68ea5f40" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Kyte-Doolittle hydrophobicity scale</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>kyte_doolittle <span class="op">=</span> {</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'I'</span>: <span class="fl">4.5</span>, <span class="st">'V'</span>: <span class="fl">4.2</span>, <span class="st">'L'</span>: <span class="fl">3.8</span>, <span class="st">'F'</span>: <span class="fl">2.8</span>, <span class="st">'C'</span>: <span class="fl">2.5</span>,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'M'</span>: <span class="fl">1.9</span>, <span class="st">'A'</span>: <span class="fl">1.8</span>, <span class="st">'G'</span>: <span class="op">-</span><span class="fl">0.4</span>, <span class="st">'T'</span>: <span class="op">-</span><span class="fl">0.7</span>, <span class="st">'S'</span>: <span class="op">-</span><span class="fl">0.8</span>,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'W'</span>: <span class="op">-</span><span class="fl">0.9</span>, <span class="st">'Y'</span>: <span class="op">-</span><span class="fl">1.3</span>, <span class="st">'P'</span>: <span class="op">-</span><span class="fl">1.6</span>, <span class="st">'H'</span>: <span class="op">-</span><span class="fl">3.2</span>, <span class="st">'E'</span>: <span class="op">-</span><span class="fl">3.5</span>,</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Q'</span>: <span class="op">-</span><span class="fl">3.5</span>, <span class="st">'D'</span>: <span class="op">-</span><span class="fl">3.5</span>, <span class="st">'N'</span>: <span class="op">-</span><span class="fl">3.5</span>, <span class="st">'K'</span>: <span class="op">-</span><span class="fl">3.9</span>, <span class="st">'R'</span>: <span class="op">-</span><span class="fl">4.5</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_avg_hydrophobicity(peptide):</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get hydrophobicity scores for each amino acid; default to 0 if missing</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> [kyte_doolittle.get(aa, <span class="dv">0</span>) <span class="cf">for</span> aa <span class="kw">in</span> peptide]</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">sum</span>(scores) <span class="op">/</span> <span class="bu">len</span>(scores) <span class="cf">if</span> scores <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to the 'peptide' column to create a new column 'avg_hydro'</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'epitope_avg_hydro'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(compute_avg_hydrophobicity)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the molecular_weight function from Bio.SeqUtils</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_molecular_weight(peptide):</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the molecular weight of a peptide sequence using Biopython."""</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.molecular_weight()</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'molecular_weight'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_molecular_weight)</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_aromaticity(peptide):</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the aromaticity of a peptide sequence using Biopython."""</span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.aromaticity()</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'aromaticity'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_aromaticity)</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_isoelectric_point(peptide):</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the isoelectric point of a peptide sequence using Biopython."""</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.isoelectric_point()</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'isoelectric_point'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_isoelectric_point)</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_instability(peptide):</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the instability of a peptide sequence using Biopython."""</span></span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.instability_index()</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'instability'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_instability)</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_charge_at_pH7(peptide):</span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the charge of a peptide sequence at pH 7 using Biopython."""</span></span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.charge_at_pH(<span class="dv">7</span>)</span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'charge_at_pH7'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_charge_at_pH7)</span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate features on the peptide column</span></span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'peptide_length'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(<span class="bu">len</span>)</span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'peptide_avg_hydro'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(compute_avg_hydrophobicity)</span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'molecular_weight'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_molecular_weight)</span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'aromaticity'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_aromaticity)</span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'isoelectric_point'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_isoelectric_point)</span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'instability'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_instability)</span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'charge_at_pH7'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_charge_at_pH7)</span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a>negatives.drop(<span class="st">'negatives'</span>, axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The protein analysis tool from the BioPython package allows for some quick feature engineering on most given peptides. For this analysis, the relevant features would be hydrophobicity, molecular weight, aromaticity, isoelectric point, instability, and the charge at pH7. Publications on epitope classification hold binding affinity — the ability for a peptide to bind to the body’s MHC complex — to be a strong preditctor. The BioPython package does not come with any functionality for binding affinity prediction but IEDB provides a tool called <strong>netMHCpan</strong>, which is the leading binding affinity prediction algorithm.</p>
<p>The IEDB website offers a GUI for using netMHCpan to predict binding affinities. However, it is only possible to run predictions on 100 peptides at a time and this analysis is examining many more than that. NetMHCpan can be downloaded and installed as a command line tool allowing more flexibility using python. Given an amino acid sequence and an MHC allele specification, netMHCpan returns a binding affinity score. This score ranges from 0 to 1, where higher values indicate a stronger likelihood of binding.</p>
<p>Subsequent analysis filters for 9-mer peptides, a common length for MHC Class I epitopes, for which binding prediction tools like netMHCpan are well-suited. After feature engineering, we have:</p>
<div id="d5be1d11" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generated using the standalone netMHCpan tool with relevant MHC alleles for each peptide</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.read_csv(<span class="st">"/Users/tariq/Documents/capstone/data/ninemer_epitopes.csv"</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.drop(columns<span class="op">=</span>[<span class="st">'fullsequence'</span>, <span class="st">'mhcrestriction_name'</span>, <span class="st">'mhcrestriction_class'</span>, <span class="st">'epitope_length'</span>])</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.rename(columns<span class="op">=</span>{<span class="st">'epitope_name'</span>: <span class="st">'peptide'</span>, <span class="st">'epitope_avg_hydro'</span>: <span class="st">'peptide_avg_hydro'</span>})</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>epitopes_BA_pred <span class="op">=</span> pd.read_csv(<span class="st">"/Users/tariq/Documents/capstone/data/ninemer_epitopes_BA_pred.csv"</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> pd.read_csv(<span class="st">"/Users/tariq/Documents/capstone/data/ninemer_negatives_trimmed.csv"</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.drop(columns<span class="op">=</span>[<span class="st">'mhc'</span>, <span class="st">'peptide_length'</span>])</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.rename(columns<span class="op">=</span>{<span class="st">'peptide'</span>: <span class="st">'peptide'</span>})</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.drop_duplicates(subset<span class="op">=</span>[<span class="st">'peptide'</span>])</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>negatives_BA_pred <span class="op">=</span> pd.read_csv(<span class="st">"/Users/tariq/Documents/capstone/data/ninemer_negatives_trimmed_BA_pred.csv"</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>negatives_BA_pred <span class="op">=</span> negatives_BA_pred.drop_duplicates(subset<span class="op">=</span>[<span class="st">'peptide'</span>])</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge the 'Score_BA' column from epitopes_BA_pred into the epitopes dataframe</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.merge(epitopes, epitopes_BA_pred[[<span class="st">'peptide'</span>, <span class="st">'Score_BA'</span>]], on<span class="op">=</span><span class="st">'peptide'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> pd.merge(negatives, negatives_BA_pred[[<span class="st">'peptide'</span>, <span class="st">'Score_BA'</span>]], on<span class="op">=</span><span class="st">'peptide'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>epitopes.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="23">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">peptide</th>
<th data-quarto-table-cell-role="th">peptide_avg_hydro</th>
<th data-quarto-table-cell-role="th">molecular_weight</th>
<th data-quarto-table-cell-role="th">aromaticity</th>
<th data-quarto-table-cell-role="th">isoelectric_point</th>
<th data-quarto-table-cell-role="th">instability</th>
<th data-quarto-table-cell-role="th">charge_at_pH7</th>
<th data-quarto-table-cell-role="th">Score_BA</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>AAGIGILTV</td>
<td>2.122222</td>
<td>813.9814</td>
<td>0.000000</td>
<td>5.570017</td>
<td>11.422222</td>
<td>-0.204125</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>ADVEFCLSL</td>
<td>1.233333</td>
<td>996.1348</td>
<td>0.111111</td>
<td>4.050028</td>
<td>20.855556</td>
<td>-2.210095</td>
<td>0.190368</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>AFLPWHRLF</td>
<td>0.533333</td>
<td>1186.4061</td>
<td>0.333333</td>
<td>9.800371</td>
<td>53.400000</td>
<td>0.883039</td>
<td>0.677877</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>ALAETSYVK</td>
<td>0.155556</td>
<td>981.1004</td>
<td>0.111111</td>
<td>6.045191</td>
<td>5.688889</td>
<td>-0.203313</td>
<td>0.652230</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>ALDVYNGLL</td>
<td>0.966667</td>
<td>977.1115</td>
<td>0.111111</td>
<td>4.050028</td>
<td>-16.188889</td>
<td>-1.204004</td>
<td>0.493034</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
<section id="what-distinguishes-an-epitope-from-any-other-peptide" class="level1">
<h1>What Distinguishes an epitope from any other peptide?</h1>
<section id="statistical-comparison" class="level3">
<h3 class="anchored" data-anchor-id="statistical-comparison">Statistical Comparison</h3>
<div id="cell-fig-stat-compare" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare numeric features between epitopes and negatives datasets</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>numeric_features <span class="op">=</span> [<span class="st">'peptide_avg_hydro'</span>, <span class="st">'molecular_weight'</span>, <span class="st">'aromaticity'</span>, </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'isoelectric_point'</span>, <span class="st">'instability'</span>, <span class="st">'charge_at_pH7'</span>, <span class="st">'Score_BA'</span>]</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a figure with subplots for each numeric feature</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="bu">len</span>(numeric_features), <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span><span class="op">*</span><span class="bu">len</span>(numeric_features)))</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co">#fig.tight_layout(pad=5.0)</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot density plots for each feature</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, feature <span class="kw">in</span> <span class="bu">enumerate</span>(numeric_features):</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> axes[i]</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create density plot for Epitopes</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    sns.kdeplot(epitopes[feature].dropna(), ax<span class="op">=</span>ax, label<span class="op">=</span><span class="st">'Epitopes'</span>, fill<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create density plot for Negatives</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    sns.kdeplot(negatives[feature].dropna(), ax<span class="op">=</span>ax, label<span class="op">=</span><span class="st">'Negatives'</span>, fill<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add feature statistics</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    epitope_mean <span class="op">=</span> epitopes[feature].mean()</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    negative_mean <span class="op">=</span> negatives[feature].mean()</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'</span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss"> Density Plot Comparison'</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    ax.text(<span class="fl">0.02</span>, <span class="fl">0.95</span>, <span class="ss">f'Epitopes mean: </span><span class="sc">{</span>epitope_mean<span class="sc">:.4f}</span><span class="ss">'</span>, transform<span class="op">=</span>ax.transAxes)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    ax.text(<span class="fl">0.02</span>, <span class="fl">0.90</span>, <span class="ss">f'Negatives mean: </span><span class="sc">{</span>negative_mean<span class="sc">:.4f}</span><span class="ss">'</span>, transform<span class="op">=</span>ax.transAxes)</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    ax.legend()</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add p-value from t-test</span></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    t_stat, p_value <span class="op">=</span> stats.ttest_ind(</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>        epitopes[feature].dropna(), </span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>        negatives[feature].dropna(),</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        equal_var<span class="op">=</span><span class="va">False</span>  <span class="co"># Welch's t-test (doesn't assume equal variances)</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">#ax.text(0.02, 0.85, f'p-value: {p_value:.4e}', transform=ax.transAxes)</span></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.suptitle('Comparison of Numeric Features Between Epitopes and Negatives', fontsize=16)</span></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-stat-compare" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-stat-compare-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="epitope_classification_files/figure-html/fig-stat-compare-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-stat-compare-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Density Plot Comparison of Numeric Features between Epitopes and Negatives
</figcaption>
</figure>
</div>
</div>
</div>
<p>A boxplot comparison of the numerical variables reveals hardly significant differences between the epitope and non-epitope peptides. The clear outlier being the predicted binding affinity score.</p>
<div id="cell-fig-ba-hist" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot Score_BA for epitopes and negatives overlaid on the same plot</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Use density instead of raw counts to normalize the histograms</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>plt.hist(epitopes[<span class="st">'Score_BA'</span>], bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'blue'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Epitopes'</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>plt.hist(negatives[<span class="st">'Score_BA'</span>], bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'red'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, </span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Negatives'</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternative approach: use log scale for y-axis</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>plt.yscale(<span class="st">'log'</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Binding Affinity'</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density (log scale)'</span>)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Normalized Histogram of Binding Affinity for Epitopes vs Negatives'</span>)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>plt.legend(prop<span class="op">=</span>{<span class="st">'size'</span>: <span class="dv">14</span>})  <span class="co"># Increased legend font size</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-ba-hist" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ba-hist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="epitope_classification_files/figure-html/fig-ba-hist-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ba-hist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Normalized Histogram of Binding Affinity Scores
</figcaption>
</figure>
</div>
</div>
</div>
<p>Upon further inspection of the difference in predicted binding affinity score, we see the non-epitope peptides exhibit a right-skewed distribution with a mean of 0.07, and the epitopes show a broad, moderate-variance spread with a much higher mean of 0.56.</p>
</section>
<section id="sequence-motifs" class="level3">
<h3 class="anchored" data-anchor-id="sequence-motifs">Sequence Motifs</h3>
<p>While the predicted binding affinity score is a strong predictor of epitope classification, it is not the only feature that distinguishes an epitope from a non-epitope. To further understand the differences between the two classes, we can look for patterns in the amino acid sequences.</p>
<p>One way to explore these patterns is to examine the frequency of short amino acid motifs, such as tripeptides. By comparing the most frequent tripeptides in known epitopes versus non-epitope sequences, we might identify motifs that are enriched in one class or the other.</p>
<div id="cell-fig-tripeptide" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create temporary copies of epitopes and negatives, then add 'label' column for this analysis</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Assumes 'epitopes' and 'negatives' DataFrames (without 'label' yet) are available from prior cells</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>temp_epitopes_for_motifs <span class="op">=</span> epitopes.copy()</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>temp_negatives_for_motifs <span class="op">=</span> negatives.copy()</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>temp_epitopes_for_motifs[<span class="st">'label'</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>temp_negatives_for_motifs[<span class="st">'label'</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Now proceed with the lines you uncommented, using these temporary DataFrames</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>epitopes_filtered <span class="op">=</span> temp_epitopes_for_motifs[[<span class="st">'peptide'</span>, <span class="st">'label'</span>]].copy()</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>epitopes_filtered.rename(columns<span class="op">=</span>{<span class="st">'peptide'</span>: <span class="st">'sequence'</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>negatives_filtered <span class="op">=</span> temp_negatives_for_motifs[[<span class="st">'peptide'</span>, <span class="st">'label'</span>]].copy()</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>negatives_filtered.rename(columns<span class="op">=</span>{<span class="st">'peptide'</span>: <span class="st">'sequence'</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Use a specific name for this combined_data to avoid conflict</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>combined_data_for_tripeptides <span class="op">=</span> pd.concat([epitopes_filtered, negatives_filtered], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_tripeptides(sequence):</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Extracts all overlapping tripeptides from a sequence."""</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [sequence[i:i<span class="op">+</span><span class="dv">3</span>] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(sequence) <span class="op">-</span> <span class="dv">2</span>)]</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Separate epitope and non-epitope sequences</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>epitope_sequences <span class="op">=</span> combined_data_for_tripeptides[combined_data_for_tripeptides[<span class="st">'label'</span>] <span class="op">==</span> <span class="dv">1</span>][<span class="st">'sequence'</span>].tolist()</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>non_epitope_sequences <span class="op">=</span> combined_data_for_tripeptides[combined_data_for_tripeptides[<span class="st">'label'</span>] <span class="op">==</span> <span class="dv">0</span>][<span class="st">'sequence'</span>].tolist()</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Get all tripeptides for epitopes</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>all_epitope_tripeptides <span class="op">=</span> []</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> seq <span class="kw">in</span> epitope_sequences:</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>    all_epitope_tripeptides.extend(get_tripeptides(seq))</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Get all tripeptides for non-epitopes</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>all_non_epitope_tripeptides <span class="op">=</span> []</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> seq <span class="kw">in</span> non_epitope_sequences:</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>    all_non_epitope_tripeptides.extend(get_tripeptides(seq))</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Count frequencies</span></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>epitope_tripeptide_counts <span class="op">=</span> Counter(all_epitope_tripeptides)</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>non_epitope_tripeptide_counts <span class="op">=</span> Counter(all_non_epitope_tripeptides)</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Get top N most common tripeptides</span></span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>top_epitope_tripeptides <span class="op">=</span> epitope_tripeptide_counts.most_common(N)</span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>top_non_epitope_tripeptides <span class="op">=</span> non_epitope_tripeptide_counts.most_common(N)</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting</span></span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">10</span>))</span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Epitope tripeptides</span></span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> top_epitope_tripeptides:</span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>    peptides, counts <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>top_epitope_tripeptides)</span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].bar(peptides, counts, color<span class="op">=</span><span class="st">'skyblue'</span>)</span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_title(<span class="ss">f'Top </span><span class="sc">{</span>N<span class="sc">}</span><span class="ss"> Most Frequent Tripeptides in Epitopes'</span>)</span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].text(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="st">'No tripeptides found for epitopes'</span>, horizontalalignment<span class="op">=</span><span class="st">'center'</span>, verticalalignment<span class="op">=</span><span class="st">'center'</span>, transform<span class="op">=</span>axes[<span class="dv">0</span>].transAxes)</span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Non-epitope tripeptides</span></span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> top_non_epitope_tripeptides:</span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a>    peptides, counts <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>top_non_epitope_tripeptides)</span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].bar(peptides, counts, color<span class="op">=</span><span class="st">'lightcoral'</span>)</span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_title(<span class="ss">f'Top </span><span class="sc">{</span>N<span class="sc">}</span><span class="ss"> Most Frequent Tripeptides in Non-Epitopes'</span>)</span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Tripeptide'</span>)</span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].text(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="st">'No tripeptides found for non-epitopes'</span>, horizontalalignment<span class="op">=</span><span class="st">'center'</span>, verticalalignment<span class="op">=</span><span class="st">'center'</span>, transform<span class="op">=</span>axes[<span class="dv">1</span>].transAxes)</span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-tripeptide" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tripeptide-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="epitope_classification_files/figure-html/fig-tripeptide-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tripeptide-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Top 15 Most Frequent Tripeptides in Epitope vs.&nbsp;Non-Epitope Sequences
</figcaption>
</figure>
</div>
</div>
</div>
<p>These plots show the most common tripeptide sequences found within the epitope and non-epitope datasets. Comparing these can help identify if certain short amino acid patterns are more prevalent in one group over the other, potentially hinting at structural or functional differences recognized by the immune system or affecting MHC binding.</p>
<p>Interpreting the tripeptide frequency plots:</p>
<ul>
<li><strong>Epitopes:</strong> The tripeptide <code>LLL</code> is dominant, with Leucine-rich sequences being prevalent.</li>
<li><strong>Non-Epitopes:</strong> <code>SSS</code> is the most frequent. While <code>LLL</code> is also common, this group shows more diversity with prominent Serine, Proline (<code>PPP</code>), and Glycine-based motifs (e.g., <code>GGS</code>).</li>
</ul>
<p>The most frequent tripeptides differ significantly between epitopes and non-epitopes. Epitopes favor Leucine-based motifs, while non-epitopes have a broader range with <code>SSS</code> leading. This suggests that these short sequence patterns contribute to distinguishing the two.</p>
<p>Another powerful way to visualize conserved patterns in a set of sequences is by generating sequence logos. Each position in the logo consists of a stack of letters, where the height of each letter indicates its frequency at that position.</p>
<div id="cell-fig-seqlogo" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming 'combined_data_for_tripeptides' DataFrame with 'sequence' and 'label' columns is available</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># from the previous tripeptide analysis cell.</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Standard 20 amino acids</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>amino_acids <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">list</span>(<span class="st">"ACDEFGHIKLMNPQRSTVWY"</span>))</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>sequence_length <span class="op">=</span> <span class="dv">9</span> <span class="co"># Assuming all sequences are 9-mers</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>epitope_sequences_for_logo <span class="op">=</span> combined_data_for_tripeptides[combined_data_for_tripeptides[<span class="st">'label'</span>] <span class="op">==</span> <span class="dv">1</span>][<span class="st">'sequence'</span>].tolist()</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>non_epitope_sequences_for_logo <span class="op">=</span> combined_data_for_tripeptides[combined_data_for_tripeptides[<span class="st">'label'</span>] <span class="op">==</span> <span class="dv">0</span>][<span class="st">'sequence'</span>].tolist()</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_ppm_from_sequences(sequences, amino_acids_list, seq_len):</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> sequences:</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> pd.DataFrame(<span class="fl">0.0</span>, index<span class="op">=</span>amino_acids_list, columns<span class="op">=</span><span class="bu">range</span>(seq_len))</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    pfm <span class="op">=</span> pd.DataFrame(<span class="dv">0</span>, index<span class="op">=</span>amino_acids_list, columns<span class="op">=</span><span class="bu">range</span>(seq_len))</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> seq <span class="kw">in</span> sequences:</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(seq) <span class="op">==</span> seq_len: <span class="co"># Ensure sequence has expected length</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i, char <span class="kw">in</span> <span class="bu">enumerate</span>(seq):</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> char <span class="kw">in</span> amino_acids_list: <span class="co"># Ensure character is a standard amino acid</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>                    pfm.loc[char, i] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert PFM to PPM (Position Probability Matrix)</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>    ppm <span class="op">=</span> pfm.div(<span class="bu">len</span>(sequences), axis<span class="op">=</span><span class="st">'columns'</span>)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ppm</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Create PPM for epitopes</span></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>ppm_epitopes <span class="op">=</span> create_ppm_from_sequences(epitope_sequences_for_logo, amino_acids, sequence_length)</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Create PPM for non-epitopes</span></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>ppm_non_epitopes <span class="op">=</span> create_ppm_from_sequences(non_epitope_sequences_for_logo, amino_acids, sequence_length)</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate and display sequence logos</span></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Epitope Logo</span></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> ppm_epitopes.empty <span class="kw">and</span> ppm_epitopes.<span class="bu">sum</span>().<span class="bu">sum</span>() <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transpose the PPM DataFrame for logomaker</span></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>    logomaker.Logo(ppm_epitopes.T, ax<span class="op">=</span>axes[<span class="dv">0</span>], font_name<span class="op">=</span><span class="st">'Arial Rounded MT Bold'</span>)</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_title(<span class="st">'Sequence Logo for Epitopes'</span>)</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Bits'</span>) <span class="co"># Typically, height is in bits of information</span></span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].text(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="st">'No data or empty PPM for epitope logo'</span>, horizontalalignment<span class="op">=</span><span class="st">'center'</span>, verticalalignment<span class="op">=</span><span class="st">'center'</span>, transform<span class="op">=</span>axes[<span class="dv">0</span>].transAxes)</span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Non-Epitope Logo</span></span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> ppm_non_epitopes.empty <span class="kw">and</span> ppm_non_epitopes.<span class="bu">sum</span>().<span class="bu">sum</span>() <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transpose the PPM DataFrame for logomaker</span></span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a>    logomaker.Logo(ppm_non_epitopes.T, ax<span class="op">=</span>axes[<span class="dv">1</span>], font_name<span class="op">=</span><span class="st">'Arial Rounded MT Bold'</span>)</span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_title(<span class="st">'Sequence Logo for Non-Epitopes'</span>)</span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Position'</span>)</span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Bits'</span>)</span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].text(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="st">'No data or empty PPM for non-epitope logo'</span>, horizontalalignment<span class="op">=</span><span class="st">'center'</span>, verticalalignment<span class="op">=</span><span class="st">'center'</span>, transform<span class="op">=</span>axes[<span class="dv">1</span>].transAxes)</span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-seqlogo" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-seqlogo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="epitope_classification_files/figure-html/fig-seqlogo-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-seqlogo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Sequence Logos for Epitope vs.&nbsp;Non-Epitope Sequences
</figcaption>
</figure>
</div>
</div>
</div>
<p>These sequence logos visually represent the amino acid frequencies at each of the 9 positions for epitopes and non-epitopes. Bigger letters indicate a higher frequency of that amino acid at that specific position.</p>
<p>Interpreting the sequence logos:</p>
<ul>
<li><strong>Epitope Logo:</strong> While showing variability, there’s a noticeable preference for Leucine at the position 8 and also a tendency for <code>L</code> at position 1. Other positions show a mix of amino acids with generally lower conservation, though residues like Serine, Lysine, and Valine appear at various spots.</li>
<li><strong>Non-Epitope Logo:</strong> This logo generally shows more diversity across all positions. While Leucine and Serine are common, no single amino acid dominates at most positions. The position 8preference for <code>L</code> seen in epitopes is less pronounced here.</li>
</ul>
</section>
</section>
<section id="can-we-predict" class="level1">
<h1>Can we predict?</h1>
<section id="model-selection-a-baseline-with-state-of-the-art-binding-prediction" class="level3">
<h3 class="anchored" data-anchor-id="model-selection-a-baseline-with-state-of-the-art-binding-prediction">Model Selection: A Baseline with State-of-the-Art Binding Prediction</h3>
<p>To establish a baseline, we first develop a Random Forest classifier. This model incorporates a unique feature: predicted binding affinity scores (<code>Score_BA</code>) derived from <code>netMHCpan</code>, a state-of-the-art algorithm for MHC binding prediction. By including this, our baseline leverages existing sophisticated domain knowledge. The full feature set includes:</p>
<ul>
<li>Average Hydrophobicity</li>
<li>Molecular Weight</li>
<li>Aromaticity</li>
<li>Isoelectric Point</li>
<li>Instability</li>
<li>Charge at pH7</li>
</ul>
<p>Performace will be evaluated based on accuracy, precision, and recall.</p>
</section>
<section id="preprocessing-1" class="level3">
<h3 class="anchored" data-anchor-id="preprocessing-1">Preprocessing</h3>
<p>Prior to training, labels are assigned to the epitopes and non-epitopes as 1 or 0 respectively. The two samples are then concatenated, scaled, and shuffled. Finally, the data is split into training and testing sets with an 80/20 ratio.</p>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add label column to epitopes dataframe (positive class = 1)</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'label'</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Add label column to negatives dataframe (negative class = 0)</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'label'</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine the positive and negative examples</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> pd.concat([epitopes, negatives], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Shuffle the combined dataset</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> combined_data.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Define features and target</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> combined_data.drop(columns<span class="op">=</span>[<span class="st">'peptide'</span>, <span class="st">'label'</span>])</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> combined_data[<span class="st">'label'</span>]</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify numerical columns to scale (exclude one-hot encoded amino acid columns)</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>numerical_cols <span class="op">=</span> [<span class="st">'peptide_avg_hydro'</span>, <span class="st">'molecular_weight'</span>, <span class="st">'aromaticity'</span>, <span class="st">'isoelectric_point'</span>, <span class="st">'instability'</span>]</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets (80% train, 20% test)</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Scale numerical features using StandardScaler</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>X_train[numerical_cols] <span class="op">=</span> scaler.fit_transform(X_train[numerical_cols])</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>X_test[numerical_cols] <span class="op">=</span> scaler.transform(X_test[numerical_cols])</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the shapes to verify the split</span></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training set: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Testing set: </span><span class="sc">{</span>X_test<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in training: </span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in training: </span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in testing: </span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in testing: </span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-cm-rf" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="11">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cm-rf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-stdout">
<pre><code>Training set: 20502 samples
Testing set: 5126 samples
Positive samples in training: 4236
Negative samples in training: 16266
Positive samples in testing: 1059
Negative samples in testing: 4067</code></pre>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-cm-rf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6
</figcaption>
</figure>
</div>
</section>
<section id="training-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="training-evaluation">Training + Evaluation</h3>
<p>The random forest classifier is fit to the training data and evaluated on the testing data.</p>
<div id="cell-fig-cm-rf-ba" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Random Forest Classifier</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,  <span class="co"># Number of trees</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="va">None</span>,    <span class="co"># Maximum depth of trees</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X_train, y_train)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> rf_model.predict(X_test)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> rf_model.predict_proba(X_test)[:, <span class="dv">1</span>]  <span class="co"># Probability estimates for positive class</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Confusion Matrix</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, </span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>[<span class="st">'Predicted Negative'</span>, <span class="st">'Predicted Positive'</span>], </span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>            yticklabels<span class="op">=</span>[<span class="st">'Actual Negative'</span>, <span class="st">'Actual Positive'</span>])</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Label'</span>)</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Label'</span>)</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix - Random Forest'</span>)</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Random Forest Model Classification Report:"</span>)</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-cm-rf-ba" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cm-rf-ba-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="epitope_classification_files/figure-html/fig-cm-rf-ba-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cm-rf-ba-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Confusion Matrix for Random Forest with Binding Affinity
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Random Forest Model Classification Report:
              precision    recall  f1-score   support

           0       0.93      0.96      0.95      4067
           1       0.82      0.74      0.78      1059

    accuracy                           0.91      5126
   macro avg       0.88      0.85      0.86      5126
weighted avg       0.91      0.91      0.91      5126
</code></pre>
</div>
</div>
<p>The results show strong performance from the random forest classifier, with an overall accuracy of 91% and recall of 75% for the positive class. This strong performance is due to the powerful <code>Score_BA</code> predictor from <code>netMHCpan</code>.</p>
<div id="cell-Fig-1" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature importance</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> pd.DataFrame({</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: X_train.columns,</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: rf_model.feature_importances_</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> feature_importance.sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot top 15 features</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>top_features <span class="op">=</span> feature_importance.head(<span class="dv">15</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>plt.barh(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Importance'</span>], align<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>plt.yticks(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Feature'</span>])</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Importance'</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Feature Importance - Random Forest'</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="epitope_classification_files/figure-html/fig-1-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Feature Importance for Random Forest with Binding Affinity
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="quantifying-the-impact-of-binding-affinity-prediction" class="level3">
<h3 class="anchored" data-anchor-id="quantifying-the-impact-of-binding-affinity-prediction">Quantifying the Impact of Binding Affinity Prediction</h3>
<p>To highlight the significant contribution of the <code>netMHCpan</code> prediction of binding affinity, we next evaluate the Random Forest model without the <code>Score_BA</code> feature. This helps quantify the performance drop when relying solely on other physiochemical properties without this advanced binding prediction.</p>
<div id="cell-fig-cm-rf-noba" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># drop the Score_BA column</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train.drop(columns<span class="op">=</span>[<span class="st">'Score_BA'</span>])</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X_test.drop(columns<span class="op">=</span>[<span class="st">'Score_BA'</span>])</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Random Forest Classifier</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,  <span class="co"># Number of trees</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="va">None</span>,    <span class="co"># Maximum depth of trees</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X_train, y_train)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> rf_model.predict(X_test)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> rf_model.predict_proba(X_test)[:, <span class="dv">1</span>]  <span class="co"># Probability estimates for positive class</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Confusion Matrix</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, </span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>[<span class="st">'Predicted Negative'</span>, <span class="st">'Predicted Positive'</span>], </span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>            yticklabels<span class="op">=</span>[<span class="st">'Actual Negative'</span>, <span class="st">'Actual Positive'</span>])</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Label'</span>)</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Label'</span>)</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix - Random Forest'</span>)</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classification Report:"</span>)</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-cm-rf-noba" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cm-rf-noba-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="epitope_classification_files/figure-html/fig-cm-rf-noba-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cm-rf-noba-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Confusion Matrix for Random Forest without Binding Affinity
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.95      0.88      4067
           1       0.47      0.18      0.26      1059

    accuracy                           0.79      5126
   macro avg       0.64      0.57      0.57      5126
weighted avg       0.75      0.79      0.75      5126
</code></pre>
</div>
</div>
<p>The accuracy only drops from 91% to 79%. However, this is misleading when considering the class imbalance of the data. The ratio of negative samples to positive is roughly 4:1, respectively. So, predicting the majority class — non-epitope — almost everytime would result in the majority of the testing data being correctly predicted and labeled.</p>
<p>A better performance metric to compare between models would be the model’s recall rate on the positive class. How many of the epitopes in the testing data were correctly predicted and labeled? The same model, when predicted binding affinity was included as a predictor, produced a 74% recall rate while the current model has a much lower 18% recall rate. This dramatic drop in recall for epitopes clearly demonstrates the model’s dependence on the <code>netMHCpan</code> binding affinity scores for identifying true positives.</p>
<div id="cell-Fig-2" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature importance</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> pd.DataFrame({</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: X_train.columns,</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: rf_model.feature_importances_</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> feature_importance.sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot top 15 features</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>top_features <span class="op">=</span> feature_importance.head(<span class="dv">15</span>)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>plt.barh(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Importance'</span>], align<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>plt.yticks(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Feature'</span>])</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Importance'</span>)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Feature Importance - Random Forest'</span>)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="epitope_classification_files/figure-html/fig-2-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Feature Importance for Random Forest without Binding Affinity
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="a-different-approach-learning-directly-from-sequence-with-cnns" class="level3">
<h3 class="anchored" data-anchor-id="a-different-approach-learning-directly-from-sequence-with-cnns">A Different Approach: Learning Directly from Sequence with CNNs</h3>
<p>Given the Random Forest model’s significant reliance on pre-computed binding affinity from <code>netMHCpan</code>, we explore an alternative strategy: a Convolutional Neural Network (CNN). The key value of the CNN in this context is its ability to learn predictive patterns directly from the raw amino acid sequences themselves. Unlike the RF model which uses engineered features and external predictions like <code>Score_BA</code>, the CNN can potentially uncover complex sequence motifs, positional tendencies, and other relevant features that may not be fully captured by binding affinity predictions alone. This approach allows the model to discover new features without feature engineering or reliance on separate binding prediction tools.</p>
<p>To start, the data will be filtered to only include the amino acid sequence and respective label.</p>
<div id="adc212ac" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter and combine</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>epitopes_filtered <span class="op">=</span> epitopes[[<span class="st">'peptide'</span>, <span class="st">'label'</span>]].copy()</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>epitopes_filtered.rename(columns<span class="op">=</span>{<span class="st">'peptide'</span>: <span class="st">'sequence'</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>negatives_filtered <span class="op">=</span> negatives[[<span class="st">'peptide'</span>, <span class="st">'label'</span>]].copy()</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>negatives_filtered.rename(columns<span class="op">=</span>{<span class="st">'peptide'</span>: <span class="st">'sequence'</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> pd.concat([epitopes_filtered, negatives_filtered], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Shuffle the validated data</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> combined_data.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>combined_data.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="33">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sequence</th>
<th data-quarto-table-cell-role="th">label</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>IENIWSPEG</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>PYQVPFVQA</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>FPEGLDPSA</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>LLFTDQHGL</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>DDRESWPSV</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>To train a neural network, the sequence must be represented in a numerical format. Assigning each amino acid a unique integer value up to 20, the sequences are converted to a list of integers. Then, the resulting integer sequences are one-hot encoded into a 3-dimensional arrary of shape (25628, 9, 20). 25,628 peptides, 9 amino acids in each peptide, 20 unique amino acids. The data is split into training, validation, and testing sets with a 70/15/15 ratio.</p>
<div id="c8b99a5c" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract sequences</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>all_sequences <span class="op">=</span> combined_data[<span class="st">'sequence'</span>].tolist()</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Find unique characters (amino acids) across all sequences</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>unique_chars <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">list</span>(<span class="bu">set</span>(<span class="st">""</span>.join(all_sequences))))</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Map characters to indices starting from 0 (no padding index needed)</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>char_to_index <span class="op">=</span> {char: i <span class="cf">for</span> i, char <span class="kw">in</span> <span class="bu">enumerate</span>(unique_chars)}</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>index_to_char <span class="op">=</span> {i: char <span class="cf">for</span> i, char <span class="kw">in</span> <span class="bu">enumerate</span>(unique_chars)}</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>num_chars <span class="op">=</span> <span class="bu">len</span>(unique_chars) <span class="co"># Vocabulary size is just the number of unique chars</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert sequences to integer sequences</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>int_sequences <span class="op">=</span> []</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> seq <span class="kw">in</span> all_sequences:</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>     int_seq <span class="op">=</span> [char_to_index[char] <span class="cf">for</span> char <span class="kw">in</span> seq]</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>     int_sequences.append(int_seq)</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a><span class="co"># One-hot encode the integer sequences</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Shape: (num_samples, sequence_length, num_unique_chars)</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming all sequences have length 9 as implied by the shape (9, num_chars)</span></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>sequence_length <span class="op">=</span> <span class="dv">9</span> <span class="co"># Explicitly define sequence length</span></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>X_onehot <span class="op">=</span> np.zeros((<span class="bu">len</span>(int_sequences), sequence_length, num_chars), dtype<span class="op">=</span>np.float32)</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, seq <span class="kw">in</span> <span class="bu">enumerate</span>(int_sequences):</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure sequence length matches expected length before encoding</span></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(seq) <span class="op">==</span> sequence_length:</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j, char_idx <span class="kw">in</span> <span class="bu">enumerate</span>(seq): <span class="co"># j is position (0-8), char_idx is the integer index of the amino acid</span></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>            X_onehot[i, j, char_idx] <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Warning: Sequence at index </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> has length </span><span class="sc">{</span><span class="bu">len</span>(seq)<span class="sc">}</span><span class="ss">, expected </span><span class="sc">{</span>sequence_length<span class="sc">}</span><span class="ss">. Skipping."</span>)</span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> combined_data[<span class="st">'label'</span>].values</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Data Splitting (70/15/15) ---</span></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--- Data Splitting ---"</span>)</span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Split into temp (85%) and test (15%)</span></span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>X_temp, X_test, y_temp, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a>    X_onehot, y, test_size<span class="op">=</span><span class="fl">0.15</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y</span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Split temp into train (70% of total) and validation (15% of total)</span></span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>val_split_ratio <span class="op">=</span> <span class="fl">0.15</span> <span class="op">/</span> <span class="fl">0.85</span> <span class="co"># Calculate split ratio for validation set</span></span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a>X_train, X_val, y_train, y_val <span class="op">=</span> train_test_split(</span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a>    X_temp, y_temp, test_size<span class="op">=</span>val_split_ratio, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y_temp</span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training set: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Validation set: </span><span class="sc">{</span>X_val<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Testing set: </span><span class="sc">{</span>X_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">30</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>--- Data Splitting ---
Training set: (17938, 9, 20)
Validation set: (3845, 9, 20)
Testing set: (3845, 9, 20)
------------------------------</code></pre>
</div>
</div>
<p>This CNN model processes one-hot encoded sequences using three 1D convolutional blocks (64, 128, 256 filters with BatchNormalization, MaxPooling, L2 regularization). Two subsequent dense blocks (256, 128 units with BatchNormalization, Dropout, L2 regularization, ReLU) follow. A final softmax layer outputs class probabilities. The model is compiled with Adam, sparse_categorical_crossentropy loss, and accuracy.</p>
<div id="117200c9" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_cnn_model(input_shape, num_classes<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Creates and compiles the CNN model."""</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> Input(shape<span class="op">=</span>input_shape)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv1D(<span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">8</span>, activation<span class="op">=</span><span class="st">'relu'</span>, padding<span class="op">=</span><span class="st">'same'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(inputs)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> MaxPooling1D(pool_size<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">'same'</span>)(x)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv1D(<span class="dv">128</span>, kernel_size<span class="op">=</span><span class="dv">8</span>, activation<span class="op">=</span><span class="st">'relu'</span>, padding<span class="op">=</span><span class="st">'same'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(x)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> MaxPooling1D(pool_size<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">'same'</span>)(x)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv1D(<span class="dv">256</span>, kernel_size<span class="op">=</span><span class="dv">8</span>, activation<span class="op">=</span><span class="st">'relu'</span>, padding<span class="op">=</span><span class="st">'same'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(x)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Flatten()(x)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">'relu'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(x)</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dropout(<span class="fl">0.5</span>)(x)</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">'relu'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(x)</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dropout(<span class="fl">0.4</span>)(x)</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> Dense(num_classes, activation<span class="op">=</span><span class="st">'softmax'</span>)(x)</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs)</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> Adam(learning_rate<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(optimizer<span class="op">=</span>optimizer,</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>                  loss<span class="op">=</span><span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>                  metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>input_shape <span class="op">=</span> (<span class="dv">9</span>, num_chars)</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> create_cnn_model(input_shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Before training the model, class weights are calculated to handle the data imbalance, effectively telling the model to “pay more attention” to samples from the minority class.</p>
<div id="cell-fig-cm-cnn" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.utils.class_weight <span class="im">import</span> compute_class_weight</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate class weights</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>class_weights <span class="op">=</span> compute_class_weight(<span class="st">'balanced'</span>, classes<span class="op">=</span>np.unique(y_train), y<span class="op">=</span>y_train)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>class_weight_dict <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">enumerate</span>(class_weights))</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Define callbacks</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>early_stopping <span class="op">=</span> EarlyStopping(monitor<span class="op">=</span><span class="st">'val_loss'</span>, patience<span class="op">=</span><span class="dv">10</span>, restore_best_weights<span class="op">=</span><span class="va">True</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>reduce_lr <span class="op">=</span> ReduceLROnPlateau(monitor<span class="op">=</span><span class="st">'val_loss'</span>, factor<span class="op">=</span><span class="fl">0.2</span>, patience<span class="op">=</span><span class="dv">5</span>, min_lr<span class="op">=</span><span class="fl">1e-6</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>model_checkpoint <span class="op">=</span> ModelCheckpoint(<span class="st">'best_cnn_model_len9.keras'</span>, monitor<span class="op">=</span><span class="st">'val_accuracy'</span>, save_best_only<span class="op">=</span><span class="va">True</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>    X_train, y_train,</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>    validation_data<span class="op">=</span>(X_val, y_val),</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>    callbacks<span class="op">=</span>[early_stopping, reduce_lr, model_checkpoint],</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>    class_weight<span class="op">=</span>class_weight_dict,</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> tf.keras.models.load_model(<span class="st">'best_cnn_model_len9.keras'</span>)</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate on test data</span></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>test_loss, test_accuracy <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Get prediction probabilities for the positive class</span></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> model.predict(X_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>y_pred_proba_positive <span class="op">=</span> y_pred_proba[:, <span class="dv">1</span>]</span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply fixed threshold of 0.5</span></span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> (y_pred_proba_positive <span class="op">&gt;=</span> <span class="fl">0.5</span>).astype(<span class="bu">int</span>)</span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Print classification report</span></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">CNN Classification Report:"</span>)</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate and plot confusion matrix</span></span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a>plt.imshow(cm, interpolation<span class="op">=</span><span class="st">'nearest'</span>, cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f'Confusion Matrix'</span>)</span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a>tick_marks <span class="op">=</span> np.arange(<span class="dv">2</span>)</span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>plt.xticks(tick_marks, [<span class="st">'Negative'</span>, <span class="st">'Positive'</span>])</span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a>plt.yticks(tick_marks, [<span class="st">'Negative'</span>, <span class="st">'Positive'</span>])</span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Label'</span>)</span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Label'</span>)</span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>thresh <span class="op">=</span> cm.<span class="bu">max</span>() <span class="op">/</span> <span class="fl">2.</span></span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(cm.shape[<span class="dv">0</span>]):</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(cm.shape[<span class="dv">1</span>]):</span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a>        plt.text(j, i, <span class="bu">format</span>(cm[i, j], <span class="st">'d'</span>),</span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a>                 horizontalalignment<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>                 color<span class="op">=</span><span class="st">"white"</span> <span class="cf">if</span> cm[i, j] <span class="op">&gt;</span> thresh <span class="cf">else</span> <span class="st">"black"</span>)</span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
CNN Classification Report:
              precision    recall  f1-score   support

           0       0.90      0.87      0.89      3051
           1       0.57      0.64      0.60       794

    accuracy                           0.83      3845
   macro avg       0.74      0.76      0.75      3845
weighted avg       0.84      0.83      0.83      3845
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div id="fig-cm-cnn" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cm-cnn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="epitope_classification_files/figure-html/fig-cm-cnn-output-2.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cm-cnn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: Confusion Matrix for CNN Model
</figcaption>
</figure>
</div>
</div>
</div>
<p>The Convolutional Neural Network produced a reasonable overall accuracy of 82%, primarily driven by its strong ability to correctly identify the majority, non-epitopes, with high precision and recall. However, its performance on the minority class, epitopes, was mixed; while managing to recall 65% of true epitopes, its precision was significantly lower at 56%, indicating that nearly half of its positive predictions were false positives.</p>
<p>The Convolutional Neural Network significantly outperforms the Random Forest classifier while relying only on the sequence data, and no additional features. The RF struggles with identifying the actual epitopes, shown by the low recall for Class 1, whereas the CNN, while still challenged with precision for Class 1, provides a better balance and significantly higher recall for the positive class, making it the more effective model in this comparison.</p>
</section>
<section id="what-did-the-cnn-learn" class="level3">
<h3 class="anchored" data-anchor-id="what-did-the-cnn-learn">What did the CNN learn?</h3>
<p>To better understand what the CNN model learned, we can generate saliency maps. A saliency map highlights which input features (amino acids at specific positions) were most influential in the model’s decision for a given input sample. This is done by calculating the gradient of the model’s output with respect to the input features.</p>
<p>The following plots examine a single sample sequence, <code>AASCFTASV</code>, which the model misclassified. The true label is Non-epitope, but the model predicted it as an Epitope with high confidence. The first map shows which features drove the incorrect prediction, and the second map shows which features would have been important for the correct classification.</p>
<div id="cell-fig-saliency-single" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure the model is loaded or available from previous cells</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co"># If not, load it:</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> tf.keras.models.load_model(<span class="st">'best_cnn_model_len9.keras'</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure X_test, y_test, and index_to_char are available from the 'sequence_encoding' cell</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Select a sample from the test set</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>sample_index <span class="op">=</span> <span class="dv">5</span> <span class="co"># You can change this to inspect different samples</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>sample_input <span class="op">=</span> X_test[sample_index:sample_index<span class="op">+</span><span class="dv">1</span>] <span class="co"># Keep batch dimension</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>sample_label <span class="op">=</span> y_test[sample_index]</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>true_class_index <span class="op">=</span> <span class="bu">int</span>(sample_label) <span class="co"># Ensure it's an integer for indexing</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the one-hot encoded sample back to a sequence for display</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>sample_sequence_onehot <span class="op">=</span> X_test[sample_index]</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>sample_amino_acid_indices <span class="op">=</span> np.argmax(sample_sequence_onehot, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>sample_sequence_str <span class="op">=</span> <span class="st">""</span>.join([index_to_char[idx] <span class="cf">for</span> idx <span class="kw">in</span> sample_amino_acid_indices])</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sample Sequence: </span><span class="sc">{</span>sample_sequence_str<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"True Label: </span><span class="sc">{</span><span class="st">'Epitope'</span> <span class="cf">if</span> sample_label <span class="op">==</span> <span class="dv">1</span> <span class="cf">else</span> <span class="st">'Non-epitope'</span><span class="sc">}</span><span class="ss"> (Class </span><span class="sc">{</span>sample_label<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a prediction to confirm</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>sample_pred_proba <span class="op">=</span> model.predict(sample_input, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>predicted_class <span class="op">=</span> np.argmax(sample_pred_proba[<span class="dv">0</span>])</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Predicted Label: </span><span class="sc">{</span><span class="st">'Epitope'</span> <span class="cf">if</span> predicted_class <span class="op">==</span> <span class="dv">1</span> <span class="cf">else</span> <span class="st">'Non-epitope'</span><span class="sc">}</span><span class="ss"> (Class </span><span class="sc">{</span>predicted_class<span class="sc">}</span><span class="ss">) with probability </span><span class="sc">{</span>sample_pred_proba[<span class="dv">0</span>][predicted_class]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert sample_input to tf.Tensor for gradient taping</span></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>sample_input_tf <span class="op">=</span> tf.convert_to_tensor(sample_input, dtype<span class="op">=</span>tf.float32)</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>    tape.watch(sample_input_tf)</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>    predictions_tensor <span class="op">=</span> model(sample_input_tf) <span class="co"># Get model output for current sample</span></span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>    predicted_class_idx <span class="op">=</span> tf.argmax(predictions_tensor, axis<span class="op">=</span><span class="dv">1</span>).numpy()[<span class="dv">0</span>] <span class="co"># Determine predicted class index</span></span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Using predicted class for saliency as per latest changes</span></span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>    output_neuron_to_explain <span class="op">=</span> predictions_tensor[:, predicted_class_idx]</span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the gradients of the output neuron with respect to the input</span></span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a>saliency_grads <span class="op">=</span> tape.gradient(output_neuron_to_explain, sample_input_tf)</span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a><span class="co"># saliency will have shape (1, 9, 20)</span></span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a><span class="co"># We take the absolute values and then sum across the one-hot encoding dimension</span></span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a><span class="co"># or take the max across the one-hot encoding for each position</span></span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a>saliency_map_per_position <span class="op">=</span> np.<span class="bu">sum</span>(np.<span class="bu">abs</span>(saliency_grads[<span class="dv">0</span>]), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a><span class="co">#saliency_map_per_position = np.max(np.abs(saliency_grads[0]), axis=1)</span></span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize the saliency map for visualization</span></span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a>saliency_map_normalized <span class="op">=</span> (saliency_map_per_position <span class="op">-</span> np.<span class="bu">min</span>(saliency_map_per_position)) <span class="op">/</span> (np.<span class="bu">max</span>(saliency_map_per_position) <span class="op">-</span> np.<span class="bu">min</span>(saliency_map_per_position) <span class="op">+</span> <span class="fl">1e-8</span>)</span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-52"><a href="#cb25-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the saliency map</span></span>
<span id="cb25-53"><a href="#cb25-53" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">4</span>))</span>
<span id="cb25-54"><a href="#cb25-54" aria-hidden="true" tabindex="-1"></a>plt.bar(<span class="bu">range</span>(<span class="bu">len</span>(sample_sequence_str)), saliency_map_normalized, color<span class="op">=</span><span class="st">'skyblue'</span>)</span>
<span id="cb25-55"><a href="#cb25-55" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(<span class="bu">len</span>(sample_sequence_str)), <span class="bu">list</span>(sample_sequence_str))</span>
<span id="cb25-56"><a href="#cb25-56" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Amino Acid Position"</span>)</span>
<span id="cb25-57"><a href="#cb25-57" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Normalized Saliency"</span>)</span>
<span id="cb25-58"><a href="#cb25-58" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Saliency Map for Sequence: </span><span class="sc">{</span>sample_sequence_str<span class="sc">}</span><span class="ss"> (Predicted: </span><span class="sc">{</span><span class="st">'Epitope'</span> <span class="cf">if</span> predicted_class <span class="op">==</span> <span class="dv">1</span> <span class="cf">else</span> <span class="st">'Non-epitope'</span><span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb25-59"><a href="#cb25-59" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb25-60"><a href="#cb25-60" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb25-61"><a href="#cb25-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-62"><a href="#cb25-62" aria-hidden="true" tabindex="-1"></a><span class="co"># You can also try visualizing the gradients for the actual true class if different</span></span>
<span id="cb25-63"><a href="#cb25-63" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> predicted_class <span class="op">!=</span> true_class_index:</span>
<span id="cb25-64"><a href="#cb25-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape_true:</span>
<span id="cb25-65"><a href="#cb25-65" aria-hidden="true" tabindex="-1"></a>        tape_true.watch(sample_input_tf)</span>
<span id="cb25-66"><a href="#cb25-66" aria-hidden="true" tabindex="-1"></a>        predictions_true <span class="op">=</span> model(sample_input_tf)</span>
<span id="cb25-67"><a href="#cb25-67" aria-hidden="true" tabindex="-1"></a>        output_neuron_true_class <span class="op">=</span> predictions_true[:, true_class_index]</span>
<span id="cb25-68"><a href="#cb25-68" aria-hidden="true" tabindex="-1"></a>    saliency_true <span class="op">=</span> tape_true.gradient(output_neuron_true_class, sample_input_tf)</span>
<span id="cb25-69"><a href="#cb25-69" aria-hidden="true" tabindex="-1"></a>    saliency_map_per_position_true <span class="op">=</span> np.<span class="bu">sum</span>(np.<span class="bu">abs</span>(saliency_true[<span class="dv">0</span>]), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb25-70"><a href="#cb25-70" aria-hidden="true" tabindex="-1"></a>    saliency_map_normalized_true <span class="op">=</span> (saliency_map_per_position_true <span class="op">-</span> np.<span class="bu">min</span>(saliency_map_per_position_true)) <span class="op">/</span> (np.<span class="bu">max</span>(saliency_map_per_position_true) <span class="op">-</span> np.<span class="bu">min</span>(saliency_map_per_position_true) <span class="op">+</span> <span class="fl">1e-8</span>)</span>
<span id="cb25-71"><a href="#cb25-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-72"><a href="#cb25-72" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">4</span>))</span>
<span id="cb25-73"><a href="#cb25-73" aria-hidden="true" tabindex="-1"></a>    plt.bar(<span class="bu">range</span>(<span class="bu">len</span>(sample_sequence_str)), saliency_map_normalized_true, color<span class="op">=</span><span class="st">'salmon'</span>)</span>
<span id="cb25-74"><a href="#cb25-74" aria-hidden="true" tabindex="-1"></a>    plt.xticks(<span class="bu">range</span>(<span class="bu">len</span>(sample_sequence_str)), <span class="bu">list</span>(sample_sequence_str))</span>
<span id="cb25-75"><a href="#cb25-75" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Amino Acid Position"</span>)</span>
<span id="cb25-76"><a href="#cb25-76" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Normalized Saliency (for True Class)"</span>)</span>
<span id="cb25-77"><a href="#cb25-77" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"Saliency Map for Sequence: </span><span class="sc">{</span>sample_sequence_str<span class="sc">}</span><span class="ss"> (Influence on True Class: </span><span class="sc">{</span><span class="st">'Epitope'</span> <span class="cf">if</span> true_class_index <span class="op">==</span> <span class="dv">1</span> <span class="cf">else</span> <span class="st">'Non-epitope'</span><span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb25-78"><a href="#cb25-78" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb25-79"><a href="#cb25-79" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Sample Sequence: DLSPDGPRS
True Label: Non-epitope (Class 0)
Predicted Label: Non-epitope (Class 0) with probability 0.9962</code></pre>
</div>
<div class="cell-output cell-output-display">
<div id="fig-saliency-single" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-saliency-single-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="epitope_classification_files/figure-html/fig-saliency-single-output-2.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-saliency-single-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12: Example Saliency Maps for a Misclassified Sample (AASCFTASV)
</figcaption>
</figure>
</div>
</div>
</div>
<p>For this specific misclassified sample (<code>AASCFTASV</code>):</p>
<ul>
<li><p>The model’s incorrect Epitope prediction was strongly influenced by the <code>C</code> at position 3, <code>A</code> at position 6, and <code>V</code> at position 8.</p></li>
<li><p>Interestingly, for the correct Non-epitope classification, the <code>C</code> at position 3 and <code>V</code> at position 8 also show high importance.</p></li>
</ul>
<p>This suggests these positions are decision points for the model for this sequence with conflicting signals leading to the misclassification.</p>
</section>
<section id="what-about-the-whole-dataset" class="level3">
<h3 class="anchored" data-anchor-id="what-about-the-whole-dataset">What about the whole dataset?</h3>
<p>To get a more general understanding of feature importance across the dataset, we can compute average saliency maps for different classes of samples. Below, we calculate and plot the average saliency map for true epitopes and true non-epitopes in the test set. The saliency is calculated with respect to the true class output for each sample. This helps to reveal general patterns the model has learned.</p>
<div id="cell-fig-saliency-agg" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure model, X_test, y_test, sequence_length, and num_chars are available</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="co"># model = tf.keras.models.load_model('best_cnn_model_len9.keras') # If not already loaded</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>num_samples_to_process <span class="op">=</span> <span class="bu">len</span>(X_test) <span class="co"># Or a smaller number for quicker testing, e.g., 100</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Accumulators for saliency maps and counts</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>saliency_accumulator_epitopes <span class="op">=</span> np.zeros(sequence_length)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>count_epitopes <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>saliency_accumulator_non_epitopes <span class="op">=</span> np.zeros(sequence_length)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>count_non_epitopes <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_samples_to_process):</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>    sample_input <span class="op">=</span> X_test[i:i<span class="op">+</span><span class="dv">1</span>] <span class="co"># Keep batch dimension</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>    true_label <span class="op">=</span> y_test[i]</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>    true_class_idx <span class="op">=</span> <span class="bu">int</span>(true_label)</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>    sample_input_tf <span class="op">=</span> tf.convert_to_tensor(sample_input, dtype<span class="op">=</span>tf.float32)</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>        tape.watch(sample_input_tf)</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>        predictions_tensor <span class="op">=</span> model(sample_input_tf) <span class="co"># Get model output for current sample</span></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Using true class for saliency</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>        output_neuron_to_explain <span class="op">=</span> predictions_tensor[:, true_class_idx]</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>    saliency_grads <span class="op">=</span> tape.gradient(output_neuron_to_explain, sample_input_tf)</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> saliency_grads <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Using np.max as per your previous preference</span></span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>        saliency_map_per_position <span class="op">=</span> np.<span class="bu">sum</span>(np.<span class="bu">abs</span>(saliency_grads[<span class="dv">0</span>].numpy()), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>        <span class="co">#saliency_map_per_position = np.max(np.abs(saliency_grads[0].numpy()), axis=1)</span></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> true_label <span class="op">==</span> <span class="dv">1</span>: <span class="co"># Epitope</span></span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>            saliency_accumulator_epitopes <span class="op">+=</span> saliency_map_per_position</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>            count_epitopes <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>: <span class="co"># Non-epitope</span></span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>            saliency_accumulator_non_epitopes <span class="op">+=</span> saliency_map_per_position</span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>            count_non_epitopes <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Warning: Gradients were None for sample </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">. Skipping."</span>)</span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (i <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(f"Processed {i+1}/{num_samples_to_process} samples...")</span></span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a><span class="co">#print("Aggregation complete.")</span></span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate average saliency maps</span></span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> count_epitopes <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a>    avg_saliency_epitopes <span class="op">=</span> saliency_accumulator_epitopes <span class="op">/</span> count_epitopes</span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a>    avg_saliency_epitopes_normalized <span class="op">=</span> (avg_saliency_epitopes <span class="op">-</span> np.<span class="bu">min</span>(avg_saliency_epitopes)) <span class="op">/</span> (np.<span class="bu">max</span>(avg_saliency_epitopes) <span class="op">-</span> np.<span class="bu">min</span>(avg_saliency_epitopes) <span class="op">+</span> <span class="fl">1e-8</span>)</span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a>    avg_saliency_epitopes_normalized <span class="op">=</span> <span class="va">None</span></span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"No epitope samples processed or found to calculate average saliency."</span>)</span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> count_non_epitopes <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb27-57"><a href="#cb27-57" aria-hidden="true" tabindex="-1"></a>    avg_saliency_non_epitopes <span class="op">=</span> saliency_accumulator_non_epitopes <span class="op">/</span> count_non_epitopes</span>
<span id="cb27-58"><a href="#cb27-58" aria-hidden="true" tabindex="-1"></a>    avg_saliency_non_epitopes_normalized <span class="op">=</span> (avg_saliency_non_epitopes <span class="op">-</span> np.<span class="bu">min</span>(avg_saliency_non_epitopes)) <span class="op">/</span> (np.<span class="bu">max</span>(avg_saliency_non_epitopes) <span class="op">-</span> np.<span class="bu">min</span>(avg_saliency_non_epitopes) <span class="op">+</span> <span class="fl">1e-8</span>)</span>
<span id="cb27-59"><a href="#cb27-59" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb27-60"><a href="#cb27-60" aria-hidden="true" tabindex="-1"></a>    avg_saliency_non_epitopes_normalized <span class="op">=</span> <span class="va">None</span></span>
<span id="cb27-61"><a href="#cb27-61" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"No non-epitope samples processed or found to calculate average saliency."</span>)</span>
<span id="cb27-62"><a href="#cb27-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-63"><a href="#cb27-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the average saliency maps</span></span>
<span id="cb27-64"><a href="#cb27-64" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>), sharex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb27-65"><a href="#cb27-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-66"><a href="#cb27-66" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> avg_saliency_epitopes_normalized <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb27-67"><a href="#cb27-67" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].bar(<span class="bu">range</span>(sequence_length), avg_saliency_epitopes_normalized, color<span class="op">=</span><span class="st">'lightcoral'</span>)</span>
<span id="cb27-68"><a href="#cb27-68" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].set_ylabel(<span class="st">"Normalized Saliency"</span>)</span>
<span id="cb27-69"><a href="#cb27-69" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].set_title(<span class="st">"Average Saliency Map for True Epitopes"</span>)</span>
<span id="cb27-70"><a href="#cb27-70" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].set_xticks(<span class="bu">range</span>(sequence_length))</span>
<span id="cb27-71"><a href="#cb27-71" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb27-72"><a href="#cb27-72" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].text(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="st">'No data for epitopes'</span>, horizontalalignment<span class="op">=</span><span class="st">'center'</span>, verticalalignment<span class="op">=</span><span class="st">'center'</span>, transform<span class="op">=</span>axs[<span class="dv">0</span>].transAxes)</span>
<span id="cb27-73"><a href="#cb27-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-74"><a href="#cb27-74" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> avg_saliency_non_epitopes_normalized <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb27-75"><a href="#cb27-75" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].bar(<span class="bu">range</span>(sequence_length), avg_saliency_non_epitopes_normalized, color<span class="op">=</span><span class="st">'skyblue'</span>)</span>
<span id="cb27-76"><a href="#cb27-76" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].set_xlabel(<span class="st">"Amino Acid Position"</span>)</span>
<span id="cb27-77"><a href="#cb27-77" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].set_ylabel(<span class="st">"Normalized Saliency"</span>)</span>
<span id="cb27-78"><a href="#cb27-78" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].set_title(<span class="st">"Average Saliency Map for True Non-Epitopes"</span>)</span>
<span id="cb27-79"><a href="#cb27-79" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].set_xticks(<span class="bu">range</span>(sequence_length))</span>
<span id="cb27-80"><a href="#cb27-80" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb27-81"><a href="#cb27-81" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].text(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="st">'No data for non-epitopes'</span>, horizontalalignment<span class="op">=</span><span class="st">'center'</span>, verticalalignment<span class="op">=</span><span class="st">'center'</span>, transform<span class="op">=</span>axs[<span class="dv">1</span>].transAxes)</span>
<span id="cb27-82"><a href="#cb27-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-83"><a href="#cb27-83" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb27-84"><a href="#cb27-84" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-saliency-agg" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-saliency-agg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="epitope_classification_files/figure-html/fig-saliency-agg-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-saliency-agg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13: Average Saliency Maps for True Epitopes and Non-Epitopes
</figcaption>
</figure>
</div>
</div>
</div>
<p>Interpreting the aggregated saliency maps:</p>
<ul>
<li><p><strong>Dominance of position 8:</strong> For both true epitopes and true non-epitopes, the amino acid at position 8 shows by far the highest average saliency. This indicates the model heavily relies on the identity of this final residue to make its classification.</p></li>
<li><p><strong>Importance of position 1 for non-epitopes:</strong> For true non-epitopes, the amino acid at position 1 also shows notably high average saliency, suggesting its importance in identifying a sequence as not an epitope.</p></li>
<li><p><strong>General pattern:</strong> The model appears to have learned that the C-terminal residue is a primary determinant, with other positions like position 1 playing secondary, but still significant, roles.</p></li>
</ul>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This project aimed to develop and evaluate computational models for classifying cancer T-cell epitopes, a necessary task for advancing personalized cancer treatment. By utilizing data from the Immune Epitope Database (IEDB) and employing feature engineering and machine learning techniques, we explored factors differentiating epitopes from non-epitope peptides derived from the same source proteins.</p>
<p>A Random Forest model incorporating predicted binding affinity scores from <code>netMHCpan</code> achieved high overall performance and reasonable recall for identifying true epitopes. However, removing this binding affinity feature caused a dramatic drop in the model’s ability to identify epitopes, indicating that standard physicochemical features alone, while descriptive, were insufficient for robust classification in this context.</p>
<p>Significantly, a Convolutional Neural Network (CNN) trained on one-hot encoded peptide sequences, without relying on external binding predictors or engineered features, demonstrated superior performance compared to the feature-based Random Forest without binding affinity. The CNN achieved balanced performance with better recall for the epitope class. This demonstrates the potential of deep learning models to capture patterns directly from sequence data.</p>
</section>
<section id="references" class="level1">

<!-- -->


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-AWAD20221010" class="csl-entry" role="listitem">
Awad, Mark M., Ramaswamy Govindan, Kristen N. Balogh, David R. Spigel, Edward B. Garon, Meghan E. Bushway, Asaf Poran, et al. 2022. <span>“Personalized Neoantigen Vaccine NEO-PV-01 with Chemotherapy and Anti-PD-1 as First-Line Treatment for Non-Squamous Non-Small Cell Lung Cancer.”</span> <em>Cancer Cell</em> 40 (9): 1010–1026.e11. <a href="https://doi.org/10.1016/j.ccell.2022.08.003">https://doi.org/10.1016/j.ccell.2022.08.003</a>.
</div>
<div id="ref-IEDB2025" class="csl-entry" role="listitem">
<span>“<span>Immune Epitope Database</span> (IEDB).”</span> 2025. <a href="https://www.iedb.org" class="uri">https://www.iedb.org</a>.
</div>
<div id="ref-Reynisson2020NetMHCpan41" class="csl-entry" role="listitem">
Reynisson, Birkir, Bruno Alvarez, Sinu Paul, Bjoern Peters, and Morten Nielsen. 2020. <span>“NetMHCpan‑4.1 and NetMHCIIpan‑4.0: Improved Predictions of MHC Antigen Presentation by Concurrent Motif Deconvolution and Integration of MS MHC Eluted Ligand Data.”</span> <em>Nucleic Acids Research</em> 48 (W1): W449–54. <a href="https://doi.org/10.1093/nar/gkaa379">https://doi.org/10.1093/nar/gkaa379</a>.
</div>
<div id="ref-UniProt2025" class="csl-entry" role="listitem">
The UniProt Consortium. 2025. <span>“<span>UniProt</span>: The Universal Protein Knowledgebase.”</span> <a href="https://www.uniprot.org" class="uri">https://www.uniprot.org</a>.
</div>
<div id="ref-Yarchoan2017" class="csl-entry" role="listitem">
Yarchoan, Mark, Burles A. Johnson, Eric R. Lutz, Daniel A. Laheru, and Elizabeth M. Jaffee. 2017. <span>“Targeting Neoantigens to Augment Antitumour Immunity.”</span> <em>Nature Reviews Cancer</em> 17 (4): 209–22. <a href="https://doi.org/10.1038/nrc.2016.154">https://doi.org/10.1038/nrc.2016.154</a>.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb28" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Cancer T-Cell Epitope Classification"</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Identifying key target antigens for cancer immunotherapy"</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Tariq Alagha"</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> references.bib</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="an">number-sections:</span><span class="co"> false</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="co">    theme: default</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="co">    rendering: embed-resources</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="an">editor:</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a><span class="co">  render-on-save: false</span></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a><span class="an">nocite:</span><span class="co"> |</span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a><span class="co">  @*</span></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a><span class="al">![@AWAD20221010](https://www.cell.com/cms/10.1016/j.ccell.2022.08.003/asset/eb36c8cd-3880-4d48-8a8b-f10accd01fba/main.assets/fx1_lrg.jpg)</span>{width="50%" fig-align="center" fig-alt="End to end personalized peptide vaccine cancer treatment"}</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introduction</span></span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>At the heart of immune defense are tiny molecular "flags" called epitopes. These short sequences of amino acids, like "ADVEFCLSL", sit on larger proteins and tell immune cells whether something is a threat. When an immune cell recognizes an epitope on a virus or a cancer cell, it can launch a protective attack.</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>Being able to reliably identify these epitopes in creating new vaccines and cancer treatments is crucial. Think of epitopes as the precise handshake between the immune system and a threat. Finding the right ones means smarter therapies can be designed. Unlike older treatments like chemotherapy that harm healthy cells, therapies targeting specific epitopes can attack diseases with more accuracy. This promises better results for patients, with fewer debilitating side effects.</span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>This project is all about teaching computers to do this vital identification work. Machine learning models are being built and tested that can look at an amino acid sequence and its properties and decide if it's an epitope or not. By making this process faster and more accurate, the discovery of new vaccine and immunotherapy candidates can be sped up, ultimately leading to more effective and kinder treatments.</span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a><span class="fu"># Data</span></span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a><span class="fu">### Dataset</span></span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a>To train these models, the main source is the <span class="co">[</span><span class="ot">Immune Epitope Database</span><span class="co">](https://www.iedb.org/)</span>(IEDB), the largest public library of knowledge about how the immune system sees and reacts to epitopes on different molecules. It tells which sequences are known to be recognized by T-cells or antibodies.</span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a>For this project, the focus has been put on epitopes found on human cancer cells that have been proven in experiments to activate T-cell immune defenses. For each epitope, its unique amino acid sequence and the specific MHC allele it interacts with will be used.</span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>Importantly, to train a good model, it doesn't just need to learn what an epitope is; it also needs to learn what it isn't. Many epitope records in the IEDB link to the full protein they come from. These full proteins are used to carefully select sequences that are not currently known epitopes. This provides a set of epitope and non-epitope examples.</span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Libraries and packages" collapse="false"}</span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a><span class="in">```{python q-collapse}</span></span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a><span class="in"># Importing libraries</span></span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a><span class="in">import pandas as pd</span></span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true" tabindex="-1"></a><span class="in">from collections import Counter</span></span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true" tabindex="-1"></a><span class="in">import matplotlib.pyplot as plt</span></span>
<span id="cb28-47"><a href="#cb28-47" aria-hidden="true" tabindex="-1"></a><span class="in">import seaborn as sns</span></span>
<span id="cb28-48"><a href="#cb28-48" aria-hidden="true" tabindex="-1"></a><span class="in">import numpy as np</span></span>
<span id="cb28-49"><a href="#cb28-49" aria-hidden="true" tabindex="-1"></a><span class="in">import Bio</span></span>
<span id="cb28-50"><a href="#cb28-50" aria-hidden="true" tabindex="-1"></a><span class="in">from Bio import SeqIO</span></span>
<span id="cb28-51"><a href="#cb28-51" aria-hidden="true" tabindex="-1"></a><span class="in">from Bio.SeqUtils.ProtParam import ProteinAnalysis</span></span>
<span id="cb28-52"><a href="#cb28-52" aria-hidden="true" tabindex="-1"></a><span class="in">from io import StringIO</span></span>
<span id="cb28-53"><a href="#cb28-53" aria-hidden="true" tabindex="-1"></a><span class="in">import logomaker</span></span>
<span id="cb28-54"><a href="#cb28-54" aria-hidden="true" tabindex="-1"></a><span class="in">import requests</span></span>
<span id="cb28-55"><a href="#cb28-55" aria-hidden="true" tabindex="-1"></a><span class="in">from scipy import stats</span></span>
<span id="cb28-56"><a href="#cb28-56" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.ensemble import RandomForestClassifier</span></span>
<span id="cb28-57"><a href="#cb28-57" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.metrics import (</span></span>
<span id="cb28-58"><a href="#cb28-58" aria-hidden="true" tabindex="-1"></a><span class="in">    accuracy_score, auc, average_precision_score, classification_report,</span></span>
<span id="cb28-59"><a href="#cb28-59" aria-hidden="true" tabindex="-1"></a><span class="in">    confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve</span></span>
<span id="cb28-60"><a href="#cb28-60" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb28-61"><a href="#cb28-61" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.model_selection import train_test_split</span></span>
<span id="cb28-62"><a href="#cb28-62" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.preprocessing import StandardScaler</span></span>
<span id="cb28-63"><a href="#cb28-63" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.utils.class_weight import compute_class_weight</span></span>
<span id="cb28-64"><a href="#cb28-64" aria-hidden="true" tabindex="-1"></a><span class="in">import tensorflow as tf</span></span>
<span id="cb28-65"><a href="#cb28-65" aria-hidden="true" tabindex="-1"></a><span class="in">from tensorflow.keras import metrics</span></span>
<span id="cb28-66"><a href="#cb28-66" aria-hidden="true" tabindex="-1"></a><span class="in">from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau</span></span>
<span id="cb28-67"><a href="#cb28-67" aria-hidden="true" tabindex="-1"></a><span class="in">from tensorflow.keras.layers import (</span></span>
<span id="cb28-68"><a href="#cb28-68" aria-hidden="true" tabindex="-1"></a><span class="in">    Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input, BatchNormalization</span></span>
<span id="cb28-69"><a href="#cb28-69" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb28-70"><a href="#cb28-70" aria-hidden="true" tabindex="-1"></a><span class="in">from tensorflow.keras.models import Model</span></span>
<span id="cb28-71"><a href="#cb28-71" aria-hidden="true" tabindex="-1"></a><span class="in">from tensorflow.keras.optimizers import Adam</span></span>
<span id="cb28-72"><a href="#cb28-72" aria-hidden="true" tabindex="-1"></a><span class="in">from tensorflow.keras.regularizers import l2</span></span>
<span id="cb28-73"><a href="#cb28-73" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.metrics import (</span></span>
<span id="cb28-74"><a href="#cb28-74" aria-hidden="true" tabindex="-1"></a><span class="in">    classification_report, confusion_matrix, roc_curve, auc,</span></span>
<span id="cb28-75"><a href="#cb28-75" aria-hidden="true" tabindex="-1"></a><span class="in">    precision_recall_curve, average_precision_score, accuracy_score</span></span>
<span id="cb28-76"><a href="#cb28-76" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb28-77"><a href="#cb28-77" aria-hidden="true" tabindex="-1"></a><span class="in">import matplotlib.pyplot as plt</span></span>
<span id="cb28-78"><a href="#cb28-78" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-79"><a href="#cb28-79" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb28-80"><a href="#cb28-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-81"><a href="#cb28-81" aria-hidden="true" tabindex="-1"></a><span class="fu">### Preprocessing</span></span>
<span id="cb28-82"><a href="#cb28-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-83"><a href="#cb28-83" aria-hidden="true" tabindex="-1"></a>Retrieving the data from IEDB was as simple as doing a search and clicking export. Using the requests python library, the full antigen sequence was downloaded and appended to the epitope dataset. Next, simple formatting was done to standardize the column names. Finally, the epitope dataset was merged with the assays dataset and filtered to include the following columns:</span>
<span id="cb28-84"><a href="#cb28-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-87"><a href="#cb28-87" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb28-88"><a href="#cb28-88" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb28-89"><a href="#cb28-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-90"><a href="#cb28-90" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.read_csv(<span class="vs">r'/Users/tariq/Documents/capstone/data/epitope_table_export_1740279588.csv'</span>)</span>
<span id="cb28-91"><a href="#cb28-91" aria-hidden="true" tabindex="-1"></a>assays <span class="op">=</span> pd.read_csv(<span class="vs">r'/Users/tariq/Documents/capstone/data/tcell_table_export_1740279970.csv'</span>)</span>
<span id="cb28-92"><a href="#cb28-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-93"><a href="#cb28-93" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fetch_full_sequence(url):</span>
<span id="cb28-94"><a href="#cb28-94" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.notna(url):  <span class="co"># Check if the URL is not NaN</span></span>
<span id="cb28-95"><a href="#cb28-95" aria-hidden="true" tabindex="-1"></a>        url <span class="op">=</span> <span class="ss">f'</span><span class="sc">{</span>url<span class="sc">}</span><span class="ss">.fasta'</span></span>
<span id="cb28-96"><a href="#cb28-96" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb28-97"><a href="#cb28-97" aria-hidden="true" tabindex="-1"></a>            response <span class="op">=</span> requests.get(url)</span>
<span id="cb28-98"><a href="#cb28-98" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> response.status_code <span class="op">==</span> <span class="dv">200</span>:</span>
<span id="cb28-99"><a href="#cb28-99" aria-hidden="true" tabindex="-1"></a>                fasta_io <span class="op">=</span> StringIO(response.text)</span>
<span id="cb28-100"><a href="#cb28-100" aria-hidden="true" tabindex="-1"></a>                records <span class="op">=</span> <span class="bu">list</span>(SeqIO.parse(fasta_io, <span class="st">"fasta"</span>))</span>
<span id="cb28-101"><a href="#cb28-101" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> records:  <span class="co"># Check if there are any records</span></span>
<span id="cb28-102"><a href="#cb28-102" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">return</span> <span class="bu">str</span>(records[<span class="dv">0</span>].seq)</span>
<span id="cb28-103"><a href="#cb28-103" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb28-104"><a href="#cb28-104" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="st">"No records found in the FASTA file."</span>)</span>
<span id="cb28-105"><a href="#cb28-105" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> requests.exceptions.RequestException <span class="im">as</span> e:</span>
<span id="cb28-106"><a href="#cb28-106" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Request failed: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb28-107"><a href="#cb28-107" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb28-108"><a href="#cb28-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-109"><a href="#cb28-109" aria-hidden="true" tabindex="-1"></a><span class="co">#epitopes['Full Sequence'] = epitopes['Epitope - Molecule Parent IRI'].apply(fetch_full_sequence)</span></span>
<span id="cb28-110"><a href="#cb28-110" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.read_csv(<span class="vs">r'/Users/tariq/Documents/capstone/data/epitope_full_seq.csv'</span>)</span>
<span id="cb28-111"><a href="#cb28-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-112"><a href="#cb28-112" aria-hidden="true" tabindex="-1"></a><span class="co"># make all column names snake case</span></span>
<span id="cb28-113"><a href="#cb28-113" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.lower()</span>
<span id="cb28-114"><a href="#cb28-114" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.lower()</span>
<span id="cb28-115"><a href="#cb28-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-116"><a href="#cb28-116" aria-hidden="true" tabindex="-1"></a><span class="co"># remove spaces from column names</span></span>
<span id="cb28-117"><a href="#cb28-117" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">''</span>)</span>
<span id="cb28-118"><a href="#cb28-118" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.replace(<span class="st">'-'</span>, <span class="st">' '</span>)</span>
<span id="cb28-119"><a href="#cb28-119" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">'_'</span>)</span>
<span id="cb28-120"><a href="#cb28-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-121"><a href="#cb28-121" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">''</span>)</span>
<span id="cb28-122"><a href="#cb28-122" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.replace(<span class="st">'-'</span>, <span class="st">' '</span>)</span>
<span id="cb28-123"><a href="#cb28-123" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">'_'</span>)</span>
<span id="cb28-124"><a href="#cb28-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-125"><a href="#cb28-125" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.<span class="bu">filter</span>([<span class="st">'epitope_name'</span>, <span class="st">'fullsequence'</span>])</span>
<span id="cb28-126"><a href="#cb28-126" aria-hidden="true" tabindex="-1"></a>assays <span class="op">=</span> assays.<span class="bu">filter</span>([<span class="st">'epitope_name'</span>, <span class="st">'epitope_moluculeparent'</span>, <span class="st">'host_name'</span>, <span class="st">'host_mhcpresent'</span>, <span class="st">'assay_method'</span>,<span class="st">'assay_responsemeasured'</span>, <span class="st">'assay_qualitativemeasurement'</span>, <span class="st">'mhcrestriction_name'</span>, <span class="st">'mhcrestriction_class'</span>, <span class="st">'assayantigen_name'</span>])</span>
<span id="cb28-127"><a href="#cb28-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-128"><a href="#cb28-128" aria-hidden="true" tabindex="-1"></a><span class="co"># map mhc name and class from the assays dataframe to a new column in the epitopes dataframe based on epitope_name</span></span>
<span id="cb28-129"><a href="#cb28-129" aria-hidden="true" tabindex="-1"></a>mhc <span class="op">=</span> assays.<span class="bu">filter</span>([<span class="st">'epitope_name'</span>, <span class="st">'mhcrestriction_name'</span>, <span class="st">'mhcrestriction_class'</span>])</span>
<span id="cb28-130"><a href="#cb28-130" aria-hidden="true" tabindex="-1"></a>mhc <span class="op">=</span> mhc.drop_duplicates(subset<span class="op">=</span>[<span class="st">'epitope_name'</span>])</span>
<span id="cb28-131"><a href="#cb28-131" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.merge(mhc, on<span class="op">=</span><span class="st">'epitope_name'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb28-132"><a href="#cb28-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-133"><a href="#cb28-133" aria-hidden="true" tabindex="-1"></a>epitopes.head()</span>
<span id="cb28-134"><a href="#cb28-134" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-135"><a href="#cb28-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-136"><a href="#cb28-136" aria-hidden="true" tabindex="-1"></a><span class="fu">### MHC Allele Distribution</span></span>
<span id="cb28-137"><a href="#cb28-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-138"><a href="#cb28-138" aria-hidden="true" tabindex="-1"></a>It's important to understand the distribution of MHC alleles associated with the epitopes in our dataset, as MHC molecules are responsible for presenting these peptides to T-cells. A skewed distribution could influence later analysis and create bias towards more represented alleles.</span>
<span id="cb28-139"><a href="#cb28-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-140"><a href="#cb28-140" aria-hidden="true" tabindex="-1"></a><span class="in">```{python mhc_allele_distribution}</span></span>
<span id="cb28-141"><a href="#cb28-141" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-mhc-dist</span></span>
<span id="cb28-142"><a href="#cb28-142" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Top 20 Most Frequent MHC Alleles in Epitope Dataset"</span></span>
<span id="cb28-143"><a href="#cb28-143" aria-hidden="true" tabindex="-1"></a><span class="in">#| warning: false</span></span>
<span id="cb28-144"><a href="#cb28-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-145"><a href="#cb28-145" aria-hidden="true" tabindex="-1"></a><span class="in"># Assuming 'epitopes' DataFrame with 'mhcrestriction_name' column is available</span></span>
<span id="cb28-146"><a href="#cb28-146" aria-hidden="true" tabindex="-1"></a><span class="in"># from the previous preprocessing cell.</span></span>
<span id="cb28-147"><a href="#cb28-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-148"><a href="#cb28-148" aria-hidden="true" tabindex="-1"></a><span class="in"># Count MHC allele frequencies, dropping any NaNs first</span></span>
<span id="cb28-149"><a href="#cb28-149" aria-hidden="true" tabindex="-1"></a><span class="in">mhc_counts = epitopes['mhcrestriction_name'].dropna().value_counts()</span></span>
<span id="cb28-150"><a href="#cb28-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-151"><a href="#cb28-151" aria-hidden="true" tabindex="-1"></a><span class="in"># Select top N for visualization</span></span>
<span id="cb28-152"><a href="#cb28-152" aria-hidden="true" tabindex="-1"></a><span class="in">N = 20 # Show the top 20 alleles</span></span>
<span id="cb28-153"><a href="#cb28-153" aria-hidden="true" tabindex="-1"></a><span class="in">top_mhc_counts = mhc_counts.head(N)</span></span>
<span id="cb28-154"><a href="#cb28-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-155"><a href="#cb28-155" aria-hidden="true" tabindex="-1"></a><span class="in"># Plotting</span></span>
<span id="cb28-156"><a href="#cb28-156" aria-hidden="true" tabindex="-1"></a><span class="in">plt.figure(figsize=(12, 8))</span></span>
<span id="cb28-157"><a href="#cb28-157" aria-hidden="true" tabindex="-1"></a><span class="in">sns.barplot(x=top_mhc_counts.values, y=top_mhc_counts.index, palette='viridis')</span></span>
<span id="cb28-158"><a href="#cb28-158" aria-hidden="true" tabindex="-1"></a><span class="in">plt.title(f'Top {N} Most Frequent MHC Alleles in Epitope Dataset')</span></span>
<span id="cb28-159"><a href="#cb28-159" aria-hidden="true" tabindex="-1"></a><span class="in">plt.xlabel('Frequency (Number of Epitopes)')</span></span>
<span id="cb28-160"><a href="#cb28-160" aria-hidden="true" tabindex="-1"></a><span class="in">plt.ylabel('MHC Allele')</span></span>
<span id="cb28-161"><a href="#cb28-161" aria-hidden="true" tabindex="-1"></a><span class="in">plt.tight_layout()</span></span>
<span id="cb28-162"><a href="#cb28-162" aria-hidden="true" tabindex="-1"></a><span class="in">plt.show()</span></span>
<span id="cb28-163"><a href="#cb28-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-164"><a href="#cb28-164" aria-hidden="true" tabindex="-1"></a><span class="in"># Optionally, print some stats for context</span></span>
<span id="cb28-165"><a href="#cb28-165" aria-hidden="true" tabindex="-1"></a><span class="in"># print(f"Total unique alleles found: {len(mhc_counts)}")</span></span>
<span id="cb28-166"><a href="#cb28-166" aria-hidden="true" tabindex="-1"></a><span class="in"># print("Top 5 allele counts:\n", top_mhc_counts.head())</span></span>
<span id="cb28-167"><a href="#cb28-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-168"><a href="#cb28-168" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-169"><a href="#cb28-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-170"><a href="#cb28-170" aria-hidden="true" tabindex="-1"></a>The plot reveals a skew in the MHC allele distribution within the initial epitope dataset. The allele **HLA-A\*02:01** is much more common compared to all others. This skew towards HLA-A<span class="sc">\*</span>02:01, is critical to acknowledge. It implies that later analyses and models might be heavily influenced by, or perform best on, peptides presented by this specific allele.</span>
<span id="cb28-171"><a href="#cb28-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-172"><a href="#cb28-172" aria-hidden="true" tabindex="-1"></a><span class="fu">### Negative Sample Generation</span></span>
<span id="cb28-173"><a href="#cb28-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-174"><a href="#cb28-174" aria-hidden="true" tabindex="-1"></a><span class="in">```{python negative_sample_generation}</span></span>
<span id="cb28-175"><a href="#cb28-175" aria-hidden="true" tabindex="-1"></a><span class="in">#| eval: false</span></span>
<span id="cb28-176"><a href="#cb28-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-177"><a href="#cb28-177" aria-hidden="true" tabindex="-1"></a><span class="in">def generate_negatives(row):</span></span>
<span id="cb28-178"><a href="#cb28-178" aria-hidden="true" tabindex="-1"></a><span class="in">    epitope = row["epitope_name"]</span></span>
<span id="cb28-179"><a href="#cb28-179" aria-hidden="true" tabindex="-1"></a><span class="in">    full_seq = row["fullsequence"]</span></span>
<span id="cb28-180"><a href="#cb28-180" aria-hidden="true" tabindex="-1"></a><span class="in">    mhc = row["mhcrestriction_name"]</span></span>
<span id="cb28-181"><a href="#cb28-181" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb28-182"><a href="#cb28-182" aria-hidden="true" tabindex="-1"></a><span class="in">    # Handle missing or empty sequences</span></span>
<span id="cb28-183"><a href="#cb28-183" aria-hidden="true" tabindex="-1"></a><span class="in">    if pd.isnull(full_seq) or full_seq == "":</span></span>
<span id="cb28-184"><a href="#cb28-184" aria-hidden="true" tabindex="-1"></a><span class="in">        return []</span></span>
<span id="cb28-185"><a href="#cb28-185" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb28-186"><a href="#cb28-186" aria-hidden="true" tabindex="-1"></a><span class="in">    epitope = str(epitope)</span></span>
<span id="cb28-187"><a href="#cb28-187" aria-hidden="true" tabindex="-1"></a><span class="in">    full_seq = str(full_seq)</span></span>
<span id="cb28-188"><a href="#cb28-188" aria-hidden="true" tabindex="-1"></a><span class="in">    ep_len = len(epitope)</span></span>
<span id="cb28-189"><a href="#cb28-189" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb28-190"><a href="#cb28-190" aria-hidden="true" tabindex="-1"></a><span class="in">    negatives = []</span></span>
<span id="cb28-191"><a href="#cb28-191" aria-hidden="true" tabindex="-1"></a><span class="in">    for i in range(len(full_seq) - ep_len + 1):</span></span>
<span id="cb28-192"><a href="#cb28-192" aria-hidden="true" tabindex="-1"></a><span class="in">        window = full_seq[i:i+ep_len]</span></span>
<span id="cb28-193"><a href="#cb28-193" aria-hidden="true" tabindex="-1"></a><span class="in">        if window != epitope:</span></span>
<span id="cb28-194"><a href="#cb28-194" aria-hidden="true" tabindex="-1"></a><span class="in">            negatives.append({"peptide": window, "mhc": mhc})</span></span>
<span id="cb28-195"><a href="#cb28-195" aria-hidden="true" tabindex="-1"></a><span class="in">    return negatives</span></span>
<span id="cb28-196"><a href="#cb28-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-197"><a href="#cb28-197" aria-hidden="true" tabindex="-1"></a><span class="in"># Apply the function to each row</span></span>
<span id="cb28-198"><a href="#cb28-198" aria-hidden="true" tabindex="-1"></a><span class="in">negatives = pd.DataFrame()</span></span>
<span id="cb28-199"><a href="#cb28-199" aria-hidden="true" tabindex="-1"></a><span class="in">negatives['negatives'] = epitopes.apply(generate_negatives, axis=1)</span></span>
<span id="cb28-200"><a href="#cb28-200" aria-hidden="true" tabindex="-1"></a><span class="in">negatives = negatives[["negatives"]].explode("negatives").reset_index(drop=True)</span></span>
<span id="cb28-201"><a href="#cb28-201" aria-hidden="true" tabindex="-1"></a><span class="in">negatives.dropna(subset=["negatives"], inplace=True)</span></span>
<span id="cb28-202"><a href="#cb28-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-203"><a href="#cb28-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-204"><a href="#cb28-204" aria-hidden="true" tabindex="-1"></a><span class="in"># Remove duplicates</span></span>
<span id="cb28-205"><a href="#cb28-205" aria-hidden="true" tabindex="-1"></a><span class="in">print(f"Shape before removing duplicates: {negatives.shape}")</span></span>
<span id="cb28-206"><a href="#cb28-206" aria-hidden="true" tabindex="-1"></a><span class="in">negatives = negatives.drop_duplicates(subset=['negatives'])</span></span>
<span id="cb28-207"><a href="#cb28-207" aria-hidden="true" tabindex="-1"></a><span class="in">print(f"Shape after removing duplicates: {negatives.shape}")</span></span>
<span id="cb28-208"><a href="#cb28-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-209"><a href="#cb28-209" aria-hidden="true" tabindex="-1"></a><span class="in"># Check for any remaining NaN values</span></span>
<span id="cb28-210"><a href="#cb28-210" aria-hidden="true" tabindex="-1"></a><span class="in">print(f"Number of NaN values in negatives: {negatives['negatives'].isna().sum()}")</span></span>
<span id="cb28-211"><a href="#cb28-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-212"><a href="#cb28-212" aria-hidden="true" tabindex="-1"></a><span class="in"># Extract peptide and mhc into separate columns</span></span>
<span id="cb28-213"><a href="#cb28-213" aria-hidden="true" tabindex="-1"></a><span class="in">negatives['peptide'] = negatives['negatives'].apply(lambda x: x['peptide'])</span></span>
<span id="cb28-214"><a href="#cb28-214" aria-hidden="true" tabindex="-1"></a><span class="in">negatives['mhc'] = negatives['negatives'].apply(lambda x: x['mhc'])</span></span>
<span id="cb28-215"><a href="#cb28-215" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-216"><a href="#cb28-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-217"><a href="#cb28-217" aria-hidden="true" tabindex="-1"></a>Although the IEDB database provided a substantial amount of epitopes, in order to draw visual comparisons and create models to classify epitopes, samples of non-epitope peptides are needed. These can be generated by shuffling and sampling amino acid sequences from the full antigen sequences of the epitopes, ensuring that the sampled sequences did not overlap with the epitope sequences.</span>
<span id="cb28-218"><a href="#cb28-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-219"><a href="#cb28-219" aria-hidden="true" tabindex="-1"></a>There are pros and cons to this methodology. As opposed to generating completely random sequences of amino acids — sampling from larger sequences allows for natural patterns and physiochemical motifs to be retained. That is not to say the performance of statistical models or qualitative analysis will be better. Random sequences are more likely to be highly irregular, or even biologically implausible. Sampling from the full antigen sequences eliminates this potential bias.</span>
<span id="cb28-220"><a href="#cb28-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-221"><a href="#cb28-221" aria-hidden="true" tabindex="-1"></a>Conversely, it is possible for a randomly sampled peptide to be an epitope that has not been tested yet, or simply isn't in the subset of data used for this analysis — resulting in an increase in the number of false negatives in our data.</span>
<span id="cb28-222"><a href="#cb28-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-223"><a href="#cb28-223" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feature Engineering</span></span>
<span id="cb28-224"><a href="#cb28-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-227"><a href="#cb28-227" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb28-228"><a href="#cb28-228" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb28-229"><a href="#cb28-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-230"><a href="#cb28-230" aria-hidden="true" tabindex="-1"></a><span class="co"># Kyte-Doolittle hydrophobicity scale</span></span>
<span id="cb28-231"><a href="#cb28-231" aria-hidden="true" tabindex="-1"></a>kyte_doolittle <span class="op">=</span> {</span>
<span id="cb28-232"><a href="#cb28-232" aria-hidden="true" tabindex="-1"></a>    <span class="st">'I'</span>: <span class="fl">4.5</span>, <span class="st">'V'</span>: <span class="fl">4.2</span>, <span class="st">'L'</span>: <span class="fl">3.8</span>, <span class="st">'F'</span>: <span class="fl">2.8</span>, <span class="st">'C'</span>: <span class="fl">2.5</span>,</span>
<span id="cb28-233"><a href="#cb28-233" aria-hidden="true" tabindex="-1"></a>    <span class="st">'M'</span>: <span class="fl">1.9</span>, <span class="st">'A'</span>: <span class="fl">1.8</span>, <span class="st">'G'</span>: <span class="op">-</span><span class="fl">0.4</span>, <span class="st">'T'</span>: <span class="op">-</span><span class="fl">0.7</span>, <span class="st">'S'</span>: <span class="op">-</span><span class="fl">0.8</span>,</span>
<span id="cb28-234"><a href="#cb28-234" aria-hidden="true" tabindex="-1"></a>    <span class="st">'W'</span>: <span class="op">-</span><span class="fl">0.9</span>, <span class="st">'Y'</span>: <span class="op">-</span><span class="fl">1.3</span>, <span class="st">'P'</span>: <span class="op">-</span><span class="fl">1.6</span>, <span class="st">'H'</span>: <span class="op">-</span><span class="fl">3.2</span>, <span class="st">'E'</span>: <span class="op">-</span><span class="fl">3.5</span>,</span>
<span id="cb28-235"><a href="#cb28-235" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Q'</span>: <span class="op">-</span><span class="fl">3.5</span>, <span class="st">'D'</span>: <span class="op">-</span><span class="fl">3.5</span>, <span class="st">'N'</span>: <span class="op">-</span><span class="fl">3.5</span>, <span class="st">'K'</span>: <span class="op">-</span><span class="fl">3.9</span>, <span class="st">'R'</span>: <span class="op">-</span><span class="fl">4.5</span></span>
<span id="cb28-236"><a href="#cb28-236" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb28-237"><a href="#cb28-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-238"><a href="#cb28-238" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_avg_hydrophobicity(peptide):</span>
<span id="cb28-239"><a href="#cb28-239" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get hydrophobicity scores for each amino acid; default to 0 if missing</span></span>
<span id="cb28-240"><a href="#cb28-240" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> [kyte_doolittle.get(aa, <span class="dv">0</span>) <span class="cf">for</span> aa <span class="kw">in</span> peptide]</span>
<span id="cb28-241"><a href="#cb28-241" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">sum</span>(scores) <span class="op">/</span> <span class="bu">len</span>(scores) <span class="cf">if</span> scores <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb28-242"><a href="#cb28-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-243"><a href="#cb28-243" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to the 'peptide' column to create a new column 'avg_hydro'</span></span>
<span id="cb28-244"><a href="#cb28-244" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'epitope_avg_hydro'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(compute_avg_hydrophobicity)</span>
<span id="cb28-245"><a href="#cb28-245" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the molecular_weight function from Bio.SeqUtils</span></span>
<span id="cb28-246"><a href="#cb28-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-247"><a href="#cb28-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-248"><a href="#cb28-248" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_molecular_weight(peptide):</span>
<span id="cb28-249"><a href="#cb28-249" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the molecular weight of a peptide sequence using Biopython."""</span></span>
<span id="cb28-250"><a href="#cb28-250" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb28-251"><a href="#cb28-251" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb28-252"><a href="#cb28-252" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb28-253"><a href="#cb28-253" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.molecular_weight()</span>
<span id="cb28-254"><a href="#cb28-254" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb28-255"><a href="#cb28-255" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb28-256"><a href="#cb28-256" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb28-257"><a href="#cb28-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-258"><a href="#cb28-258" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb28-259"><a href="#cb28-259" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'molecular_weight'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_molecular_weight)</span>
<span id="cb28-260"><a href="#cb28-260" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_aromaticity(peptide):</span>
<span id="cb28-261"><a href="#cb28-261" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the aromaticity of a peptide sequence using Biopython."""</span></span>
<span id="cb28-262"><a href="#cb28-262" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb28-263"><a href="#cb28-263" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb28-264"><a href="#cb28-264" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb28-265"><a href="#cb28-265" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.aromaticity()</span>
<span id="cb28-266"><a href="#cb28-266" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb28-267"><a href="#cb28-267" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb28-268"><a href="#cb28-268" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb28-269"><a href="#cb28-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-270"><a href="#cb28-270" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb28-271"><a href="#cb28-271" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'aromaticity'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_aromaticity)</span>
<span id="cb28-272"><a href="#cb28-272" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_isoelectric_point(peptide):</span>
<span id="cb28-273"><a href="#cb28-273" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the isoelectric point of a peptide sequence using Biopython."""</span></span>
<span id="cb28-274"><a href="#cb28-274" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb28-275"><a href="#cb28-275" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb28-276"><a href="#cb28-276" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb28-277"><a href="#cb28-277" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.isoelectric_point()</span>
<span id="cb28-278"><a href="#cb28-278" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb28-279"><a href="#cb28-279" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb28-280"><a href="#cb28-280" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb28-281"><a href="#cb28-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-282"><a href="#cb28-282" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb28-283"><a href="#cb28-283" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'isoelectric_point'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_isoelectric_point)</span>
<span id="cb28-284"><a href="#cb28-284" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_instability(peptide):</span>
<span id="cb28-285"><a href="#cb28-285" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the instability of a peptide sequence using Biopython."""</span></span>
<span id="cb28-286"><a href="#cb28-286" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb28-287"><a href="#cb28-287" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb28-288"><a href="#cb28-288" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb28-289"><a href="#cb28-289" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.instability_index()</span>
<span id="cb28-290"><a href="#cb28-290" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb28-291"><a href="#cb28-291" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb28-292"><a href="#cb28-292" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb28-293"><a href="#cb28-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-294"><a href="#cb28-294" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb28-295"><a href="#cb28-295" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'instability'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_instability)</span>
<span id="cb28-296"><a href="#cb28-296" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_charge_at_pH7(peptide):</span>
<span id="cb28-297"><a href="#cb28-297" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the charge of a peptide sequence at pH 7 using Biopython."""</span></span>
<span id="cb28-298"><a href="#cb28-298" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb28-299"><a href="#cb28-299" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb28-300"><a href="#cb28-300" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb28-301"><a href="#cb28-301" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.charge_at_pH(<span class="dv">7</span>)</span>
<span id="cb28-302"><a href="#cb28-302" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb28-303"><a href="#cb28-303" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb28-304"><a href="#cb28-304" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb28-305"><a href="#cb28-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-306"><a href="#cb28-306" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb28-307"><a href="#cb28-307" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'charge_at_pH7'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_charge_at_pH7)</span>
<span id="cb28-308"><a href="#cb28-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-309"><a href="#cb28-309" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate features on the peptide column</span></span>
<span id="cb28-310"><a href="#cb28-310" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'peptide_length'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(<span class="bu">len</span>)</span>
<span id="cb28-311"><a href="#cb28-311" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'peptide_avg_hydro'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(compute_avg_hydrophobicity)</span>
<span id="cb28-312"><a href="#cb28-312" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'molecular_weight'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_molecular_weight)</span>
<span id="cb28-313"><a href="#cb28-313" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'aromaticity'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_aromaticity)</span>
<span id="cb28-314"><a href="#cb28-314" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'isoelectric_point'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_isoelectric_point)</span>
<span id="cb28-315"><a href="#cb28-315" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'instability'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_instability)</span>
<span id="cb28-316"><a href="#cb28-316" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'charge_at_pH7'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_charge_at_pH7)</span>
<span id="cb28-317"><a href="#cb28-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-318"><a href="#cb28-318" aria-hidden="true" tabindex="-1"></a>negatives.drop(<span class="st">'negatives'</span>, axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-319"><a href="#cb28-319" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-320"><a href="#cb28-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-321"><a href="#cb28-321" aria-hidden="true" tabindex="-1"></a>The protein analysis tool from the BioPython package allows for some quick feature engineering on most given peptides. For this analysis, the relevant features would be hydrophobicity, molecular weight, aromaticity, isoelectric point, instability, and the charge at pH7. Publications on epitope classification hold binding affinity — the ability for a peptide to bind to the body's MHC complex — to be a strong preditctor. The BioPython package does not come with any functionality for binding affinity prediction but IEDB provides a tool called **netMHCpan**, which is the leading binding affinity prediction algorithm.</span>
<span id="cb28-322"><a href="#cb28-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-323"><a href="#cb28-323" aria-hidden="true" tabindex="-1"></a>The IEDB website offers a GUI for using netMHCpan to predict binding affinities. However, it is only possible to run predictions on 100 peptides at a time and this analysis is examining many more than that. NetMHCpan can be downloaded and installed as a command line tool allowing more flexibility using python. Given an amino acid sequence and an MHC allele specification, netMHCpan returns a binding affinity score. This score ranges from 0 to 1, where higher values indicate a stronger likelihood of binding.</span>
<span id="cb28-324"><a href="#cb28-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-325"><a href="#cb28-325" aria-hidden="true" tabindex="-1"></a>Subsequent analysis filters for 9-mer peptides, a common length for MHC Class I epitopes, for which binding prediction tools like netMHCpan are well-suited. After feature engineering, we have:</span>
<span id="cb28-326"><a href="#cb28-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-329"><a href="#cb28-329" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb28-330"><a href="#cb28-330" aria-hidden="true" tabindex="-1"></a><span class="co"># Generated using the standalone netMHCpan tool with relevant MHC alleles for each peptide</span></span>
<span id="cb28-331"><a href="#cb28-331" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.read_csv(<span class="st">"/Users/tariq/Documents/capstone/data/ninemer_epitopes.csv"</span>)</span>
<span id="cb28-332"><a href="#cb28-332" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.drop(columns<span class="op">=</span>[<span class="st">'fullsequence'</span>, <span class="st">'mhcrestriction_name'</span>, <span class="st">'mhcrestriction_class'</span>, <span class="st">'epitope_length'</span>])</span>
<span id="cb28-333"><a href="#cb28-333" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.rename(columns<span class="op">=</span>{<span class="st">'epitope_name'</span>: <span class="st">'peptide'</span>, <span class="st">'epitope_avg_hydro'</span>: <span class="st">'peptide_avg_hydro'</span>})</span>
<span id="cb28-334"><a href="#cb28-334" aria-hidden="true" tabindex="-1"></a>epitopes_BA_pred <span class="op">=</span> pd.read_csv(<span class="st">"/Users/tariq/Documents/capstone/data/ninemer_epitopes_BA_pred.csv"</span>)</span>
<span id="cb28-335"><a href="#cb28-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-336"><a href="#cb28-336" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> pd.read_csv(<span class="st">"/Users/tariq/Documents/capstone/data/ninemer_negatives_trimmed.csv"</span>)</span>
<span id="cb28-337"><a href="#cb28-337" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.drop(columns<span class="op">=</span>[<span class="st">'mhc'</span>, <span class="st">'peptide_length'</span>])</span>
<span id="cb28-338"><a href="#cb28-338" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.rename(columns<span class="op">=</span>{<span class="st">'peptide'</span>: <span class="st">'peptide'</span>})</span>
<span id="cb28-339"><a href="#cb28-339" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.drop_duplicates(subset<span class="op">=</span>[<span class="st">'peptide'</span>])</span>
<span id="cb28-340"><a href="#cb28-340" aria-hidden="true" tabindex="-1"></a>negatives_BA_pred <span class="op">=</span> pd.read_csv(<span class="st">"/Users/tariq/Documents/capstone/data/ninemer_negatives_trimmed_BA_pred.csv"</span>)</span>
<span id="cb28-341"><a href="#cb28-341" aria-hidden="true" tabindex="-1"></a>negatives_BA_pred <span class="op">=</span> negatives_BA_pred.drop_duplicates(subset<span class="op">=</span>[<span class="st">'peptide'</span>])</span>
<span id="cb28-342"><a href="#cb28-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-343"><a href="#cb28-343" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge the 'Score_BA' column from epitopes_BA_pred into the epitopes dataframe</span></span>
<span id="cb28-344"><a href="#cb28-344" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.merge(epitopes, epitopes_BA_pred[[<span class="st">'peptide'</span>, <span class="st">'Score_BA'</span>]], on<span class="op">=</span><span class="st">'peptide'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb28-345"><a href="#cb28-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-346"><a href="#cb28-346" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> pd.merge(negatives, negatives_BA_pred[[<span class="st">'peptide'</span>, <span class="st">'Score_BA'</span>]], on<span class="op">=</span><span class="st">'peptide'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb28-347"><a href="#cb28-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-348"><a href="#cb28-348" aria-hidden="true" tabindex="-1"></a>epitopes.head()</span>
<span id="cb28-349"><a href="#cb28-349" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-350"><a href="#cb28-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-351"><a href="#cb28-351" aria-hidden="true" tabindex="-1"></a><span class="fu"># What Distinguishes an epitope from any other peptide?</span></span>
<span id="cb28-352"><a href="#cb28-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-353"><a href="#cb28-353" aria-hidden="true" tabindex="-1"></a><span class="fu">### Statistical Comparison</span></span>
<span id="cb28-354"><a href="#cb28-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-357"><a href="#cb28-357" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb28-358"><a href="#cb28-358" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-stat-compare</span></span>
<span id="cb28-359"><a href="#cb28-359" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Density Plot Comparison of Numeric Features between Epitopes and Negatives"</span></span>
<span id="cb28-360"><a href="#cb28-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-361"><a href="#cb28-361" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare numeric features between epitopes and negatives datasets</span></span>
<span id="cb28-362"><a href="#cb28-362" aria-hidden="true" tabindex="-1"></a>numeric_features <span class="op">=</span> [<span class="st">'peptide_avg_hydro'</span>, <span class="st">'molecular_weight'</span>, <span class="st">'aromaticity'</span>, </span>
<span id="cb28-363"><a href="#cb28-363" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'isoelectric_point'</span>, <span class="st">'instability'</span>, <span class="st">'charge_at_pH7'</span>, <span class="st">'Score_BA'</span>]</span>
<span id="cb28-364"><a href="#cb28-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-365"><a href="#cb28-365" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a figure with subplots for each numeric feature</span></span>
<span id="cb28-366"><a href="#cb28-366" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="bu">len</span>(numeric_features), <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span><span class="op">*</span><span class="bu">len</span>(numeric_features)))</span>
<span id="cb28-367"><a href="#cb28-367" aria-hidden="true" tabindex="-1"></a><span class="co">#fig.tight_layout(pad=5.0)</span></span>
<span id="cb28-368"><a href="#cb28-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-369"><a href="#cb28-369" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot density plots for each feature</span></span>
<span id="cb28-370"><a href="#cb28-370" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, feature <span class="kw">in</span> <span class="bu">enumerate</span>(numeric_features):</span>
<span id="cb28-371"><a href="#cb28-371" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> axes[i]</span>
<span id="cb28-372"><a href="#cb28-372" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-373"><a href="#cb28-373" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create density plot for Epitopes</span></span>
<span id="cb28-374"><a href="#cb28-374" aria-hidden="true" tabindex="-1"></a>    sns.kdeplot(epitopes[feature].dropna(), ax<span class="op">=</span>ax, label<span class="op">=</span><span class="st">'Epitopes'</span>, fill<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-375"><a href="#cb28-375" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-376"><a href="#cb28-376" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create density plot for Negatives</span></span>
<span id="cb28-377"><a href="#cb28-377" aria-hidden="true" tabindex="-1"></a>    sns.kdeplot(negatives[feature].dropna(), ax<span class="op">=</span>ax, label<span class="op">=</span><span class="st">'Negatives'</span>, fill<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-378"><a href="#cb28-378" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-379"><a href="#cb28-379" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add feature statistics</span></span>
<span id="cb28-380"><a href="#cb28-380" aria-hidden="true" tabindex="-1"></a>    epitope_mean <span class="op">=</span> epitopes[feature].mean()</span>
<span id="cb28-381"><a href="#cb28-381" aria-hidden="true" tabindex="-1"></a>    negative_mean <span class="op">=</span> negatives[feature].mean()</span>
<span id="cb28-382"><a href="#cb28-382" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-383"><a href="#cb28-383" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'</span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss"> Density Plot Comparison'</span>)</span>
<span id="cb28-384"><a href="#cb28-384" aria-hidden="true" tabindex="-1"></a>    ax.text(<span class="fl">0.02</span>, <span class="fl">0.95</span>, <span class="ss">f'Epitopes mean: </span><span class="sc">{</span>epitope_mean<span class="sc">:.4f}</span><span class="ss">'</span>, transform<span class="op">=</span>ax.transAxes)</span>
<span id="cb28-385"><a href="#cb28-385" aria-hidden="true" tabindex="-1"></a>    ax.text(<span class="fl">0.02</span>, <span class="fl">0.90</span>, <span class="ss">f'Negatives mean: </span><span class="sc">{</span>negative_mean<span class="sc">:.4f}</span><span class="ss">'</span>, transform<span class="op">=</span>ax.transAxes)</span>
<span id="cb28-386"><a href="#cb28-386" aria-hidden="true" tabindex="-1"></a>    ax.legend()</span>
<span id="cb28-387"><a href="#cb28-387" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-388"><a href="#cb28-388" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add p-value from t-test</span></span>
<span id="cb28-389"><a href="#cb28-389" aria-hidden="true" tabindex="-1"></a>    t_stat, p_value <span class="op">=</span> stats.ttest_ind(</span>
<span id="cb28-390"><a href="#cb28-390" aria-hidden="true" tabindex="-1"></a>        epitopes[feature].dropna(), </span>
<span id="cb28-391"><a href="#cb28-391" aria-hidden="true" tabindex="-1"></a>        negatives[feature].dropna(),</span>
<span id="cb28-392"><a href="#cb28-392" aria-hidden="true" tabindex="-1"></a>        equal_var<span class="op">=</span><span class="va">False</span>  <span class="co"># Welch's t-test (doesn't assume equal variances)</span></span>
<span id="cb28-393"><a href="#cb28-393" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb28-394"><a href="#cb28-394" aria-hidden="true" tabindex="-1"></a>    <span class="co">#ax.text(0.02, 0.85, f'p-value: {p_value:.4e}', transform=ax.transAxes)</span></span>
<span id="cb28-395"><a href="#cb28-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-396"><a href="#cb28-396" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.suptitle('Comparison of Numeric Features Between Epitopes and Negatives', fontsize=16)</span></span>
<span id="cb28-397"><a href="#cb28-397" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb28-398"><a href="#cb28-398" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-399"><a href="#cb28-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-400"><a href="#cb28-400" aria-hidden="true" tabindex="-1"></a>A boxplot comparison of the numerical variables reveals hardly significant differences between the epitope and non-epitope peptides. The clear outlier being the predicted binding affinity score.</span>
<span id="cb28-401"><a href="#cb28-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-404"><a href="#cb28-404" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb28-405"><a href="#cb28-405" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-ba-hist</span></span>
<span id="cb28-406"><a href="#cb28-406" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Normalized Histogram of Binding Affinity Scores"</span></span>
<span id="cb28-407"><a href="#cb28-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-408"><a href="#cb28-408" aria-hidden="true" tabindex="-1"></a><span class="co"># plot Score_BA for epitopes and negatives overlaid on the same plot</span></span>
<span id="cb28-409"><a href="#cb28-409" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb28-410"><a href="#cb28-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-411"><a href="#cb28-411" aria-hidden="true" tabindex="-1"></a><span class="co"># Use density instead of raw counts to normalize the histograms</span></span>
<span id="cb28-412"><a href="#cb28-412" aria-hidden="true" tabindex="-1"></a>plt.hist(epitopes[<span class="st">'Score_BA'</span>], bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'blue'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, </span>
<span id="cb28-413"><a href="#cb28-413" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Epitopes'</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-414"><a href="#cb28-414" aria-hidden="true" tabindex="-1"></a>plt.hist(negatives[<span class="st">'Score_BA'</span>], bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'red'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, </span>
<span id="cb28-415"><a href="#cb28-415" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Negatives'</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-416"><a href="#cb28-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-417"><a href="#cb28-417" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternative approach: use log scale for y-axis</span></span>
<span id="cb28-418"><a href="#cb28-418" aria-hidden="true" tabindex="-1"></a>plt.yscale(<span class="st">'log'</span>)</span>
<span id="cb28-419"><a href="#cb28-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-420"><a href="#cb28-420" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Binding Affinity'</span>)</span>
<span id="cb28-421"><a href="#cb28-421" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density (log scale)'</span>)</span>
<span id="cb28-422"><a href="#cb28-422" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Normalized Histogram of Binding Affinity for Epitopes vs Negatives'</span>)</span>
<span id="cb28-423"><a href="#cb28-423" aria-hidden="true" tabindex="-1"></a>plt.legend(prop<span class="op">=</span>{<span class="st">'size'</span>: <span class="dv">14</span>})  <span class="co"># Increased legend font size</span></span>
<span id="cb28-424"><a href="#cb28-424" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb28-425"><a href="#cb28-425" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb28-426"><a href="#cb28-426" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-427"><a href="#cb28-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-428"><a href="#cb28-428" aria-hidden="true" tabindex="-1"></a>Upon further inspection of the difference in predicted binding affinity score, we see the non-epitope peptides exhibit a right-skewed distribution with a mean of 0.07, and the epitopes show a broad, moderate-variance spread with a much higher mean of 0.56.</span>
<span id="cb28-429"><a href="#cb28-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-430"><a href="#cb28-430" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sequence Motifs</span></span>
<span id="cb28-431"><a href="#cb28-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-432"><a href="#cb28-432" aria-hidden="true" tabindex="-1"></a>While the predicted binding affinity score is a strong predictor of epitope classification, it is not the only feature that distinguishes an epitope from a non-epitope. To further understand the differences between the two classes, we can look for patterns in the amino acid sequences. </span>
<span id="cb28-433"><a href="#cb28-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-434"><a href="#cb28-434" aria-hidden="true" tabindex="-1"></a>One way to explore these patterns is to examine the frequency of short amino acid motifs, such as tripeptides. By comparing the most frequent tripeptides in known epitopes versus non-epitope sequences, we might identify motifs that are enriched in one class or the other.</span>
<span id="cb28-435"><a href="#cb28-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-436"><a href="#cb28-436" aria-hidden="true" tabindex="-1"></a><span class="in">```{python tripeptide_frequency_analysis}</span></span>
<span id="cb28-437"><a href="#cb28-437" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-tripeptide</span></span>
<span id="cb28-438"><a href="#cb28-438" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Top 15 Most Frequent Tripeptides in Epitope vs. Non-Epitope Sequences"</span></span>
<span id="cb28-439"><a href="#cb28-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-440"><a href="#cb28-440" aria-hidden="true" tabindex="-1"></a><span class="in"># Create temporary copies of epitopes and negatives, then add 'label' column for this analysis</span></span>
<span id="cb28-441"><a href="#cb28-441" aria-hidden="true" tabindex="-1"></a><span class="in"># Assumes 'epitopes' and 'negatives' DataFrames (without 'label' yet) are available from prior cells</span></span>
<span id="cb28-442"><a href="#cb28-442" aria-hidden="true" tabindex="-1"></a><span class="in">temp_epitopes_for_motifs = epitopes.copy()</span></span>
<span id="cb28-443"><a href="#cb28-443" aria-hidden="true" tabindex="-1"></a><span class="in">temp_negatives_for_motifs = negatives.copy()</span></span>
<span id="cb28-444"><a href="#cb28-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-445"><a href="#cb28-445" aria-hidden="true" tabindex="-1"></a><span class="in">temp_epitopes_for_motifs['label'] = 1</span></span>
<span id="cb28-446"><a href="#cb28-446" aria-hidden="true" tabindex="-1"></a><span class="in">temp_negatives_for_motifs['label'] = 0</span></span>
<span id="cb28-447"><a href="#cb28-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-448"><a href="#cb28-448" aria-hidden="true" tabindex="-1"></a><span class="in"># Now proceed with the lines you uncommented, using these temporary DataFrames</span></span>
<span id="cb28-449"><a href="#cb28-449" aria-hidden="true" tabindex="-1"></a><span class="in">epitopes_filtered = temp_epitopes_for_motifs[['peptide', 'label']].copy()</span></span>
<span id="cb28-450"><a href="#cb28-450" aria-hidden="true" tabindex="-1"></a><span class="in">epitopes_filtered.rename(columns={'peptide': 'sequence'}, inplace=True)</span></span>
<span id="cb28-451"><a href="#cb28-451" aria-hidden="true" tabindex="-1"></a><span class="in">negatives_filtered = temp_negatives_for_motifs[['peptide', 'label']].copy()</span></span>
<span id="cb28-452"><a href="#cb28-452" aria-hidden="true" tabindex="-1"></a><span class="in">negatives_filtered.rename(columns={'peptide': 'sequence'}, inplace=True)</span></span>
<span id="cb28-453"><a href="#cb28-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-454"><a href="#cb28-454" aria-hidden="true" tabindex="-1"></a><span class="in"># Use a specific name for this combined_data to avoid conflict</span></span>
<span id="cb28-455"><a href="#cb28-455" aria-hidden="true" tabindex="-1"></a><span class="in">combined_data_for_tripeptides = pd.concat([epitopes_filtered, negatives_filtered], ignore_index=True)</span></span>
<span id="cb28-456"><a href="#cb28-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-457"><a href="#cb28-457" aria-hidden="true" tabindex="-1"></a><span class="in">def get_tripeptides(sequence):</span></span>
<span id="cb28-458"><a href="#cb28-458" aria-hidden="true" tabindex="-1"></a><span class="in">    """Extracts all overlapping tripeptides from a sequence."""</span></span>
<span id="cb28-459"><a href="#cb28-459" aria-hidden="true" tabindex="-1"></a><span class="in">    return [sequence[i:i+3] for i in range(len(sequence) - 2)]</span></span>
<span id="cb28-460"><a href="#cb28-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-461"><a href="#cb28-461" aria-hidden="true" tabindex="-1"></a><span class="in"># Separate epitope and non-epitope sequences</span></span>
<span id="cb28-462"><a href="#cb28-462" aria-hidden="true" tabindex="-1"></a><span class="in">epitope_sequences = combined_data_for_tripeptides[combined_data_for_tripeptides['label'] == 1]['sequence'].tolist()</span></span>
<span id="cb28-463"><a href="#cb28-463" aria-hidden="true" tabindex="-1"></a><span class="in">non_epitope_sequences = combined_data_for_tripeptides[combined_data_for_tripeptides['label'] == 0]['sequence'].tolist()</span></span>
<span id="cb28-464"><a href="#cb28-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-465"><a href="#cb28-465" aria-hidden="true" tabindex="-1"></a><span class="in"># Get all tripeptides for epitopes</span></span>
<span id="cb28-466"><a href="#cb28-466" aria-hidden="true" tabindex="-1"></a><span class="in">all_epitope_tripeptides = []</span></span>
<span id="cb28-467"><a href="#cb28-467" aria-hidden="true" tabindex="-1"></a><span class="in">for seq in epitope_sequences:</span></span>
<span id="cb28-468"><a href="#cb28-468" aria-hidden="true" tabindex="-1"></a><span class="in">    all_epitope_tripeptides.extend(get_tripeptides(seq))</span></span>
<span id="cb28-469"><a href="#cb28-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-470"><a href="#cb28-470" aria-hidden="true" tabindex="-1"></a><span class="in"># Get all tripeptides for non-epitopes</span></span>
<span id="cb28-471"><a href="#cb28-471" aria-hidden="true" tabindex="-1"></a><span class="in">all_non_epitope_tripeptides = []</span></span>
<span id="cb28-472"><a href="#cb28-472" aria-hidden="true" tabindex="-1"></a><span class="in">for seq in non_epitope_sequences:</span></span>
<span id="cb28-473"><a href="#cb28-473" aria-hidden="true" tabindex="-1"></a><span class="in">    all_non_epitope_tripeptides.extend(get_tripeptides(seq))</span></span>
<span id="cb28-474"><a href="#cb28-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-475"><a href="#cb28-475" aria-hidden="true" tabindex="-1"></a><span class="in"># Count frequencies</span></span>
<span id="cb28-476"><a href="#cb28-476" aria-hidden="true" tabindex="-1"></a><span class="in">epitope_tripeptide_counts = Counter(all_epitope_tripeptides)</span></span>
<span id="cb28-477"><a href="#cb28-477" aria-hidden="true" tabindex="-1"></a><span class="in">non_epitope_tripeptide_counts = Counter(all_non_epitope_tripeptides)</span></span>
<span id="cb28-478"><a href="#cb28-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-479"><a href="#cb28-479" aria-hidden="true" tabindex="-1"></a><span class="in"># Get top N most common tripeptides</span></span>
<span id="cb28-480"><a href="#cb28-480" aria-hidden="true" tabindex="-1"></a><span class="in">N = 15</span></span>
<span id="cb28-481"><a href="#cb28-481" aria-hidden="true" tabindex="-1"></a><span class="in">top_epitope_tripeptides = epitope_tripeptide_counts.most_common(N)</span></span>
<span id="cb28-482"><a href="#cb28-482" aria-hidden="true" tabindex="-1"></a><span class="in">top_non_epitope_tripeptides = non_epitope_tripeptide_counts.most_common(N)</span></span>
<span id="cb28-483"><a href="#cb28-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-484"><a href="#cb28-484" aria-hidden="true" tabindex="-1"></a><span class="in"># Plotting</span></span>
<span id="cb28-485"><a href="#cb28-485" aria-hidden="true" tabindex="-1"></a><span class="in">fig, axes = plt.subplots(2, 1, figsize=(12, 10))</span></span>
<span id="cb28-486"><a href="#cb28-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-487"><a href="#cb28-487" aria-hidden="true" tabindex="-1"></a><span class="in"># Epitope tripeptides</span></span>
<span id="cb28-488"><a href="#cb28-488" aria-hidden="true" tabindex="-1"></a><span class="in">if top_epitope_tripeptides:</span></span>
<span id="cb28-489"><a href="#cb28-489" aria-hidden="true" tabindex="-1"></a><span class="in">    peptides, counts = zip(*top_epitope_tripeptides)</span></span>
<span id="cb28-490"><a href="#cb28-490" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[0].bar(peptides, counts, color='skyblue')</span></span>
<span id="cb28-491"><a href="#cb28-491" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[0].set_title(f'Top {N} Most Frequent Tripeptides in Epitopes')</span></span>
<span id="cb28-492"><a href="#cb28-492" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[0].set_ylabel('Frequency')</span></span>
<span id="cb28-493"><a href="#cb28-493" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[0].tick_params(axis='x', rotation=45)</span></span>
<span id="cb28-494"><a href="#cb28-494" aria-hidden="true" tabindex="-1"></a><span class="in">else:</span></span>
<span id="cb28-495"><a href="#cb28-495" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[0].text(0.5, 0.5, 'No tripeptides found for epitopes', horizontalalignment='center', verticalalignment='center', transform=axes[0].transAxes)</span></span>
<span id="cb28-496"><a href="#cb28-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-497"><a href="#cb28-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-498"><a href="#cb28-498" aria-hidden="true" tabindex="-1"></a><span class="in"># Non-epitope tripeptides</span></span>
<span id="cb28-499"><a href="#cb28-499" aria-hidden="true" tabindex="-1"></a><span class="in">if top_non_epitope_tripeptides:</span></span>
<span id="cb28-500"><a href="#cb28-500" aria-hidden="true" tabindex="-1"></a><span class="in">    peptides, counts = zip(*top_non_epitope_tripeptides)</span></span>
<span id="cb28-501"><a href="#cb28-501" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[1].bar(peptides, counts, color='lightcoral')</span></span>
<span id="cb28-502"><a href="#cb28-502" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[1].set_title(f'Top {N} Most Frequent Tripeptides in Non-Epitopes')</span></span>
<span id="cb28-503"><a href="#cb28-503" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[1].set_ylabel('Frequency')</span></span>
<span id="cb28-504"><a href="#cb28-504" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[1].set_xlabel('Tripeptide')</span></span>
<span id="cb28-505"><a href="#cb28-505" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[1].tick_params(axis='x', rotation=45)</span></span>
<span id="cb28-506"><a href="#cb28-506" aria-hidden="true" tabindex="-1"></a><span class="in">else:</span></span>
<span id="cb28-507"><a href="#cb28-507" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[1].text(0.5, 0.5, 'No tripeptides found for non-epitopes', horizontalalignment='center', verticalalignment='center', transform=axes[1].transAxes)</span></span>
<span id="cb28-508"><a href="#cb28-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-509"><a href="#cb28-509" aria-hidden="true" tabindex="-1"></a><span class="in">plt.tight_layout()</span></span>
<span id="cb28-510"><a href="#cb28-510" aria-hidden="true" tabindex="-1"></a><span class="in">plt.show()</span></span>
<span id="cb28-511"><a href="#cb28-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-512"><a href="#cb28-512" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-513"><a href="#cb28-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-514"><a href="#cb28-514" aria-hidden="true" tabindex="-1"></a>These plots show the most common tripeptide sequences found within the epitope and non-epitope datasets. Comparing these can help identify if certain short amino acid patterns are more prevalent in one group over the other, potentially hinting at structural or functional differences recognized by the immune system or affecting MHC binding.</span>
<span id="cb28-515"><a href="#cb28-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-516"><a href="#cb28-516" aria-hidden="true" tabindex="-1"></a>Interpreting the tripeptide frequency plots:</span>
<span id="cb28-517"><a href="#cb28-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-518"><a href="#cb28-518" aria-hidden="true" tabindex="-1"></a><span class="ss">*   </span>**Epitopes:** The tripeptide <span class="in">`LLL`</span> is dominant, with Leucine-rich sequences being prevalent.</span>
<span id="cb28-519"><a href="#cb28-519" aria-hidden="true" tabindex="-1"></a><span class="ss">*   </span>**Non-Epitopes:** <span class="in">`SSS`</span> is the most frequent. While <span class="in">`LLL`</span> is also common, this group shows more diversity with prominent Serine, Proline (<span class="in">`PPP`</span>), and Glycine-based motifs (e.g., <span class="in">`GGS`</span>).</span>
<span id="cb28-520"><a href="#cb28-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-521"><a href="#cb28-521" aria-hidden="true" tabindex="-1"></a>The most frequent tripeptides differ significantly between epitopes and non-epitopes. Epitopes favor Leucine-based motifs, while non-epitopes have a broader range with <span class="in">`SSS`</span> leading. This suggests that these short sequence patterns contribute to distinguishing the two.</span>
<span id="cb28-522"><a href="#cb28-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-523"><a href="#cb28-523" aria-hidden="true" tabindex="-1"></a>Another powerful way to visualize conserved patterns in a set of sequences is by generating sequence logos. Each position in the logo consists of a stack of letters, where the height of each letter indicates its frequency at that position.</span>
<span id="cb28-524"><a href="#cb28-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-525"><a href="#cb28-525" aria-hidden="true" tabindex="-1"></a><span class="in">```{python sequence_logo_generation}</span></span>
<span id="cb28-526"><a href="#cb28-526" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-seqlogo</span></span>
<span id="cb28-527"><a href="#cb28-527" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Sequence Logos for Epitope vs. Non-Epitope Sequences"</span></span>
<span id="cb28-528"><a href="#cb28-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-529"><a href="#cb28-529" aria-hidden="true" tabindex="-1"></a><span class="in"># Assuming 'combined_data_for_tripeptides' DataFrame with 'sequence' and 'label' columns is available</span></span>
<span id="cb28-530"><a href="#cb28-530" aria-hidden="true" tabindex="-1"></a><span class="in"># from the previous tripeptide analysis cell.</span></span>
<span id="cb28-531"><a href="#cb28-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-532"><a href="#cb28-532" aria-hidden="true" tabindex="-1"></a><span class="in"># Standard 20 amino acids</span></span>
<span id="cb28-533"><a href="#cb28-533" aria-hidden="true" tabindex="-1"></a><span class="in">amino_acids = sorted(list("ACDEFGHIKLMNPQRSTVWY"))</span></span>
<span id="cb28-534"><a href="#cb28-534" aria-hidden="true" tabindex="-1"></a><span class="in">sequence_length = 9 # Assuming all sequences are 9-mers</span></span>
<span id="cb28-535"><a href="#cb28-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-536"><a href="#cb28-536" aria-hidden="true" tabindex="-1"></a><span class="in">epitope_sequences_for_logo = combined_data_for_tripeptides[combined_data_for_tripeptides['label'] == 1]['sequence'].tolist()</span></span>
<span id="cb28-537"><a href="#cb28-537" aria-hidden="true" tabindex="-1"></a><span class="in">non_epitope_sequences_for_logo = combined_data_for_tripeptides[combined_data_for_tripeptides['label'] == 0]['sequence'].tolist()</span></span>
<span id="cb28-538"><a href="#cb28-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-539"><a href="#cb28-539" aria-hidden="true" tabindex="-1"></a><span class="in">def create_ppm_from_sequences(sequences, amino_acids_list, seq_len):</span></span>
<span id="cb28-540"><a href="#cb28-540" aria-hidden="true" tabindex="-1"></a><span class="in">    if not sequences:</span></span>
<span id="cb28-541"><a href="#cb28-541" aria-hidden="true" tabindex="-1"></a><span class="in">        return pd.DataFrame(0.0, index=amino_acids_list, columns=range(seq_len))</span></span>
<span id="cb28-542"><a href="#cb28-542" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb28-543"><a href="#cb28-543" aria-hidden="true" tabindex="-1"></a><span class="in">    pfm = pd.DataFrame(0, index=amino_acids_list, columns=range(seq_len))</span></span>
<span id="cb28-544"><a href="#cb28-544" aria-hidden="true" tabindex="-1"></a><span class="in">    for seq in sequences:</span></span>
<span id="cb28-545"><a href="#cb28-545" aria-hidden="true" tabindex="-1"></a><span class="in">        if len(seq) == seq_len: # Ensure sequence has expected length</span></span>
<span id="cb28-546"><a href="#cb28-546" aria-hidden="true" tabindex="-1"></a><span class="in">            for i, char in enumerate(seq):</span></span>
<span id="cb28-547"><a href="#cb28-547" aria-hidden="true" tabindex="-1"></a><span class="in">                if char in amino_acids_list: # Ensure character is a standard amino acid</span></span>
<span id="cb28-548"><a href="#cb28-548" aria-hidden="true" tabindex="-1"></a><span class="in">                    pfm.loc[char, i] += 1</span></span>
<span id="cb28-549"><a href="#cb28-549" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb28-550"><a href="#cb28-550" aria-hidden="true" tabindex="-1"></a><span class="in">    # Convert PFM to PPM (Position Probability Matrix)</span></span>
<span id="cb28-551"><a href="#cb28-551" aria-hidden="true" tabindex="-1"></a><span class="in">    ppm = pfm.div(len(sequences), axis='columns')</span></span>
<span id="cb28-552"><a href="#cb28-552" aria-hidden="true" tabindex="-1"></a><span class="in">    return ppm</span></span>
<span id="cb28-553"><a href="#cb28-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-554"><a href="#cb28-554" aria-hidden="true" tabindex="-1"></a><span class="in"># Create PPM for epitopes</span></span>
<span id="cb28-555"><a href="#cb28-555" aria-hidden="true" tabindex="-1"></a><span class="in">ppm_epitopes = create_ppm_from_sequences(epitope_sequences_for_logo, amino_acids, sequence_length)</span></span>
<span id="cb28-556"><a href="#cb28-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-557"><a href="#cb28-557" aria-hidden="true" tabindex="-1"></a><span class="in"># Create PPM for non-epitopes</span></span>
<span id="cb28-558"><a href="#cb28-558" aria-hidden="true" tabindex="-1"></a><span class="in">ppm_non_epitopes = create_ppm_from_sequences(non_epitope_sequences_for_logo, amino_acids, sequence_length)</span></span>
<span id="cb28-559"><a href="#cb28-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-560"><a href="#cb28-560" aria-hidden="true" tabindex="-1"></a><span class="in"># Generate and display sequence logos</span></span>
<span id="cb28-561"><a href="#cb28-561" aria-hidden="true" tabindex="-1"></a><span class="in">fig, axes = plt.subplots(2, 1, figsize=(12, 6))</span></span>
<span id="cb28-562"><a href="#cb28-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-563"><a href="#cb28-563" aria-hidden="true" tabindex="-1"></a><span class="in"># Epitope Logo</span></span>
<span id="cb28-564"><a href="#cb28-564" aria-hidden="true" tabindex="-1"></a><span class="in">if not ppm_epitopes.empty and ppm_epitopes.sum().sum() &gt; 0:</span></span>
<span id="cb28-565"><a href="#cb28-565" aria-hidden="true" tabindex="-1"></a><span class="in">    # Transpose the PPM DataFrame for logomaker</span></span>
<span id="cb28-566"><a href="#cb28-566" aria-hidden="true" tabindex="-1"></a><span class="in">    logomaker.Logo(ppm_epitopes.T, ax=axes[0], font_name='Arial Rounded MT Bold')</span></span>
<span id="cb28-567"><a href="#cb28-567" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[0].set_title('Sequence Logo for Epitopes')</span></span>
<span id="cb28-568"><a href="#cb28-568" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[0].set_ylabel('Bits') # Typically, height is in bits of information</span></span>
<span id="cb28-569"><a href="#cb28-569" aria-hidden="true" tabindex="-1"></a><span class="in">else:</span></span>
<span id="cb28-570"><a href="#cb28-570" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[0].text(0.5, 0.5, 'No data or empty PPM for epitope logo', horizontalalignment='center', verticalalignment='center', transform=axes[0].transAxes)</span></span>
<span id="cb28-571"><a href="#cb28-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-572"><a href="#cb28-572" aria-hidden="true" tabindex="-1"></a><span class="in"># Non-Epitope Logo</span></span>
<span id="cb28-573"><a href="#cb28-573" aria-hidden="true" tabindex="-1"></a><span class="in">if not ppm_non_epitopes.empty and ppm_non_epitopes.sum().sum() &gt; 0:</span></span>
<span id="cb28-574"><a href="#cb28-574" aria-hidden="true" tabindex="-1"></a><span class="in">    # Transpose the PPM DataFrame for logomaker</span></span>
<span id="cb28-575"><a href="#cb28-575" aria-hidden="true" tabindex="-1"></a><span class="in">    logomaker.Logo(ppm_non_epitopes.T, ax=axes[1], font_name='Arial Rounded MT Bold')</span></span>
<span id="cb28-576"><a href="#cb28-576" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[1].set_title('Sequence Logo for Non-Epitopes')</span></span>
<span id="cb28-577"><a href="#cb28-577" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[1].set_xlabel('Position')</span></span>
<span id="cb28-578"><a href="#cb28-578" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[1].set_ylabel('Bits')</span></span>
<span id="cb28-579"><a href="#cb28-579" aria-hidden="true" tabindex="-1"></a><span class="in">else:</span></span>
<span id="cb28-580"><a href="#cb28-580" aria-hidden="true" tabindex="-1"></a><span class="in">    axes[1].text(0.5, 0.5, 'No data or empty PPM for non-epitope logo', horizontalalignment='center', verticalalignment='center', transform=axes[1].transAxes)</span></span>
<span id="cb28-581"><a href="#cb28-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-582"><a href="#cb28-582" aria-hidden="true" tabindex="-1"></a><span class="in">plt.tight_layout()</span></span>
<span id="cb28-583"><a href="#cb28-583" aria-hidden="true" tabindex="-1"></a><span class="in">plt.show()</span></span>
<span id="cb28-584"><a href="#cb28-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-585"><a href="#cb28-585" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-586"><a href="#cb28-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-587"><a href="#cb28-587" aria-hidden="true" tabindex="-1"></a>These sequence logos visually represent the amino acid frequencies at each of the 9 positions for epitopes and non-epitopes. Bigger letters indicate a higher frequency of that amino acid at that specific position.</span>
<span id="cb28-588"><a href="#cb28-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-589"><a href="#cb28-589" aria-hidden="true" tabindex="-1"></a>Interpreting the sequence logos:</span>
<span id="cb28-590"><a href="#cb28-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-591"><a href="#cb28-591" aria-hidden="true" tabindex="-1"></a><span class="ss">*   </span>**Epitope Logo:** While showing variability, there's a noticeable preference for Leucine at the position 8 and also a tendency for <span class="in">`L`</span> at position 1. Other positions show a mix of amino acids with generally lower conservation, though residues like Serine, Lysine, and Valine appear at various spots.</span>
<span id="cb28-592"><a href="#cb28-592" aria-hidden="true" tabindex="-1"></a><span class="ss">*   </span>**Non-Epitope Logo:** This logo generally shows more diversity across all positions. While Leucine and Serine are common, no single amino acid dominates at most positions. The position 8preference for <span class="in">`L`</span> seen in epitopes is less pronounced here.</span>
<span id="cb28-593"><a href="#cb28-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-594"><a href="#cb28-594" aria-hidden="true" tabindex="-1"></a><span class="fu"># Can we predict?</span></span>
<span id="cb28-595"><a href="#cb28-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-596"><a href="#cb28-596" aria-hidden="true" tabindex="-1"></a><span class="fu">### Model Selection: A Baseline with State-of-the-Art Binding Prediction</span></span>
<span id="cb28-597"><a href="#cb28-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-598"><a href="#cb28-598" aria-hidden="true" tabindex="-1"></a>To establish a baseline, we first develop a Random Forest classifier. This model incorporates a unique feature: predicted binding affinity scores (<span class="in">`Score_BA`</span>) derived from <span class="in">`netMHCpan`</span>, a state-of-the-art algorithm for MHC binding prediction. By including this, our baseline leverages existing sophisticated domain knowledge. The full feature set includes:</span>
<span id="cb28-599"><a href="#cb28-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-600"><a href="#cb28-600" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Average Hydrophobicity</span>
<span id="cb28-601"><a href="#cb28-601" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Molecular Weight</span>
<span id="cb28-602"><a href="#cb28-602" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Aromaticity</span>
<span id="cb28-603"><a href="#cb28-603" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Isoelectric Point</span>
<span id="cb28-604"><a href="#cb28-604" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Instability</span>
<span id="cb28-605"><a href="#cb28-605" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Charge at pH7</span>
<span id="cb28-606"><a href="#cb28-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-607"><a href="#cb28-607" aria-hidden="true" tabindex="-1"></a>Performace will be evaluated based on accuracy, precision, and recall.</span>
<span id="cb28-608"><a href="#cb28-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-609"><a href="#cb28-609" aria-hidden="true" tabindex="-1"></a><span class="fu">### Preprocessing</span></span>
<span id="cb28-610"><a href="#cb28-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-611"><a href="#cb28-611" aria-hidden="true" tabindex="-1"></a>Prior to training, labels are assigned to the epitopes and non-epitopes as 1 or 0 respectively. The two samples are then concatenated, scaled, and shuffled. Finally, the data is split into training and testing sets with an 80/20 ratio.</span>
<span id="cb28-612"><a href="#cb28-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-615"><a href="#cb28-615" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb28-616"><a href="#cb28-616" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-cm-rf</span></span>
<span id="cb28-617"><a href="#cb28-617" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Confusion Matrix for Random Forest with Binding Affinity"</span></span>
<span id="cb28-618"><a href="#cb28-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-619"><a href="#cb28-619" aria-hidden="true" tabindex="-1"></a><span class="co"># Add label column to epitopes dataframe (positive class = 1)</span></span>
<span id="cb28-620"><a href="#cb28-620" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'label'</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb28-621"><a href="#cb28-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-622"><a href="#cb28-622" aria-hidden="true" tabindex="-1"></a><span class="co"># Add label column to negatives dataframe (negative class = 0)</span></span>
<span id="cb28-623"><a href="#cb28-623" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'label'</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb28-624"><a href="#cb28-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-625"><a href="#cb28-625" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine the positive and negative examples</span></span>
<span id="cb28-626"><a href="#cb28-626" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> pd.concat([epitopes, negatives], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-627"><a href="#cb28-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-628"><a href="#cb28-628" aria-hidden="true" tabindex="-1"></a><span class="co"># Shuffle the combined dataset</span></span>
<span id="cb28-629"><a href="#cb28-629" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> combined_data.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-630"><a href="#cb28-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-631"><a href="#cb28-631" aria-hidden="true" tabindex="-1"></a><span class="co"># Define features and target</span></span>
<span id="cb28-632"><a href="#cb28-632" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> combined_data.drop(columns<span class="op">=</span>[<span class="st">'peptide'</span>, <span class="st">'label'</span>])</span>
<span id="cb28-633"><a href="#cb28-633" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> combined_data[<span class="st">'label'</span>]</span>
<span id="cb28-634"><a href="#cb28-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-635"><a href="#cb28-635" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify numerical columns to scale (exclude one-hot encoded amino acid columns)</span></span>
<span id="cb28-636"><a href="#cb28-636" aria-hidden="true" tabindex="-1"></a>numerical_cols <span class="op">=</span> [<span class="st">'peptide_avg_hydro'</span>, <span class="st">'molecular_weight'</span>, <span class="st">'aromaticity'</span>, <span class="st">'isoelectric_point'</span>, <span class="st">'instability'</span>]</span>
<span id="cb28-637"><a href="#cb28-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-638"><a href="#cb28-638" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets (80% train, 20% test)</span></span>
<span id="cb28-639"><a href="#cb28-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-640"><a href="#cb28-640" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb28-641"><a href="#cb28-641" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y</span>
<span id="cb28-642"><a href="#cb28-642" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-643"><a href="#cb28-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-644"><a href="#cb28-644" aria-hidden="true" tabindex="-1"></a><span class="co"># Scale numerical features using StandardScaler</span></span>
<span id="cb28-645"><a href="#cb28-645" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb28-646"><a href="#cb28-646" aria-hidden="true" tabindex="-1"></a>X_train[numerical_cols] <span class="op">=</span> scaler.fit_transform(X_train[numerical_cols])</span>
<span id="cb28-647"><a href="#cb28-647" aria-hidden="true" tabindex="-1"></a>X_test[numerical_cols] <span class="op">=</span> scaler.transform(X_test[numerical_cols])</span>
<span id="cb28-648"><a href="#cb28-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-649"><a href="#cb28-649" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the shapes to verify the split</span></span>
<span id="cb28-650"><a href="#cb28-650" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training set: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb28-651"><a href="#cb28-651" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Testing set: </span><span class="sc">{</span>X_test<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb28-652"><a href="#cb28-652" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in training: </span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb28-653"><a href="#cb28-653" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in training: </span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb28-654"><a href="#cb28-654" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in testing: </span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb28-655"><a href="#cb28-655" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in testing: </span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb28-656"><a href="#cb28-656" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-657"><a href="#cb28-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-658"><a href="#cb28-658" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training + Evaluation</span></span>
<span id="cb28-659"><a href="#cb28-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-660"><a href="#cb28-660" aria-hidden="true" tabindex="-1"></a>The random forest classifier is fit to the training data and evaluated on the testing data.</span>
<span id="cb28-661"><a href="#cb28-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-664"><a href="#cb28-664" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb28-665"><a href="#cb28-665" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-cm-rf-ba</span></span>
<span id="cb28-666"><a href="#cb28-666" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Confusion Matrix for Random Forest with Binding Affinity"</span></span>
<span id="cb28-667"><a href="#cb28-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-668"><a href="#cb28-668" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Random Forest Classifier</span></span>
<span id="cb28-669"><a href="#cb28-669" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb28-670"><a href="#cb28-670" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,  <span class="co"># Number of trees</span></span>
<span id="cb28-671"><a href="#cb28-671" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="va">None</span>,    <span class="co"># Maximum depth of trees</span></span>
<span id="cb28-672"><a href="#cb28-672" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb28-673"><a href="#cb28-673" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb28-674"><a href="#cb28-674" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb28-675"><a href="#cb28-675" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-676"><a href="#cb28-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-677"><a href="#cb28-677" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb28-678"><a href="#cb28-678" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X_train, y_train)</span>
<span id="cb28-679"><a href="#cb28-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-680"><a href="#cb28-680" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb28-681"><a href="#cb28-681" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> rf_model.predict(X_test)</span>
<span id="cb28-682"><a href="#cb28-682" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> rf_model.predict_proba(X_test)[:, <span class="dv">1</span>]  <span class="co"># Probability estimates for positive class</span></span>
<span id="cb28-683"><a href="#cb28-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-684"><a href="#cb28-684" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb28-685"><a href="#cb28-685" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb28-686"><a href="#cb28-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-687"><a href="#cb28-687" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Confusion Matrix</span></span>
<span id="cb28-688"><a href="#cb28-688" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb28-689"><a href="#cb28-689" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, </span>
<span id="cb28-690"><a href="#cb28-690" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>[<span class="st">'Predicted Negative'</span>, <span class="st">'Predicted Positive'</span>], </span>
<span id="cb28-691"><a href="#cb28-691" aria-hidden="true" tabindex="-1"></a>            yticklabels<span class="op">=</span>[<span class="st">'Actual Negative'</span>, <span class="st">'Actual Positive'</span>])</span>
<span id="cb28-692"><a href="#cb28-692" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Label'</span>)</span>
<span id="cb28-693"><a href="#cb28-693" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Label'</span>)</span>
<span id="cb28-694"><a href="#cb28-694" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix - Random Forest'</span>)</span>
<span id="cb28-695"><a href="#cb28-695" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb28-696"><a href="#cb28-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-697"><a href="#cb28-697" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb28-698"><a href="#cb28-698" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Random Forest Model Classification Report:"</span>)</span>
<span id="cb28-699"><a href="#cb28-699" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span>
<span id="cb28-700"><a href="#cb28-700" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-701"><a href="#cb28-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-702"><a href="#cb28-702" aria-hidden="true" tabindex="-1"></a>The results show strong performance from the random forest classifier, with an overall accuracy of 91% and recall of 75% for the positive class. This strong performance is due to the powerful <span class="in">`Score_BA`</span> predictor from <span class="in">`netMHCpan`</span>.</span>
<span id="cb28-703"><a href="#cb28-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-706"><a href="#cb28-706" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb28-707"><a href="#cb28-707" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: Fig-1</span></span>
<span id="cb28-708"><a href="#cb28-708" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Feature Importance for Random Forest with Binding Affinity"</span></span>
<span id="cb28-709"><a href="#cb28-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-710"><a href="#cb28-710" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature importance</span></span>
<span id="cb28-711"><a href="#cb28-711" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> pd.DataFrame({</span>
<span id="cb28-712"><a href="#cb28-712" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: X_train.columns,</span>
<span id="cb28-713"><a href="#cb28-713" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: rf_model.feature_importances_</span>
<span id="cb28-714"><a href="#cb28-714" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb28-715"><a href="#cb28-715" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> feature_importance.sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-716"><a href="#cb28-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-717"><a href="#cb28-717" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot top 15 features</span></span>
<span id="cb28-718"><a href="#cb28-718" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb28-719"><a href="#cb28-719" aria-hidden="true" tabindex="-1"></a>top_features <span class="op">=</span> feature_importance.head(<span class="dv">15</span>)</span>
<span id="cb28-720"><a href="#cb28-720" aria-hidden="true" tabindex="-1"></a>plt.barh(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Importance'</span>], align<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb28-721"><a href="#cb28-721" aria-hidden="true" tabindex="-1"></a>plt.yticks(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Feature'</span>])</span>
<span id="cb28-722"><a href="#cb28-722" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Importance'</span>)</span>
<span id="cb28-723"><a href="#cb28-723" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Feature Importance - Random Forest'</span>)</span>
<span id="cb28-724"><a href="#cb28-724" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb28-725"><a href="#cb28-725" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb28-726"><a href="#cb28-726" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-727"><a href="#cb28-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-728"><a href="#cb28-728" aria-hidden="true" tabindex="-1"></a><span class="fu">### Quantifying the Impact of Binding Affinity Prediction</span></span>
<span id="cb28-729"><a href="#cb28-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-730"><a href="#cb28-730" aria-hidden="true" tabindex="-1"></a>To highlight the significant contribution of the <span class="in">`netMHCpan`</span> prediction of binding affinity, we next evaluate the Random Forest model without the <span class="in">`Score_BA`</span> feature. This helps quantify the performance drop when relying solely on other physiochemical properties without this advanced binding prediction.</span>
<span id="cb28-731"><a href="#cb28-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-734"><a href="#cb28-734" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb28-735"><a href="#cb28-735" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-cm-rf-noba</span></span>
<span id="cb28-736"><a href="#cb28-736" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Confusion Matrix for Random Forest without Binding Affinity"</span></span>
<span id="cb28-737"><a href="#cb28-737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-738"><a href="#cb28-738" aria-hidden="true" tabindex="-1"></a><span class="co"># drop the Score_BA column</span></span>
<span id="cb28-739"><a href="#cb28-739" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train.drop(columns<span class="op">=</span>[<span class="st">'Score_BA'</span>])</span>
<span id="cb28-740"><a href="#cb28-740" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X_test.drop(columns<span class="op">=</span>[<span class="st">'Score_BA'</span>])</span>
<span id="cb28-741"><a href="#cb28-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-742"><a href="#cb28-742" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Random Forest Classifier</span></span>
<span id="cb28-743"><a href="#cb28-743" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb28-744"><a href="#cb28-744" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,  <span class="co"># Number of trees</span></span>
<span id="cb28-745"><a href="#cb28-745" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="va">None</span>,    <span class="co"># Maximum depth of trees</span></span>
<span id="cb28-746"><a href="#cb28-746" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb28-747"><a href="#cb28-747" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb28-748"><a href="#cb28-748" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb28-749"><a href="#cb28-749" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-750"><a href="#cb28-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-751"><a href="#cb28-751" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb28-752"><a href="#cb28-752" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X_train, y_train)</span>
<span id="cb28-753"><a href="#cb28-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-754"><a href="#cb28-754" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb28-755"><a href="#cb28-755" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> rf_model.predict(X_test)</span>
<span id="cb28-756"><a href="#cb28-756" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> rf_model.predict_proba(X_test)[:, <span class="dv">1</span>]  <span class="co"># Probability estimates for positive class</span></span>
<span id="cb28-757"><a href="#cb28-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-758"><a href="#cb28-758" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb28-759"><a href="#cb28-759" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb28-760"><a href="#cb28-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-761"><a href="#cb28-761" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Confusion Matrix</span></span>
<span id="cb28-762"><a href="#cb28-762" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb28-763"><a href="#cb28-763" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, </span>
<span id="cb28-764"><a href="#cb28-764" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>[<span class="st">'Predicted Negative'</span>, <span class="st">'Predicted Positive'</span>], </span>
<span id="cb28-765"><a href="#cb28-765" aria-hidden="true" tabindex="-1"></a>            yticklabels<span class="op">=</span>[<span class="st">'Actual Negative'</span>, <span class="st">'Actual Positive'</span>])</span>
<span id="cb28-766"><a href="#cb28-766" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Label'</span>)</span>
<span id="cb28-767"><a href="#cb28-767" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Label'</span>)</span>
<span id="cb28-768"><a href="#cb28-768" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix - Random Forest'</span>)</span>
<span id="cb28-769"><a href="#cb28-769" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb28-770"><a href="#cb28-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-771"><a href="#cb28-771" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb28-772"><a href="#cb28-772" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classification Report:"</span>)</span>
<span id="cb28-773"><a href="#cb28-773" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span>
<span id="cb28-774"><a href="#cb28-774" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-775"><a href="#cb28-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-776"><a href="#cb28-776" aria-hidden="true" tabindex="-1"></a>The accuracy only drops from 91% to 79%. However, this is misleading when considering the class imbalance of the data. The ratio of negative samples to positive is roughly 4:1, respectively. So, predicting the majority class — non-epitope — almost everytime would result in the majority of the testing data being correctly predicted and labeled.</span>
<span id="cb28-777"><a href="#cb28-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-778"><a href="#cb28-778" aria-hidden="true" tabindex="-1"></a>A better performance metric to compare between models would be the model's recall rate on the positive class. How many of the epitopes in the testing data were correctly predicted and labeled? The same model, when predicted binding affinity was included as a predictor, produced a 74% recall rate while the current model has a much lower 18% recall rate. This dramatic drop in recall for epitopes clearly demonstrates the model's dependence on the <span class="in">`netMHCpan`</span> binding affinity scores for identifying true positives.</span>
<span id="cb28-779"><a href="#cb28-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-782"><a href="#cb28-782" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb28-783"><a href="#cb28-783" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: Fig-2</span></span>
<span id="cb28-784"><a href="#cb28-784" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Feature Importance for Random Forest without Binding Affinity"</span></span>
<span id="cb28-785"><a href="#cb28-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-786"><a href="#cb28-786" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature importance</span></span>
<span id="cb28-787"><a href="#cb28-787" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> pd.DataFrame({</span>
<span id="cb28-788"><a href="#cb28-788" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: X_train.columns,</span>
<span id="cb28-789"><a href="#cb28-789" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: rf_model.feature_importances_</span>
<span id="cb28-790"><a href="#cb28-790" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb28-791"><a href="#cb28-791" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> feature_importance.sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-792"><a href="#cb28-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-793"><a href="#cb28-793" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot top 15 features</span></span>
<span id="cb28-794"><a href="#cb28-794" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb28-795"><a href="#cb28-795" aria-hidden="true" tabindex="-1"></a>top_features <span class="op">=</span> feature_importance.head(<span class="dv">15</span>)</span>
<span id="cb28-796"><a href="#cb28-796" aria-hidden="true" tabindex="-1"></a>plt.barh(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Importance'</span>], align<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb28-797"><a href="#cb28-797" aria-hidden="true" tabindex="-1"></a>plt.yticks(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Feature'</span>])</span>
<span id="cb28-798"><a href="#cb28-798" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Importance'</span>)</span>
<span id="cb28-799"><a href="#cb28-799" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Feature Importance - Random Forest'</span>)</span>
<span id="cb28-800"><a href="#cb28-800" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb28-801"><a href="#cb28-801" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb28-802"><a href="#cb28-802" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-803"><a href="#cb28-803" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-804"><a href="#cb28-804" aria-hidden="true" tabindex="-1"></a><span class="fu">### A Different Approach: Learning Directly from Sequence with CNNs</span></span>
<span id="cb28-805"><a href="#cb28-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-806"><a href="#cb28-806" aria-hidden="true" tabindex="-1"></a>Given the Random Forest model's significant reliance on pre-computed binding affinity from <span class="in">`netMHCpan`</span>, we explore an alternative strategy: a Convolutional Neural Network (CNN). The key value of the CNN in this context is its ability to learn predictive patterns directly from the raw amino acid sequences themselves. Unlike the RF model which uses engineered features and external predictions like <span class="in">`Score_BA`</span>, the CNN can potentially uncover complex sequence motifs, positional tendencies, and other relevant features that may not be fully captured by binding affinity predictions alone. This approach allows the model to discover new features without feature engineering or reliance on separate binding prediction tools.</span>
<span id="cb28-807"><a href="#cb28-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-808"><a href="#cb28-808" aria-hidden="true" tabindex="-1"></a>To start, the data will be filtered to only include the amino acid sequence and respective label.</span>
<span id="cb28-809"><a href="#cb28-809" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-810"><a href="#cb28-810" aria-hidden="true" tabindex="-1"></a><span class="in">```{python data_prep}</span></span>
<span id="cb28-811"><a href="#cb28-811" aria-hidden="true" tabindex="-1"></a><span class="in"># Filter and combine</span></span>
<span id="cb28-812"><a href="#cb28-812" aria-hidden="true" tabindex="-1"></a><span class="in">epitopes_filtered = epitopes[['peptide', 'label']].copy()</span></span>
<span id="cb28-813"><a href="#cb28-813" aria-hidden="true" tabindex="-1"></a><span class="in">epitopes_filtered.rename(columns={'peptide': 'sequence'}, inplace=True)</span></span>
<span id="cb28-814"><a href="#cb28-814" aria-hidden="true" tabindex="-1"></a><span class="in">negatives_filtered = negatives[['peptide', 'label']].copy()</span></span>
<span id="cb28-815"><a href="#cb28-815" aria-hidden="true" tabindex="-1"></a><span class="in">negatives_filtered.rename(columns={'peptide': 'sequence'}, inplace=True)</span></span>
<span id="cb28-816"><a href="#cb28-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-817"><a href="#cb28-817" aria-hidden="true" tabindex="-1"></a><span class="in">combined_data = pd.concat([epitopes_filtered, negatives_filtered], ignore_index=True)</span></span>
<span id="cb28-818"><a href="#cb28-818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-819"><a href="#cb28-819" aria-hidden="true" tabindex="-1"></a><span class="in"># Shuffle the validated data</span></span>
<span id="cb28-820"><a href="#cb28-820" aria-hidden="true" tabindex="-1"></a><span class="in">combined_data = combined_data.sample(frac=1, random_state=42).reset_index(drop=True)</span></span>
<span id="cb28-821"><a href="#cb28-821" aria-hidden="true" tabindex="-1"></a><span class="in">combined_data.head()</span></span>
<span id="cb28-822"><a href="#cb28-822" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-823"><a href="#cb28-823" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-824"><a href="#cb28-824" aria-hidden="true" tabindex="-1"></a>To train a neural network, the sequence must be represented in a numerical format. Assigning each amino acid a unique integer value up to 20, the sequences are converted to a list of integers. Then, the resulting integer sequences are one-hot encoded into a 3-dimensional arrary of shape (25628, 9, 20). 25,628 peptides, 9 amino acids in each peptide, 20 unique amino acids. The data is split into training, validation, and testing sets with a 70/15/15 ratio.</span>
<span id="cb28-825"><a href="#cb28-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-826"><a href="#cb28-826" aria-hidden="true" tabindex="-1"></a><span class="in">```{python sequence_encoding}</span></span>
<span id="cb28-827"><a href="#cb28-827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-828"><a href="#cb28-828" aria-hidden="true" tabindex="-1"></a><span class="in"># Extract sequences</span></span>
<span id="cb28-829"><a href="#cb28-829" aria-hidden="true" tabindex="-1"></a><span class="in">all_sequences = combined_data['sequence'].tolist()</span></span>
<span id="cb28-830"><a href="#cb28-830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-831"><a href="#cb28-831" aria-hidden="true" tabindex="-1"></a><span class="in"># Find unique characters (amino acids) across all sequences</span></span>
<span id="cb28-832"><a href="#cb28-832" aria-hidden="true" tabindex="-1"></a><span class="in">unique_chars = sorted(list(set("".join(all_sequences))))</span></span>
<span id="cb28-833"><a href="#cb28-833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-834"><a href="#cb28-834" aria-hidden="true" tabindex="-1"></a><span class="in"># Map characters to indices starting from 0 (no padding index needed)</span></span>
<span id="cb28-835"><a href="#cb28-835" aria-hidden="true" tabindex="-1"></a><span class="in">char_to_index = {char: i for i, char in enumerate(unique_chars)}</span></span>
<span id="cb28-836"><a href="#cb28-836" aria-hidden="true" tabindex="-1"></a><span class="in">index_to_char = {i: char for i, char in enumerate(unique_chars)}</span></span>
<span id="cb28-837"><a href="#cb28-837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-838"><a href="#cb28-838" aria-hidden="true" tabindex="-1"></a><span class="in">num_chars = len(unique_chars) # Vocabulary size is just the number of unique chars</span></span>
<span id="cb28-839"><a href="#cb28-839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-840"><a href="#cb28-840" aria-hidden="true" tabindex="-1"></a><span class="in"># Convert sequences to integer sequences</span></span>
<span id="cb28-841"><a href="#cb28-841" aria-hidden="true" tabindex="-1"></a><span class="in">int_sequences = []</span></span>
<span id="cb28-842"><a href="#cb28-842" aria-hidden="true" tabindex="-1"></a><span class="in">for seq in all_sequences:</span></span>
<span id="cb28-843"><a href="#cb28-843" aria-hidden="true" tabindex="-1"></a><span class="in">     int_seq = [char_to_index[char] for char in seq]</span></span>
<span id="cb28-844"><a href="#cb28-844" aria-hidden="true" tabindex="-1"></a><span class="in">     int_sequences.append(int_seq)</span></span>
<span id="cb28-845"><a href="#cb28-845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-846"><a href="#cb28-846" aria-hidden="true" tabindex="-1"></a><span class="in"># One-hot encode the integer sequences</span></span>
<span id="cb28-847"><a href="#cb28-847" aria-hidden="true" tabindex="-1"></a><span class="in"># Shape: (num_samples, sequence_length, num_unique_chars)</span></span>
<span id="cb28-848"><a href="#cb28-848" aria-hidden="true" tabindex="-1"></a><span class="in"># Assuming all sequences have length 9 as implied by the shape (9, num_chars)</span></span>
<span id="cb28-849"><a href="#cb28-849" aria-hidden="true" tabindex="-1"></a><span class="in">sequence_length = 9 # Explicitly define sequence length</span></span>
<span id="cb28-850"><a href="#cb28-850" aria-hidden="true" tabindex="-1"></a><span class="in">X_onehot = np.zeros((len(int_sequences), sequence_length, num_chars), dtype=np.float32)</span></span>
<span id="cb28-851"><a href="#cb28-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-852"><a href="#cb28-852" aria-hidden="true" tabindex="-1"></a><span class="in">for i, seq in enumerate(int_sequences):</span></span>
<span id="cb28-853"><a href="#cb28-853" aria-hidden="true" tabindex="-1"></a><span class="in">    # Ensure sequence length matches expected length before encoding</span></span>
<span id="cb28-854"><a href="#cb28-854" aria-hidden="true" tabindex="-1"></a><span class="in">    if len(seq) == sequence_length:</span></span>
<span id="cb28-855"><a href="#cb28-855" aria-hidden="true" tabindex="-1"></a><span class="in">        for j, char_idx in enumerate(seq): # j is position (0-8), char_idx is the integer index of the amino acid</span></span>
<span id="cb28-856"><a href="#cb28-856" aria-hidden="true" tabindex="-1"></a><span class="in">            X_onehot[i, j, char_idx] = 1.0</span></span>
<span id="cb28-857"><a href="#cb28-857" aria-hidden="true" tabindex="-1"></a><span class="in">    else:</span></span>
<span id="cb28-858"><a href="#cb28-858" aria-hidden="true" tabindex="-1"></a><span class="in">        print(f"Warning: Sequence at index {i} has length {len(seq)}, expected {sequence_length}. Skipping.")</span></span>
<span id="cb28-859"><a href="#cb28-859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-860"><a href="#cb28-860" aria-hidden="true" tabindex="-1"></a><span class="in">y = combined_data['label'].values</span></span>
<span id="cb28-861"><a href="#cb28-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-862"><a href="#cb28-862" aria-hidden="true" tabindex="-1"></a><span class="in"># --- Data Splitting (70/15/15) ---</span></span>
<span id="cb28-863"><a href="#cb28-863" aria-hidden="true" tabindex="-1"></a><span class="in">print("--- Data Splitting ---")</span></span>
<span id="cb28-864"><a href="#cb28-864" aria-hidden="true" tabindex="-1"></a><span class="in"># Split into temp (85%) and test (15%)</span></span>
<span id="cb28-865"><a href="#cb28-865" aria-hidden="true" tabindex="-1"></a><span class="in">X_temp, X_test, y_temp, y_test = train_test_split(</span></span>
<span id="cb28-866"><a href="#cb28-866" aria-hidden="true" tabindex="-1"></a><span class="in">    X_onehot, y, test_size=0.15, random_state=42, stratify=y</span></span>
<span id="cb28-867"><a href="#cb28-867" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb28-868"><a href="#cb28-868" aria-hidden="true" tabindex="-1"></a><span class="in"># Split temp into train (70% of total) and validation (15% of total)</span></span>
<span id="cb28-869"><a href="#cb28-869" aria-hidden="true" tabindex="-1"></a><span class="in">val_split_ratio = 0.15 / 0.85 # Calculate split ratio for validation set</span></span>
<span id="cb28-870"><a href="#cb28-870" aria-hidden="true" tabindex="-1"></a><span class="in">X_train, X_val, y_train, y_val = train_test_split(</span></span>
<span id="cb28-871"><a href="#cb28-871" aria-hidden="true" tabindex="-1"></a><span class="in">    X_temp, y_temp, test_size=val_split_ratio, random_state=42, stratify=y_temp</span></span>
<span id="cb28-872"><a href="#cb28-872" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb28-873"><a href="#cb28-873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-874"><a href="#cb28-874" aria-hidden="true" tabindex="-1"></a><span class="in">print(f"Training set: {X_train.shape}")</span></span>
<span id="cb28-875"><a href="#cb28-875" aria-hidden="true" tabindex="-1"></a><span class="in">print(f"Validation set: {X_val.shape}")</span></span>
<span id="cb28-876"><a href="#cb28-876" aria-hidden="true" tabindex="-1"></a><span class="in">print(f"Testing set: {X_test.shape}")</span></span>
<span id="cb28-877"><a href="#cb28-877" aria-hidden="true" tabindex="-1"></a><span class="in">print("-" * 30)</span></span>
<span id="cb28-878"><a href="#cb28-878" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-879"><a href="#cb28-879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-880"><a href="#cb28-880" aria-hidden="true" tabindex="-1"></a>This CNN model processes one-hot encoded sequences using three 1D convolutional blocks (64, 128, 256 filters with BatchNormalization, MaxPooling, L2 regularization). Two subsequent dense blocks (256, 128 units with BatchNormalization, Dropout, L2 regularization, ReLU) follow. A final softmax layer outputs class probabilities. The model is compiled with Adam, sparse_categorical_crossentropy loss, and accuracy.</span>
<span id="cb28-881"><a href="#cb28-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-882"><a href="#cb28-882" aria-hidden="true" tabindex="-1"></a><span class="in">```{python model_definition}</span></span>
<span id="cb28-883"><a href="#cb28-883" aria-hidden="true" tabindex="-1"></a><span class="in">def create_cnn_model(input_shape, num_classes=2):</span></span>
<span id="cb28-884"><a href="#cb28-884" aria-hidden="true" tabindex="-1"></a><span class="in">    """Creates and compiles the CNN model."""</span></span>
<span id="cb28-885"><a href="#cb28-885" aria-hidden="true" tabindex="-1"></a><span class="in">    inputs = Input(shape=input_shape)</span></span>
<span id="cb28-886"><a href="#cb28-886" aria-hidden="true" tabindex="-1"></a><span class="in">    x = Conv1D(64, kernel_size=8, activation='relu', padding='same', kernel_regularizer=l2(0.001))(inputs)</span></span>
<span id="cb28-887"><a href="#cb28-887" aria-hidden="true" tabindex="-1"></a><span class="in">    x = BatchNormalization()(x)</span></span>
<span id="cb28-888"><a href="#cb28-888" aria-hidden="true" tabindex="-1"></a><span class="in">    x = MaxPooling1D(pool_size=2, padding='same')(x)</span></span>
<span id="cb28-889"><a href="#cb28-889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-890"><a href="#cb28-890" aria-hidden="true" tabindex="-1"></a><span class="in">    x = Conv1D(128, kernel_size=8, activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)</span></span>
<span id="cb28-891"><a href="#cb28-891" aria-hidden="true" tabindex="-1"></a><span class="in">    x = BatchNormalization()(x)</span></span>
<span id="cb28-892"><a href="#cb28-892" aria-hidden="true" tabindex="-1"></a><span class="in">    x = MaxPooling1D(pool_size=2, padding='same')(x)</span></span>
<span id="cb28-893"><a href="#cb28-893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-894"><a href="#cb28-894" aria-hidden="true" tabindex="-1"></a><span class="in">    x = Conv1D(256, kernel_size=8, activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)</span></span>
<span id="cb28-895"><a href="#cb28-895" aria-hidden="true" tabindex="-1"></a><span class="in">    x = BatchNormalization()(x)</span></span>
<span id="cb28-896"><a href="#cb28-896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-897"><a href="#cb28-897" aria-hidden="true" tabindex="-1"></a><span class="in">    x = Flatten()(x)</span></span>
<span id="cb28-898"><a href="#cb28-898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-899"><a href="#cb28-899" aria-hidden="true" tabindex="-1"></a><span class="in">    x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)</span></span>
<span id="cb28-900"><a href="#cb28-900" aria-hidden="true" tabindex="-1"></a><span class="in">    x = BatchNormalization()(x)</span></span>
<span id="cb28-901"><a href="#cb28-901" aria-hidden="true" tabindex="-1"></a><span class="in">    x = Dropout(0.5)(x)</span></span>
<span id="cb28-902"><a href="#cb28-902" aria-hidden="true" tabindex="-1"></a><span class="in">    x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)</span></span>
<span id="cb28-903"><a href="#cb28-903" aria-hidden="true" tabindex="-1"></a><span class="in">    x = BatchNormalization()(x)</span></span>
<span id="cb28-904"><a href="#cb28-904" aria-hidden="true" tabindex="-1"></a><span class="in">    x = Dropout(0.4)(x)</span></span>
<span id="cb28-905"><a href="#cb28-905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-906"><a href="#cb28-906" aria-hidden="true" tabindex="-1"></a><span class="in">    outputs = Dense(num_classes, activation='softmax')(x)</span></span>
<span id="cb28-907"><a href="#cb28-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-908"><a href="#cb28-908" aria-hidden="true" tabindex="-1"></a><span class="in">    model = Model(inputs=inputs, outputs=outputs)</span></span>
<span id="cb28-909"><a href="#cb28-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-910"><a href="#cb28-910" aria-hidden="true" tabindex="-1"></a><span class="in">    optimizer = Adam(learning_rate=0.001)</span></span>
<span id="cb28-911"><a href="#cb28-911" aria-hidden="true" tabindex="-1"></a><span class="in">    model.compile(optimizer=optimizer,</span></span>
<span id="cb28-912"><a href="#cb28-912" aria-hidden="true" tabindex="-1"></a><span class="in">                  loss='sparse_categorical_crossentropy',</span></span>
<span id="cb28-913"><a href="#cb28-913" aria-hidden="true" tabindex="-1"></a><span class="in">                  metrics=['accuracy'])</span></span>
<span id="cb28-914"><a href="#cb28-914" aria-hidden="true" tabindex="-1"></a><span class="in">    return model</span></span>
<span id="cb28-915"><a href="#cb28-915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-916"><a href="#cb28-916" aria-hidden="true" tabindex="-1"></a><span class="in">input_shape = (9, num_chars)</span></span>
<span id="cb28-917"><a href="#cb28-917" aria-hidden="true" tabindex="-1"></a><span class="in">model = create_cnn_model(input_shape)</span></span>
<span id="cb28-918"><a href="#cb28-918" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-919"><a href="#cb28-919" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-920"><a href="#cb28-920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-921"><a href="#cb28-921" aria-hidden="true" tabindex="-1"></a>Before training the model, class weights are calculated to handle the data imbalance, effectively telling the model to "pay more attention" to samples from the minority class.</span>
<span id="cb28-922"><a href="#cb28-922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-923"><a href="#cb28-923" aria-hidden="true" tabindex="-1"></a><span class="in">```{python class-weights_and_training}</span></span>
<span id="cb28-924"><a href="#cb28-924" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-cm-cnn</span></span>
<span id="cb28-925"><a href="#cb28-925" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Confusion Matrix for CNN Model"</span></span>
<span id="cb28-926"><a href="#cb28-926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-927"><a href="#cb28-927" aria-hidden="true" tabindex="-1"></a><span class="in">from sklearn.utils.class_weight import compute_class_weight</span></span>
<span id="cb28-928"><a href="#cb28-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-929"><a href="#cb28-929" aria-hidden="true" tabindex="-1"></a><span class="in"># Calculate class weights</span></span>
<span id="cb28-930"><a href="#cb28-930" aria-hidden="true" tabindex="-1"></a><span class="in">class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)</span></span>
<span id="cb28-931"><a href="#cb28-931" aria-hidden="true" tabindex="-1"></a><span class="in">class_weight_dict = dict(enumerate(class_weights))</span></span>
<span id="cb28-932"><a href="#cb28-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-933"><a href="#cb28-933" aria-hidden="true" tabindex="-1"></a><span class="in"># Define callbacks</span></span>
<span id="cb28-934"><a href="#cb28-934" aria-hidden="true" tabindex="-1"></a><span class="in">early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0)</span></span>
<span id="cb28-935"><a href="#cb28-935" aria-hidden="true" tabindex="-1"></a><span class="in">reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=0)</span></span>
<span id="cb28-936"><a href="#cb28-936" aria-hidden="true" tabindex="-1"></a><span class="in">model_checkpoint = ModelCheckpoint('best_cnn_model_len9.keras', monitor='val_accuracy', save_best_only=True, verbose=0)</span></span>
<span id="cb28-937"><a href="#cb28-937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-938"><a href="#cb28-938" aria-hidden="true" tabindex="-1"></a><span class="in"># Train the model</span></span>
<span id="cb28-939"><a href="#cb28-939" aria-hidden="true" tabindex="-1"></a><span class="in">history = model.fit(</span></span>
<span id="cb28-940"><a href="#cb28-940" aria-hidden="true" tabindex="-1"></a><span class="in">    X_train, y_train,</span></span>
<span id="cb28-941"><a href="#cb28-941" aria-hidden="true" tabindex="-1"></a><span class="in">    epochs=50,</span></span>
<span id="cb28-942"><a href="#cb28-942" aria-hidden="true" tabindex="-1"></a><span class="in">    batch_size=32,</span></span>
<span id="cb28-943"><a href="#cb28-943" aria-hidden="true" tabindex="-1"></a><span class="in">    validation_data=(X_val, y_val),</span></span>
<span id="cb28-944"><a href="#cb28-944" aria-hidden="true" tabindex="-1"></a><span class="in">    callbacks=[early_stopping, reduce_lr, model_checkpoint],</span></span>
<span id="cb28-945"><a href="#cb28-945" aria-hidden="true" tabindex="-1"></a><span class="in">    class_weight=class_weight_dict,</span></span>
<span id="cb28-946"><a href="#cb28-946" aria-hidden="true" tabindex="-1"></a><span class="in">    verbose=0</span></span>
<span id="cb28-947"><a href="#cb28-947" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb28-948"><a href="#cb28-948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-949"><a href="#cb28-949" aria-hidden="true" tabindex="-1"></a><span class="in">model = tf.keras.models.load_model('best_cnn_model_len9.keras')</span></span>
<span id="cb28-950"><a href="#cb28-950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-951"><a href="#cb28-951" aria-hidden="true" tabindex="-1"></a><span class="in"># Evaluate on test data</span></span>
<span id="cb28-952"><a href="#cb28-952" aria-hidden="true" tabindex="-1"></a><span class="in">test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)</span></span>
<span id="cb28-953"><a href="#cb28-953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-954"><a href="#cb28-954" aria-hidden="true" tabindex="-1"></a><span class="in"># Get prediction probabilities for the positive class</span></span>
<span id="cb28-955"><a href="#cb28-955" aria-hidden="true" tabindex="-1"></a><span class="in">y_pred_proba = model.predict(X_test, verbose=0)</span></span>
<span id="cb28-956"><a href="#cb28-956" aria-hidden="true" tabindex="-1"></a><span class="in">y_pred_proba_positive = y_pred_proba[:, 1]</span></span>
<span id="cb28-957"><a href="#cb28-957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-958"><a href="#cb28-958" aria-hidden="true" tabindex="-1"></a><span class="in"># Apply fixed threshold of 0.5</span></span>
<span id="cb28-959"><a href="#cb28-959" aria-hidden="true" tabindex="-1"></a><span class="in">y_pred = (y_pred_proba_positive &gt;= 0.5).astype(int)</span></span>
<span id="cb28-960"><a href="#cb28-960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-961"><a href="#cb28-961" aria-hidden="true" tabindex="-1"></a><span class="in"># Print classification report</span></span>
<span id="cb28-962"><a href="#cb28-962" aria-hidden="true" tabindex="-1"></a><span class="in">print("\nCNN Classification Report:")</span></span>
<span id="cb28-963"><a href="#cb28-963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-964"><a href="#cb28-964" aria-hidden="true" tabindex="-1"></a><span class="in"># Calculate and plot confusion matrix</span></span>
<span id="cb28-965"><a href="#cb28-965" aria-hidden="true" tabindex="-1"></a><span class="in">cm = confusion_matrix(y_test, y_pred)</span></span>
<span id="cb28-966"><a href="#cb28-966" aria-hidden="true" tabindex="-1"></a><span class="in">plt.figure(figsize=(6, 5))</span></span>
<span id="cb28-967"><a href="#cb28-967" aria-hidden="true" tabindex="-1"></a><span class="in">plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)</span></span>
<span id="cb28-968"><a href="#cb28-968" aria-hidden="true" tabindex="-1"></a><span class="in">plt.title(f'Confusion Matrix')</span></span>
<span id="cb28-969"><a href="#cb28-969" aria-hidden="true" tabindex="-1"></a><span class="in">plt.colorbar()</span></span>
<span id="cb28-970"><a href="#cb28-970" aria-hidden="true" tabindex="-1"></a><span class="in">tick_marks = np.arange(2)</span></span>
<span id="cb28-971"><a href="#cb28-971" aria-hidden="true" tabindex="-1"></a><span class="in">plt.xticks(tick_marks, ['Negative', 'Positive'])</span></span>
<span id="cb28-972"><a href="#cb28-972" aria-hidden="true" tabindex="-1"></a><span class="in">plt.yticks(tick_marks, ['Negative', 'Positive'])</span></span>
<span id="cb28-973"><a href="#cb28-973" aria-hidden="true" tabindex="-1"></a><span class="in">plt.xlabel('Predicted Label')</span></span>
<span id="cb28-974"><a href="#cb28-974" aria-hidden="true" tabindex="-1"></a><span class="in">plt.ylabel('True Label')</span></span>
<span id="cb28-975"><a href="#cb28-975" aria-hidden="true" tabindex="-1"></a><span class="in">thresh = cm.max() / 2.</span></span>
<span id="cb28-976"><a href="#cb28-976" aria-hidden="true" tabindex="-1"></a><span class="in">for i in range(cm.shape[0]):</span></span>
<span id="cb28-977"><a href="#cb28-977" aria-hidden="true" tabindex="-1"></a><span class="in">    for j in range(cm.shape[1]):</span></span>
<span id="cb28-978"><a href="#cb28-978" aria-hidden="true" tabindex="-1"></a><span class="in">        plt.text(j, i, format(cm[i, j], 'd'),</span></span>
<span id="cb28-979"><a href="#cb28-979" aria-hidden="true" tabindex="-1"></a><span class="in">                 horizontalalignment="center",</span></span>
<span id="cb28-980"><a href="#cb28-980" aria-hidden="true" tabindex="-1"></a><span class="in">                 color="white" if cm[i, j] &gt; thresh else "black")</span></span>
<span id="cb28-981"><a href="#cb28-981" aria-hidden="true" tabindex="-1"></a><span class="in">plt.tight_layout()</span></span>
<span id="cb28-982"><a href="#cb28-982" aria-hidden="true" tabindex="-1"></a><span class="in">print(classification_report(y_test, y_pred))</span></span>
<span id="cb28-983"><a href="#cb28-983" aria-hidden="true" tabindex="-1"></a><span class="in">plt.show()</span></span>
<span id="cb28-984"><a href="#cb28-984" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-985"><a href="#cb28-985" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-986"><a href="#cb28-986" aria-hidden="true" tabindex="-1"></a>The Convolutional Neural Network produced a reasonable overall accuracy of 82%, primarily driven by its strong ability to correctly identify the majority, non-epitopes, with high precision and recall. However, its performance on the minority class, epitopes, was mixed; while managing to recall 65% of true epitopes, its precision was significantly lower at 56%, indicating that nearly half of its positive predictions were false positives.</span>
<span id="cb28-987"><a href="#cb28-987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-988"><a href="#cb28-988" aria-hidden="true" tabindex="-1"></a>The Convolutional Neural Network significantly outperforms the Random Forest classifier while relying only on the sequence data, and no additional features. The RF struggles with identifying the actual epitopes, shown by the low recall for Class 1, whereas the CNN, while still challenged with precision for Class 1, provides a better balance and significantly higher recall for the positive class, making it the more effective model in this comparison.</span>
<span id="cb28-989"><a href="#cb28-989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-990"><a href="#cb28-990" aria-hidden="true" tabindex="-1"></a><span class="fu">### What did the CNN learn?</span></span>
<span id="cb28-991"><a href="#cb28-991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-992"><a href="#cb28-992" aria-hidden="true" tabindex="-1"></a>To better understand what the CNN model learned, we can generate saliency maps. A saliency map highlights which input features (amino acids at specific positions) were most influential in the model's decision for a given input sample. This is done by calculating the gradient of the model's output with respect to the input features.</span>
<span id="cb28-993"><a href="#cb28-993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-994"><a href="#cb28-994" aria-hidden="true" tabindex="-1"></a>The following plots examine a single sample sequence, <span class="in">`AASCFTASV`</span>, which the model misclassified. The true label is Non-epitope, but the model predicted it as an Epitope with high confidence. The first map shows which features drove the incorrect prediction, and the second map shows which features would have been important for the correct classification.</span>
<span id="cb28-995"><a href="#cb28-995" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-996"><a href="#cb28-996" aria-hidden="true" tabindex="-1"></a><span class="in">```{python cnn_saliency_map}</span></span>
<span id="cb28-997"><a href="#cb28-997" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-saliency-single</span></span>
<span id="cb28-998"><a href="#cb28-998" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Example Saliency Maps for a Misclassified Sample (AASCFTASV)"</span></span>
<span id="cb28-999"><a href="#cb28-999" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1000"><a href="#cb28-1000" aria-hidden="true" tabindex="-1"></a><span class="in"># Ensure the model is loaded or available from previous cells</span></span>
<span id="cb28-1001"><a href="#cb28-1001" aria-hidden="true" tabindex="-1"></a><span class="in"># If not, load it:</span></span>
<span id="cb28-1002"><a href="#cb28-1002" aria-hidden="true" tabindex="-1"></a><span class="in">model = tf.keras.models.load_model('best_cnn_model_len9.keras')</span></span>
<span id="cb28-1003"><a href="#cb28-1003" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1004"><a href="#cb28-1004" aria-hidden="true" tabindex="-1"></a><span class="in"># Ensure X_test, y_test, and index_to_char are available from the 'sequence_encoding' cell</span></span>
<span id="cb28-1005"><a href="#cb28-1005" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1006"><a href="#cb28-1006" aria-hidden="true" tabindex="-1"></a><span class="in"># Select a sample from the test set</span></span>
<span id="cb28-1007"><a href="#cb28-1007" aria-hidden="true" tabindex="-1"></a><span class="in">sample_index = 5 # You can change this to inspect different samples</span></span>
<span id="cb28-1008"><a href="#cb28-1008" aria-hidden="true" tabindex="-1"></a><span class="in">sample_input = X_test[sample_index:sample_index+1] # Keep batch dimension</span></span>
<span id="cb28-1009"><a href="#cb28-1009" aria-hidden="true" tabindex="-1"></a><span class="in">sample_label = y_test[sample_index]</span></span>
<span id="cb28-1010"><a href="#cb28-1010" aria-hidden="true" tabindex="-1"></a><span class="in">true_class_index = int(sample_label) # Ensure it's an integer for indexing</span></span>
<span id="cb28-1011"><a href="#cb28-1011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1012"><a href="#cb28-1012" aria-hidden="true" tabindex="-1"></a><span class="in"># Convert the one-hot encoded sample back to a sequence for display</span></span>
<span id="cb28-1013"><a href="#cb28-1013" aria-hidden="true" tabindex="-1"></a><span class="in">sample_sequence_onehot = X_test[sample_index]</span></span>
<span id="cb28-1014"><a href="#cb28-1014" aria-hidden="true" tabindex="-1"></a><span class="in">sample_amino_acid_indices = np.argmax(sample_sequence_onehot, axis=1)</span></span>
<span id="cb28-1015"><a href="#cb28-1015" aria-hidden="true" tabindex="-1"></a><span class="in">sample_sequence_str = "".join([index_to_char[idx] for idx in sample_amino_acid_indices])</span></span>
<span id="cb28-1016"><a href="#cb28-1016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1017"><a href="#cb28-1017" aria-hidden="true" tabindex="-1"></a><span class="in">print(f"Sample Sequence: {sample_sequence_str}")</span></span>
<span id="cb28-1018"><a href="#cb28-1018" aria-hidden="true" tabindex="-1"></a><span class="in">print(f"True Label: {'Epitope' if sample_label == 1 else 'Non-epitope'} (Class {sample_label})")</span></span>
<span id="cb28-1019"><a href="#cb28-1019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1020"><a href="#cb28-1020" aria-hidden="true" tabindex="-1"></a><span class="in"># Make a prediction to confirm</span></span>
<span id="cb28-1021"><a href="#cb28-1021" aria-hidden="true" tabindex="-1"></a><span class="in">sample_pred_proba = model.predict(sample_input, verbose=0)</span></span>
<span id="cb28-1022"><a href="#cb28-1022" aria-hidden="true" tabindex="-1"></a><span class="in">predicted_class = np.argmax(sample_pred_proba[0])</span></span>
<span id="cb28-1023"><a href="#cb28-1023" aria-hidden="true" tabindex="-1"></a><span class="in">print(f"Predicted Label: {'Epitope' if predicted_class == 1 else 'Non-epitope'} (Class {predicted_class}) with probability {sample_pred_proba[0][predicted_class]:.4f}")</span></span>
<span id="cb28-1024"><a href="#cb28-1024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1025"><a href="#cb28-1025" aria-hidden="true" tabindex="-1"></a><span class="in"># Convert sample_input to tf.Tensor for gradient taping</span></span>
<span id="cb28-1026"><a href="#cb28-1026" aria-hidden="true" tabindex="-1"></a><span class="in">sample_input_tf = tf.convert_to_tensor(sample_input, dtype=tf.float32)</span></span>
<span id="cb28-1027"><a href="#cb28-1027" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1028"><a href="#cb28-1028" aria-hidden="true" tabindex="-1"></a><span class="in">with tf.GradientTape() as tape:</span></span>
<span id="cb28-1029"><a href="#cb28-1029" aria-hidden="true" tabindex="-1"></a><span class="in">    tape.watch(sample_input_tf)</span></span>
<span id="cb28-1030"><a href="#cb28-1030" aria-hidden="true" tabindex="-1"></a><span class="in">    predictions_tensor = model(sample_input_tf) # Get model output for current sample</span></span>
<span id="cb28-1031"><a href="#cb28-1031" aria-hidden="true" tabindex="-1"></a><span class="in">    predicted_class_idx = tf.argmax(predictions_tensor, axis=1).numpy()[0] # Determine predicted class index</span></span>
<span id="cb28-1032"><a href="#cb28-1032" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb28-1033"><a href="#cb28-1033" aria-hidden="true" tabindex="-1"></a><span class="in">    # Using predicted class for saliency as per latest changes</span></span>
<span id="cb28-1034"><a href="#cb28-1034" aria-hidden="true" tabindex="-1"></a><span class="in">    output_neuron_to_explain = predictions_tensor[:, predicted_class_idx]</span></span>
<span id="cb28-1035"><a href="#cb28-1035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1036"><a href="#cb28-1036" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1037"><a href="#cb28-1037" aria-hidden="true" tabindex="-1"></a><span class="in"># Get the gradients of the output neuron with respect to the input</span></span>
<span id="cb28-1038"><a href="#cb28-1038" aria-hidden="true" tabindex="-1"></a><span class="in">saliency_grads = tape.gradient(output_neuron_to_explain, sample_input_tf)</span></span>
<span id="cb28-1039"><a href="#cb28-1039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1040"><a href="#cb28-1040" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1041"><a href="#cb28-1041" aria-hidden="true" tabindex="-1"></a><span class="in"># saliency will have shape (1, 9, 20)</span></span>
<span id="cb28-1042"><a href="#cb28-1042" aria-hidden="true" tabindex="-1"></a><span class="in"># We take the absolute values and then sum across the one-hot encoding dimension</span></span>
<span id="cb28-1043"><a href="#cb28-1043" aria-hidden="true" tabindex="-1"></a><span class="in"># or take the max across the one-hot encoding for each position</span></span>
<span id="cb28-1044"><a href="#cb28-1044" aria-hidden="true" tabindex="-1"></a><span class="in">saliency_map_per_position = np.sum(np.abs(saliency_grads[0]), axis=1)</span></span>
<span id="cb28-1045"><a href="#cb28-1045" aria-hidden="true" tabindex="-1"></a><span class="in">#saliency_map_per_position = np.max(np.abs(saliency_grads[0]), axis=1)</span></span>
<span id="cb28-1046"><a href="#cb28-1046" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1047"><a href="#cb28-1047" aria-hidden="true" tabindex="-1"></a><span class="in"># Normalize the saliency map for visualization</span></span>
<span id="cb28-1048"><a href="#cb28-1048" aria-hidden="true" tabindex="-1"></a><span class="in">saliency_map_normalized = (saliency_map_per_position - np.min(saliency_map_per_position)) / (np.max(saliency_map_per_position) - np.min(saliency_map_per_position) + 1e-8)</span></span>
<span id="cb28-1049"><a href="#cb28-1049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1050"><a href="#cb28-1050" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1051"><a href="#cb28-1051" aria-hidden="true" tabindex="-1"></a><span class="in"># Plotting the saliency map</span></span>
<span id="cb28-1052"><a href="#cb28-1052" aria-hidden="true" tabindex="-1"></a><span class="in">plt.figure(figsize=(10, 4))</span></span>
<span id="cb28-1053"><a href="#cb28-1053" aria-hidden="true" tabindex="-1"></a><span class="in">plt.bar(range(len(sample_sequence_str)), saliency_map_normalized, color='skyblue')</span></span>
<span id="cb28-1054"><a href="#cb28-1054" aria-hidden="true" tabindex="-1"></a><span class="in">plt.xticks(range(len(sample_sequence_str)), list(sample_sequence_str))</span></span>
<span id="cb28-1055"><a href="#cb28-1055" aria-hidden="true" tabindex="-1"></a><span class="in">plt.xlabel("Amino Acid Position")</span></span>
<span id="cb28-1056"><a href="#cb28-1056" aria-hidden="true" tabindex="-1"></a><span class="in">plt.ylabel("Normalized Saliency")</span></span>
<span id="cb28-1057"><a href="#cb28-1057" aria-hidden="true" tabindex="-1"></a><span class="in">plt.title(f"Saliency Map for Sequence: {sample_sequence_str} (Predicted: {'Epitope' if predicted_class == 1 else 'Non-epitope'})")</span></span>
<span id="cb28-1058"><a href="#cb28-1058" aria-hidden="true" tabindex="-1"></a><span class="in">plt.tight_layout()</span></span>
<span id="cb28-1059"><a href="#cb28-1059" aria-hidden="true" tabindex="-1"></a><span class="in">plt.show()</span></span>
<span id="cb28-1060"><a href="#cb28-1060" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1061"><a href="#cb28-1061" aria-hidden="true" tabindex="-1"></a><span class="in"># You can also try visualizing the gradients for the actual true class if different</span></span>
<span id="cb28-1062"><a href="#cb28-1062" aria-hidden="true" tabindex="-1"></a><span class="in">if predicted_class != true_class_index:</span></span>
<span id="cb28-1063"><a href="#cb28-1063" aria-hidden="true" tabindex="-1"></a><span class="in">    with tf.GradientTape() as tape_true:</span></span>
<span id="cb28-1064"><a href="#cb28-1064" aria-hidden="true" tabindex="-1"></a><span class="in">        tape_true.watch(sample_input_tf)</span></span>
<span id="cb28-1065"><a href="#cb28-1065" aria-hidden="true" tabindex="-1"></a><span class="in">        predictions_true = model(sample_input_tf)</span></span>
<span id="cb28-1066"><a href="#cb28-1066" aria-hidden="true" tabindex="-1"></a><span class="in">        output_neuron_true_class = predictions_true[:, true_class_index]</span></span>
<span id="cb28-1067"><a href="#cb28-1067" aria-hidden="true" tabindex="-1"></a><span class="in">    saliency_true = tape_true.gradient(output_neuron_true_class, sample_input_tf)</span></span>
<span id="cb28-1068"><a href="#cb28-1068" aria-hidden="true" tabindex="-1"></a><span class="in">    saliency_map_per_position_true = np.sum(np.abs(saliency_true[0]), axis=1)</span></span>
<span id="cb28-1069"><a href="#cb28-1069" aria-hidden="true" tabindex="-1"></a><span class="in">    saliency_map_normalized_true = (saliency_map_per_position_true - np.min(saliency_map_per_position_true)) / (np.max(saliency_map_per_position_true) - np.min(saliency_map_per_position_true) + 1e-8)</span></span>
<span id="cb28-1070"><a href="#cb28-1070" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1071"><a href="#cb28-1071" aria-hidden="true" tabindex="-1"></a><span class="in">    plt.figure(figsize=(10, 4))</span></span>
<span id="cb28-1072"><a href="#cb28-1072" aria-hidden="true" tabindex="-1"></a><span class="in">    plt.bar(range(len(sample_sequence_str)), saliency_map_normalized_true, color='salmon')</span></span>
<span id="cb28-1073"><a href="#cb28-1073" aria-hidden="true" tabindex="-1"></a><span class="in">    plt.xticks(range(len(sample_sequence_str)), list(sample_sequence_str))</span></span>
<span id="cb28-1074"><a href="#cb28-1074" aria-hidden="true" tabindex="-1"></a><span class="in">    plt.xlabel("Amino Acid Position")</span></span>
<span id="cb28-1075"><a href="#cb28-1075" aria-hidden="true" tabindex="-1"></a><span class="in">    plt.ylabel("Normalized Saliency (for True Class)")</span></span>
<span id="cb28-1076"><a href="#cb28-1076" aria-hidden="true" tabindex="-1"></a><span class="in">    plt.title(f"Saliency Map for Sequence: {sample_sequence_str} (Influence on True Class: {'Epitope' if true_class_index == 1 else 'Non-epitope'})")</span></span>
<span id="cb28-1077"><a href="#cb28-1077" aria-hidden="true" tabindex="-1"></a><span class="in">    plt.tight_layout()</span></span>
<span id="cb28-1078"><a href="#cb28-1078" aria-hidden="true" tabindex="-1"></a><span class="in">    plt.show()</span></span>
<span id="cb28-1079"><a href="#cb28-1079" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1080"><a href="#cb28-1080" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-1081"><a href="#cb28-1081" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1082"><a href="#cb28-1082" aria-hidden="true" tabindex="-1"></a>For this specific misclassified sample (<span class="in">`AASCFTASV`</span>):</span>
<span id="cb28-1083"><a href="#cb28-1083" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1084"><a href="#cb28-1084" aria-hidden="true" tabindex="-1"></a><span class="ss">*   </span>The model's incorrect Epitope prediction was strongly influenced by the <span class="in">`C`</span> at position 3, <span class="in">`A`</span> at position 6, and <span class="in">`V`</span> at position 8.</span>
<span id="cb28-1085"><a href="#cb28-1085" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1086"><a href="#cb28-1086" aria-hidden="true" tabindex="-1"></a><span class="ss">*   </span>Interestingly, for the correct Non-epitope classification, the <span class="in">`C`</span> at position 3 and <span class="in">`V`</span> at position 8 also show high importance.</span>
<span id="cb28-1087"><a href="#cb28-1087" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1088"><a href="#cb28-1088" aria-hidden="true" tabindex="-1"></a>This suggests these positions are decision points for the model for this sequence with conflicting signals leading to the misclassification.</span>
<span id="cb28-1089"><a href="#cb28-1089" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1090"><a href="#cb28-1090" aria-hidden="true" tabindex="-1"></a><span class="fu">### What about the whole dataset?</span></span>
<span id="cb28-1091"><a href="#cb28-1091" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1092"><a href="#cb28-1092" aria-hidden="true" tabindex="-1"></a>To get a more general understanding of feature importance across the dataset, we can compute average saliency maps for different classes of samples. Below, we calculate and plot the average saliency map for true epitopes and true non-epitopes in the test set. The saliency is calculated with respect to the true class output for each sample. This helps to reveal general patterns the model has learned.</span>
<span id="cb28-1093"><a href="#cb28-1093" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1094"><a href="#cb28-1094" aria-hidden="true" tabindex="-1"></a><span class="in">```{python aggregated_saliency_maps}</span></span>
<span id="cb28-1095"><a href="#cb28-1095" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: fig-saliency-agg</span></span>
<span id="cb28-1096"><a href="#cb28-1096" aria-hidden="true" tabindex="-1"></a><span class="in">#| fig-cap: "Average Saliency Maps for True Epitopes and Non-Epitopes"</span></span>
<span id="cb28-1097"><a href="#cb28-1097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1098"><a href="#cb28-1098" aria-hidden="true" tabindex="-1"></a><span class="in"># Ensure model, X_test, y_test, sequence_length, and num_chars are available</span></span>
<span id="cb28-1099"><a href="#cb28-1099" aria-hidden="true" tabindex="-1"></a><span class="in"># model = tf.keras.models.load_model('best_cnn_model_len9.keras') # If not already loaded</span></span>
<span id="cb28-1100"><a href="#cb28-1100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1101"><a href="#cb28-1101" aria-hidden="true" tabindex="-1"></a><span class="in">num_samples_to_process = len(X_test) # Or a smaller number for quicker testing, e.g., 100</span></span>
<span id="cb28-1102"><a href="#cb28-1102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1103"><a href="#cb28-1103" aria-hidden="true" tabindex="-1"></a><span class="in"># Accumulators for saliency maps and counts</span></span>
<span id="cb28-1104"><a href="#cb28-1104" aria-hidden="true" tabindex="-1"></a><span class="in">saliency_accumulator_epitopes = np.zeros(sequence_length)</span></span>
<span id="cb28-1105"><a href="#cb28-1105" aria-hidden="true" tabindex="-1"></a><span class="in">count_epitopes = 0</span></span>
<span id="cb28-1106"><a href="#cb28-1106" aria-hidden="true" tabindex="-1"></a><span class="in">saliency_accumulator_non_epitopes = np.zeros(sequence_length)</span></span>
<span id="cb28-1107"><a href="#cb28-1107" aria-hidden="true" tabindex="-1"></a><span class="in">count_non_epitopes = 0</span></span>
<span id="cb28-1108"><a href="#cb28-1108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1109"><a href="#cb28-1109" aria-hidden="true" tabindex="-1"></a><span class="in">for i in range(num_samples_to_process):</span></span>
<span id="cb28-1110"><a href="#cb28-1110" aria-hidden="true" tabindex="-1"></a><span class="in">    sample_input = X_test[i:i+1] # Keep batch dimension</span></span>
<span id="cb28-1111"><a href="#cb28-1111" aria-hidden="true" tabindex="-1"></a><span class="in">    true_label = y_test[i]</span></span>
<span id="cb28-1112"><a href="#cb28-1112" aria-hidden="true" tabindex="-1"></a><span class="in">    true_class_idx = int(true_label)</span></span>
<span id="cb28-1113"><a href="#cb28-1113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1114"><a href="#cb28-1114" aria-hidden="true" tabindex="-1"></a><span class="in">    sample_input_tf = tf.convert_to_tensor(sample_input, dtype=tf.float32)</span></span>
<span id="cb28-1115"><a href="#cb28-1115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1116"><a href="#cb28-1116" aria-hidden="true" tabindex="-1"></a><span class="in">    with tf.GradientTape() as tape:</span></span>
<span id="cb28-1117"><a href="#cb28-1117" aria-hidden="true" tabindex="-1"></a><span class="in">        tape.watch(sample_input_tf)</span></span>
<span id="cb28-1118"><a href="#cb28-1118" aria-hidden="true" tabindex="-1"></a><span class="in">        predictions_tensor = model(sample_input_tf) # Get model output for current sample</span></span>
<span id="cb28-1119"><a href="#cb28-1119" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb28-1120"><a href="#cb28-1120" aria-hidden="true" tabindex="-1"></a><span class="in">        # Using true class for saliency</span></span>
<span id="cb28-1121"><a href="#cb28-1121" aria-hidden="true" tabindex="-1"></a><span class="in">        output_neuron_to_explain = predictions_tensor[:, true_class_idx]</span></span>
<span id="cb28-1122"><a href="#cb28-1122" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb28-1123"><a href="#cb28-1123" aria-hidden="true" tabindex="-1"></a><span class="in">    saliency_grads = tape.gradient(output_neuron_to_explain, sample_input_tf)</span></span>
<span id="cb28-1124"><a href="#cb28-1124" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb28-1125"><a href="#cb28-1125" aria-hidden="true" tabindex="-1"></a><span class="in">    if saliency_grads is not None:</span></span>
<span id="cb28-1126"><a href="#cb28-1126" aria-hidden="true" tabindex="-1"></a><span class="in">        # Using np.max as per your previous preference</span></span>
<span id="cb28-1127"><a href="#cb28-1127" aria-hidden="true" tabindex="-1"></a><span class="in">        saliency_map_per_position = np.sum(np.abs(saliency_grads[0].numpy()), axis=1)</span></span>
<span id="cb28-1128"><a href="#cb28-1128" aria-hidden="true" tabindex="-1"></a><span class="in">        #saliency_map_per_position = np.max(np.abs(saliency_grads[0].numpy()), axis=1)</span></span>
<span id="cb28-1129"><a href="#cb28-1129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1130"><a href="#cb28-1130" aria-hidden="true" tabindex="-1"></a><span class="in">        if true_label == 1: # Epitope</span></span>
<span id="cb28-1131"><a href="#cb28-1131" aria-hidden="true" tabindex="-1"></a><span class="in">            saliency_accumulator_epitopes += saliency_map_per_position</span></span>
<span id="cb28-1132"><a href="#cb28-1132" aria-hidden="true" tabindex="-1"></a><span class="in">            count_epitopes += 1</span></span>
<span id="cb28-1133"><a href="#cb28-1133" aria-hidden="true" tabindex="-1"></a><span class="in">        else: # Non-epitope</span></span>
<span id="cb28-1134"><a href="#cb28-1134" aria-hidden="true" tabindex="-1"></a><span class="in">            saliency_accumulator_non_epitopes += saliency_map_per_position</span></span>
<span id="cb28-1135"><a href="#cb28-1135" aria-hidden="true" tabindex="-1"></a><span class="in">            count_non_epitopes += 1</span></span>
<span id="cb28-1136"><a href="#cb28-1136" aria-hidden="true" tabindex="-1"></a><span class="in">    else:</span></span>
<span id="cb28-1137"><a href="#cb28-1137" aria-hidden="true" tabindex="-1"></a><span class="in">        print(f"Warning: Gradients were None for sample {i}. Skipping.")</span></span>
<span id="cb28-1138"><a href="#cb28-1138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1139"><a href="#cb28-1139" aria-hidden="true" tabindex="-1"></a><span class="in">    if (i + 1) % 100 == 0:</span></span>
<span id="cb28-1140"><a href="#cb28-1140" aria-hidden="true" tabindex="-1"></a><span class="in">        #print(f"Processed {i+1}/{num_samples_to_process} samples...")</span></span>
<span id="cb28-1141"><a href="#cb28-1141" aria-hidden="true" tabindex="-1"></a><span class="in">        pass</span></span>
<span id="cb28-1142"><a href="#cb28-1142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1143"><a href="#cb28-1143" aria-hidden="true" tabindex="-1"></a><span class="in">#print("Aggregation complete.")</span></span>
<span id="cb28-1144"><a href="#cb28-1144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1145"><a href="#cb28-1145" aria-hidden="true" tabindex="-1"></a><span class="in"># Calculate average saliency maps</span></span>
<span id="cb28-1146"><a href="#cb28-1146" aria-hidden="true" tabindex="-1"></a><span class="in">if count_epitopes &gt; 0:</span></span>
<span id="cb28-1147"><a href="#cb28-1147" aria-hidden="true" tabindex="-1"></a><span class="in">    avg_saliency_epitopes = saliency_accumulator_epitopes / count_epitopes</span></span>
<span id="cb28-1148"><a href="#cb28-1148" aria-hidden="true" tabindex="-1"></a><span class="in">    avg_saliency_epitopes_normalized = (avg_saliency_epitopes - np.min(avg_saliency_epitopes)) / (np.max(avg_saliency_epitopes) - np.min(avg_saliency_epitopes) + 1e-8)</span></span>
<span id="cb28-1149"><a href="#cb28-1149" aria-hidden="true" tabindex="-1"></a><span class="in">else:</span></span>
<span id="cb28-1150"><a href="#cb28-1150" aria-hidden="true" tabindex="-1"></a><span class="in">    avg_saliency_epitopes_normalized = None</span></span>
<span id="cb28-1151"><a href="#cb28-1151" aria-hidden="true" tabindex="-1"></a><span class="in">    print("No epitope samples processed or found to calculate average saliency.")</span></span>
<span id="cb28-1152"><a href="#cb28-1152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1153"><a href="#cb28-1153" aria-hidden="true" tabindex="-1"></a><span class="in">if count_non_epitopes &gt; 0:</span></span>
<span id="cb28-1154"><a href="#cb28-1154" aria-hidden="true" tabindex="-1"></a><span class="in">    avg_saliency_non_epitopes = saliency_accumulator_non_epitopes / count_non_epitopes</span></span>
<span id="cb28-1155"><a href="#cb28-1155" aria-hidden="true" tabindex="-1"></a><span class="in">    avg_saliency_non_epitopes_normalized = (avg_saliency_non_epitopes - np.min(avg_saliency_non_epitopes)) / (np.max(avg_saliency_non_epitopes) - np.min(avg_saliency_non_epitopes) + 1e-8)</span></span>
<span id="cb28-1156"><a href="#cb28-1156" aria-hidden="true" tabindex="-1"></a><span class="in">else:</span></span>
<span id="cb28-1157"><a href="#cb28-1157" aria-hidden="true" tabindex="-1"></a><span class="in">    avg_saliency_non_epitopes_normalized = None</span></span>
<span id="cb28-1158"><a href="#cb28-1158" aria-hidden="true" tabindex="-1"></a><span class="in">    print("No non-epitope samples processed or found to calculate average saliency.")</span></span>
<span id="cb28-1159"><a href="#cb28-1159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1160"><a href="#cb28-1160" aria-hidden="true" tabindex="-1"></a><span class="in"># Plotting the average saliency maps</span></span>
<span id="cb28-1161"><a href="#cb28-1161" aria-hidden="true" tabindex="-1"></a><span class="in">fig, axs = plt.subplots(2, 1, figsize=(12, 8), sharex=True)</span></span>
<span id="cb28-1162"><a href="#cb28-1162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1163"><a href="#cb28-1163" aria-hidden="true" tabindex="-1"></a><span class="in">if avg_saliency_epitopes_normalized is not None:</span></span>
<span id="cb28-1164"><a href="#cb28-1164" aria-hidden="true" tabindex="-1"></a><span class="in">    axs[0].bar(range(sequence_length), avg_saliency_epitopes_normalized, color='lightcoral')</span></span>
<span id="cb28-1165"><a href="#cb28-1165" aria-hidden="true" tabindex="-1"></a><span class="in">    axs[0].set_ylabel("Normalized Saliency")</span></span>
<span id="cb28-1166"><a href="#cb28-1166" aria-hidden="true" tabindex="-1"></a><span class="in">    axs[0].set_title("Average Saliency Map for True Epitopes")</span></span>
<span id="cb28-1167"><a href="#cb28-1167" aria-hidden="true" tabindex="-1"></a><span class="in">    axs[0].set_xticks(range(sequence_length))</span></span>
<span id="cb28-1168"><a href="#cb28-1168" aria-hidden="true" tabindex="-1"></a><span class="in">else:</span></span>
<span id="cb28-1169"><a href="#cb28-1169" aria-hidden="true" tabindex="-1"></a><span class="in">    axs[0].text(0.5, 0.5, 'No data for epitopes', horizontalalignment='center', verticalalignment='center', transform=axs[0].transAxes)</span></span>
<span id="cb28-1170"><a href="#cb28-1170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1171"><a href="#cb28-1171" aria-hidden="true" tabindex="-1"></a><span class="in">if avg_saliency_non_epitopes_normalized is not None:</span></span>
<span id="cb28-1172"><a href="#cb28-1172" aria-hidden="true" tabindex="-1"></a><span class="in">    axs[1].bar(range(sequence_length), avg_saliency_non_epitopes_normalized, color='skyblue')</span></span>
<span id="cb28-1173"><a href="#cb28-1173" aria-hidden="true" tabindex="-1"></a><span class="in">    axs[1].set_xlabel("Amino Acid Position")</span></span>
<span id="cb28-1174"><a href="#cb28-1174" aria-hidden="true" tabindex="-1"></a><span class="in">    axs[1].set_ylabel("Normalized Saliency")</span></span>
<span id="cb28-1175"><a href="#cb28-1175" aria-hidden="true" tabindex="-1"></a><span class="in">    axs[1].set_title("Average Saliency Map for True Non-Epitopes")</span></span>
<span id="cb28-1176"><a href="#cb28-1176" aria-hidden="true" tabindex="-1"></a><span class="in">    axs[1].set_xticks(range(sequence_length))</span></span>
<span id="cb28-1177"><a href="#cb28-1177" aria-hidden="true" tabindex="-1"></a><span class="in">else:</span></span>
<span id="cb28-1178"><a href="#cb28-1178" aria-hidden="true" tabindex="-1"></a><span class="in">    axs[1].text(0.5, 0.5, 'No data for non-epitopes', horizontalalignment='center', verticalalignment='center', transform=axs[1].transAxes)</span></span>
<span id="cb28-1179"><a href="#cb28-1179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1180"><a href="#cb28-1180" aria-hidden="true" tabindex="-1"></a><span class="in">plt.tight_layout()</span></span>
<span id="cb28-1181"><a href="#cb28-1181" aria-hidden="true" tabindex="-1"></a><span class="in">plt.show()</span></span>
<span id="cb28-1182"><a href="#cb28-1182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1183"><a href="#cb28-1183" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-1184"><a href="#cb28-1184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1185"><a href="#cb28-1185" aria-hidden="true" tabindex="-1"></a>Interpreting the aggregated saliency maps:</span>
<span id="cb28-1186"><a href="#cb28-1186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1187"><a href="#cb28-1187" aria-hidden="true" tabindex="-1"></a><span class="ss">*   </span>**Dominance of position 8:** For both true epitopes and true non-epitopes, the amino acid at position 8 shows by far the highest average saliency. This indicates the model heavily relies on the identity of this final residue to make its classification.</span>
<span id="cb28-1188"><a href="#cb28-1188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1189"><a href="#cb28-1189" aria-hidden="true" tabindex="-1"></a><span class="ss">*   </span>**Importance of position 1 for non-epitopes:** For true non-epitopes, the amino acid at position 1 also shows notably high average saliency, suggesting its importance in identifying a sequence as not an epitope.</span>
<span id="cb28-1190"><a href="#cb28-1190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1191"><a href="#cb28-1191" aria-hidden="true" tabindex="-1"></a><span class="ss">*   </span>**General pattern:** The model appears to have learned that the C-terminal residue is a primary determinant, with other positions like position 1 playing secondary, but still significant, roles.</span>
<span id="cb28-1192"><a href="#cb28-1192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1193"><a href="#cb28-1193" aria-hidden="true" tabindex="-1"></a><span class="fu"># Conclusion</span></span>
<span id="cb28-1194"><a href="#cb28-1194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1195"><a href="#cb28-1195" aria-hidden="true" tabindex="-1"></a>This project aimed to develop and evaluate computational models for classifying cancer T-cell epitopes, a necessary task for advancing personalized cancer treatment. By utilizing data from the Immune Epitope Database (IEDB) and employing feature engineering and machine learning techniques, we explored factors differentiating epitopes from non-epitope peptides derived from the same source proteins.</span>
<span id="cb28-1196"><a href="#cb28-1196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1197"><a href="#cb28-1197" aria-hidden="true" tabindex="-1"></a>A Random Forest model incorporating predicted binding affinity scores from <span class="in">`netMHCpan`</span> achieved high overall performance and reasonable recall for identifying true epitopes. However, removing this binding affinity feature caused a dramatic drop in the model's ability to identify epitopes, indicating that standard physicochemical features alone, while descriptive, were insufficient for robust classification in this context.</span>
<span id="cb28-1198"><a href="#cb28-1198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1199"><a href="#cb28-1199" aria-hidden="true" tabindex="-1"></a>Significantly, a Convolutional Neural Network (CNN) trained on one-hot encoded peptide sequences, without relying on external binding predictors or engineered features, demonstrated superior performance compared to the feature-based Random Forest without binding affinity. The CNN achieved balanced performance with better recall for the epitope class. This demonstrates the potential of deep learning models to capture patterns directly from sequence data.</span>
<span id="cb28-1200"><a href="#cb28-1200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-1201"><a href="#cb28-1201" aria-hidden="true" tabindex="-1"></a><span class="fu"># References</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>