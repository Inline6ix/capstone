<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.29">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tariq Alagha">

<title>Cancer T-Cell Epitope Classification</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="blog_files/libs/clipboard/clipboard.min.js"></script>
<script src="blog_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="blog_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="blog_files/libs/quarto-html/popper.min.js"></script>
<script src="blog_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="blog_files/libs/quarto-html/anchor.min.js"></script>
<link href="blog_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="blog_files/libs/quarto-html/quarto-syntax-highlighting-0815c480559380816a4d1ea211a47e91.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="blog_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="blog_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="blog_files/libs/bootstrap/bootstrap-bb462d781dde1847d9e3ccf7736099dd.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#data" id="toc-data" class="nav-link active" data-scroll-target="#data">Data</a>
  <ul class="collapse">
  <li><a href="#dataset" id="toc-dataset" class="nav-link" data-scroll-target="#dataset">Dataset</a></li>
  <li><a href="#preprocessing" id="toc-preprocessing" class="nav-link" data-scroll-target="#preprocessing">Preprocessing</a></li>
  <li><a href="#negative-sample-generation" id="toc-negative-sample-generation" class="nav-link" data-scroll-target="#negative-sample-generation">Negative Sample Generation</a></li>
  <li><a href="#feature-engineering" id="toc-feature-engineering" class="nav-link" data-scroll-target="#feature-engineering">Feature Engineering</a></li>
  </ul></li>
  <li><a href="#exploratory-analysis" id="toc-exploratory-analysis" class="nav-link" data-scroll-target="#exploratory-analysis">Exploratory Analysis</a></li>
  <li><a href="#modeling" id="toc-modeling" class="nav-link" data-scroll-target="#modeling">Modeling</a>
  <ul class="collapse">
  <li><a href="#model-selection" id="toc-model-selection" class="nav-link" data-scroll-target="#model-selection">Model Selection</a></li>
  <li><a href="#preprocessing-1" id="toc-preprocessing-1" class="nav-link" data-scroll-target="#preprocessing-1">Preprocessing</a></li>
  <li><a href="#training-evaluation" id="toc-training-evaluation" class="nav-link" data-scroll-target="#training-evaluation">Training + Evaluation</a></li>
  <li><a href="#training-without-netmhcpan" id="toc-training-without-netmhcpan" class="nav-link" data-scroll-target="#training-without-netmhcpan">Training without netMHCpan</a></li>
  <li><a href="#basic-convolutional-neural-network" id="toc-basic-convolutional-neural-network" class="nav-link" data-scroll-target="#basic-convolutional-neural-network">Basic Convolutional Neural Network</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Cancer T-Cell Epitope Classification</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
<p class="subtitle lead">Identifying key target antigens for cancer immunotherapy</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Tariq Alagha </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.cell.com/cms/10.1016/j.ccell.2022.08.003/asset/eb36c8cd-3880-4d48-8a8b-f10accd01fba/main.assets/fx1_lrg.jpg" class="img-fluid figure-img" style="width:50.0%" alt="End to end personalized peptide vaccine cancer treatment"></p>
<figcaption><span class="citation" data-cites="AWAD20221010">Awad et al. (<a href="#ref-AWAD20221010" role="doc-biblioref">2022</a>)</span></figcaption>
</figure>
</div>
<p>Epitope classification is a critical area of immunology and vaccine development that focuses on identifying and characterizing specific regions of antigens that are recognized by the immune system. Epitopes serve as the molecular interface between pathogens and the host immune response, making their accurate identification essential for understanding immune responses and developing targeted therapeutics. As shown in Figure 2, standard chemotherapy treatment targets rapidly dividing cells which can include the hosts immune system, making them counterproductive. However, effective fabrication of personalized antigens would make treatment much less physically devastating.</p>
<section id="data" class="level1">
<h1>Data</h1>
<section id="dataset" class="level3">
<h3 class="anchored" data-anchor-id="dataset">Dataset</h3>
<p>The dataset utilized for this analysis is sourced from <a href="https://www.iedb.org/">The Immune Epitope Database (IEDB)</a>, a publicly available database of manually extracted data from published scientific research on antibody and T-cell epitopes. It was created to aggregate and centralize data on how the immune system recognizes specific molecular features, known as epitopes, on antigens.</p>
<p>The database can be queried for known epitopes, returning a list of assays — tests or experiments — that have been performed on the antigen and their results. These tests can include whether or not a particular epitope binds to the MHC complex or is capable of triggering a cytokine release to kill living cells.</p>
<p>The scope of my analysis will be limited to epitopes sourced from human cancer T-cells that were tested and found to produce an autoimmune response. While the database has a wide range of information about each antigen, I will only be utilizing the epitopes’ amino acid sequence and the MHC allele it was tested against.</p>
<p>Along with these features, each epitope entry also contains a link to the antigen’s full amino acid sequence. These full sequences come from the <a href="https://www.uniprot.org/">UniProt</a> database, which contains a collection of protein sequences and their associated information. These full sequences will be used to generate negative samples for the model.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Libraries and packages">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Libraries and packages
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<div id="394cad57" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Importing libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> Bio</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> Bio.SeqUtils.ProtParam <span class="im">import</span> ProteinAnalysis</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> io <span class="im">import</span> StringIO</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> Bio <span class="im">import</span> SeqIO</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
</div>
</div>
</section>
<section id="preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="preprocessing">Preprocessing</h3>
<div id="22d1ad13" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.read_csv(<span class="vs">r'/Users/tariq/Documents/capstone/data/epitope_table_export_1740279588</span><span class="dv">.</span><span class="vs">csv'</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>assays <span class="op">=</span> pd.read_csv(<span class="vs">r'/Users/tariq/Documents/capstone/data/tcell_table_export_1740279970</span><span class="dv">.</span><span class="vs">csv'</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fetch_full_sequence(url):</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.notna(url):  <span class="co"># Check if the URL is not NaN</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        url <span class="op">=</span> <span class="ss">f'</span><span class="sc">{</span>url<span class="sc">}</span><span class="ss">.fasta'</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>            response <span class="op">=</span> requests.get(url)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> response.status_code <span class="op">==</span> <span class="dv">200</span>:</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>                fasta_io <span class="op">=</span> StringIO(response.text)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>                records <span class="op">=</span> <span class="bu">list</span>(SeqIO.parse(fasta_io, <span class="st">"fasta"</span>))</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> records:  <span class="co"># Check if there are any records</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">return</span> <span class="bu">str</span>(records[<span class="dv">0</span>].seq)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="st">"No records found in the FASTA file."</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> requests.exceptions.RequestException <span class="im">as</span> e:</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Request failed: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="co">#epitopes['Full Sequence'] = epitopes['Epitope - Molecule Parent IRI'].apply(fetch_full_sequence)</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.read_csv(<span class="vs">r'/Users/tariq/Documents/capstone/data/epitope_full_seq</span><span class="dv">.</span><span class="vs">csv'</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="co"># make all the column names snake case</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.lower()</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.lower()</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="co"># remove spaces from column names</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">''</span>)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.replace(<span class="st">'-'</span>, <span class="st">' '</span>)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">'_'</span>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">''</span>)</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.replace(<span class="st">'-'</span>, <span class="st">' '</span>)</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">'_'</span>)</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.<span class="bu">filter</span>([<span class="st">'epitope_name'</span>, <span class="st">'fullsequence'</span>])</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>assays <span class="op">=</span> assays.<span class="bu">filter</span>([<span class="st">'epitope_name'</span>, <span class="st">'epitope_moluculeparent'</span>, <span class="st">'host_name'</span>, <span class="st">'host_mhcpresent'</span>, <span class="st">'assay_method'</span>,<span class="st">'assay_responsemeasured'</span>, <span class="st">'assay_qualitativemeasurement'</span>, <span class="st">'mhcrestriction_name'</span>, <span class="st">'mhcrestriction_class'</span>, <span class="st">'assayantigen_name'</span>])</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a><span class="co"># map mhc name and class from the assays dataframe to a new column in the epitopes dataframe based on epitope_name</span></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>mhc <span class="op">=</span> assays.<span class="bu">filter</span>([<span class="st">'epitope_name'</span>, <span class="st">'mhcrestriction_name'</span>, <span class="st">'mhcrestriction_class'</span>])</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>mhc <span class="op">=</span> mhc.drop_duplicates(subset<span class="op">=</span>[<span class="st">'epitope_name'</span>])</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.merge(mhc, on<span class="op">=</span><span class="st">'epitope_name'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>epitopes.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="170">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">epitope_name</th>
<th data-quarto-table-cell-role="th">fullsequence</th>
<th data-quarto-table-cell-role="th">mhcrestriction_name</th>
<th data-quarto-table-cell-role="th">mhcrestriction_class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>AAGIGILTV</td>
<td>MPREDAHFIYGYPKKGHGHSYTTAEEAAGIGILTVILGVLLLIGCW...</td>
<td>HLA-A2</td>
<td>I</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>AAGIGILTVI</td>
<td>MPREDAHFIYGYPKKGHGHSYTTAEEAAGIGILTVILGVLLLIGCW...</td>
<td>HLA-A*02:01</td>
<td>I</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>ACDPHSGHFV</td>
<td>NaN</td>
<td>HLA-A2</td>
<td>I</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>ADLVGFLLLK</td>
<td>MSLEQRSLHCKPEEALEAQQEALGLVCVQAATSSSSPLVLGTLEEV...</td>
<td>HLA-A*11:01</td>
<td>I</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>ADVEFCLSL</td>
<td>MLLAVLYCLLWSFQTSAGHFPRACVSSKNLMEKECCPPWSGDRSPC...</td>
<td>HLA-B*44:03</td>
<td>I</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Retriving the data from IEDB was as simple as doing a search and clicking exoprt. Two files were exported, one containing 28,681 unique epitopes and another with their corresponding assays and respective results. Roughly 10% of the epitopes in the dataset came with a corresponding <a href="https://www.uniprot.org/">UniProt</a> link. For our purposes this will be enough. Using the requests python library, the full antigen sequence was downloaded and appended to the epitope dataset. Next, simple formatting was done to standardize the column names. Finally, the epitope dataset was merged with the assays dataset on the epitope_name column and filtered to include the following columns:</p>
</section>
<section id="negative-sample-generation" class="level3">
<h3 class="anchored" data-anchor-id="negative-sample-generation">Negative Sample Generation</h3>
<div id="939b8245" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_negatives(row):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    epitope <span class="op">=</span> row[<span class="st">"epitope_name"</span>]</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    full_seq <span class="op">=</span> row[<span class="st">"fullsequence"</span>]</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    mhc <span class="op">=</span> row[<span class="st">"mhcrestriction_name"</span>]</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle missing or empty sequences</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.isnull(full_seq) <span class="kw">or</span> full_seq <span class="op">==</span> <span class="st">""</span>:</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> []</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    epitope <span class="op">=</span> <span class="bu">str</span>(epitope)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    full_seq <span class="op">=</span> <span class="bu">str</span>(full_seq)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    ep_len <span class="op">=</span> <span class="bu">len</span>(epitope)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    negatives <span class="op">=</span> []</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(full_seq) <span class="op">-</span> ep_len <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        window <span class="op">=</span> full_seq[i:i<span class="op">+</span>ep_len]</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> window <span class="op">!=</span> epitope:</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>            negatives.append({<span class="st">"peptide"</span>: window, <span class="st">"mhc"</span>: mhc})</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> negatives</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to each row</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> pd.DataFrame()</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'negatives'</span>] <span class="op">=</span> epitopes.<span class="bu">apply</span>(generate_negatives, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives[[<span class="st">"negatives"</span>]].explode(<span class="st">"negatives"</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>negatives.dropna(subset<span class="op">=</span>[<span class="st">"negatives"</span>], inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove duplicate peptide-mhc combinations</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Shape before removing duplicates: </span><span class="sc">{</span>negatives<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.drop_duplicates(subset<span class="op">=</span>[<span class="st">'negatives'</span>])</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Shape after removing duplicates: </span><span class="sc">{</span>negatives<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for any remaining NaN values</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of NaN values in negatives: </span><span class="sc">{</span>negatives[<span class="st">'negatives'</span>]<span class="sc">.</span>isna()<span class="sc">.</span><span class="bu">sum</span>()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract peptide and mhc into separate columns</span></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'peptide'</span>] <span class="op">=</span> negatives[<span class="st">'negatives'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x[<span class="st">'peptide'</span>])</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'mhc'</span>] <span class="op">=</span> negatives[<span class="st">'negatives'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x[<span class="st">'mhc'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Although the IEDB database provided a substantial amount of epitopes, in order draw visual comparisons and create models to classify epitopes, samples of non-epitope peptides are needed. These can be generated by shuffling and sampling amino acid sequences from the full antigen sequences of the epitopes, ensuring that the sampled sequences did not overlap with the epitope sequences.</p>
<p>There are pros and cons to this methodology. As opposed to generating completely random sequences of amino acids — sampling from larger sequences allows for natural patterns and physiochemical motifs to be retained. That is not to say the performance of statistical modeling or qualitative analysis will be better. Random sequences are more likely to be highly irregular, or even biologically implausible. Sampling from the full antigen sequences eliminates this potential bias.</p>
<p>Conversely, it is possible for a randomly sampled peptide to be an epitope that has not been tested yet, or simply isn’t in the subset of data used for this analysis — resulting in an increase in the number of false negatives in our data.</p>
</section>
<section id="feature-engineering" class="level3">
<h3 class="anchored" data-anchor-id="feature-engineering">Feature Engineering</h3>
<div id="0516a398" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Kyte-Doolittle hydrophobicity scale</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>kyte_doolittle <span class="op">=</span> {</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'I'</span>: <span class="fl">4.5</span>, <span class="st">'V'</span>: <span class="fl">4.2</span>, <span class="st">'L'</span>: <span class="fl">3.8</span>, <span class="st">'F'</span>: <span class="fl">2.8</span>, <span class="st">'C'</span>: <span class="fl">2.5</span>,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'M'</span>: <span class="fl">1.9</span>, <span class="st">'A'</span>: <span class="fl">1.8</span>, <span class="st">'G'</span>: <span class="op">-</span><span class="fl">0.4</span>, <span class="st">'T'</span>: <span class="op">-</span><span class="fl">0.7</span>, <span class="st">'S'</span>: <span class="op">-</span><span class="fl">0.8</span>,</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'W'</span>: <span class="op">-</span><span class="fl">0.9</span>, <span class="st">'Y'</span>: <span class="op">-</span><span class="fl">1.3</span>, <span class="st">'P'</span>: <span class="op">-</span><span class="fl">1.6</span>, <span class="st">'H'</span>: <span class="op">-</span><span class="fl">3.2</span>, <span class="st">'E'</span>: <span class="op">-</span><span class="fl">3.5</span>,</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Q'</span>: <span class="op">-</span><span class="fl">3.5</span>, <span class="st">'D'</span>: <span class="op">-</span><span class="fl">3.5</span>, <span class="st">'N'</span>: <span class="op">-</span><span class="fl">3.5</span>, <span class="st">'K'</span>: <span class="op">-</span><span class="fl">3.9</span>, <span class="st">'R'</span>: <span class="op">-</span><span class="fl">4.5</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_avg_hydrophobicity(peptide):</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get hydrophobicity scores for each amino acid; default to 0 if missing</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> [kyte_doolittle.get(aa, <span class="dv">0</span>) <span class="cf">for</span> aa <span class="kw">in</span> peptide]</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">sum</span>(scores) <span class="op">/</span> <span class="bu">len</span>(scores) <span class="cf">if</span> scores <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to the 'peptide' column to create a new column 'avg_hydro'</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'epitope_avg_hydro'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(compute_avg_hydrophobicity)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the molecular_weight function from Bio.SeqUtils</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_molecular_weight(peptide):</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the molecular weight of a peptide sequence using Biopython."""</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.molecular_weight()</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'molecular_weight'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_molecular_weight)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_aromaticity(peptide):</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the aromaticity of a peptide sequence using Biopython."""</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.aromaticity()</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'aromaticity'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_aromaticity)</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_isoelectric_point(peptide):</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the isoelectric point of a peptide sequence using Biopython."""</span></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.isoelectric_point()</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'isoelectric_point'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_isoelectric_point)</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_instability(peptide):</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the instability of a peptide sequence using Biopython."""</span></span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.instability_index()</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'instability'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_instability)</span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_charge_at_pH7(peptide):</span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the charge of a peptide sequence at pH 7 using Biopython."""</span></span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.charge_at_pH(<span class="dv">7</span>)</span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'charge_at_pH7'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_charge_at_pH7)</span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate features on the peptide column</span></span>
<span id="cb4-81"><a href="#cb4-81" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'peptide_length'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(<span class="bu">len</span>)</span>
<span id="cb4-82"><a href="#cb4-82" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'peptide_avg_hydro'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(compute_avg_hydrophobicity)</span>
<span id="cb4-83"><a href="#cb4-83" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'molecular_weight'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_molecular_weight)</span>
<span id="cb4-84"><a href="#cb4-84" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'aromaticity'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_aromaticity)</span>
<span id="cb4-85"><a href="#cb4-85" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'isoelectric_point'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_isoelectric_point)</span>
<span id="cb4-86"><a href="#cb4-86" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'instability'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_instability)</span>
<span id="cb4-87"><a href="#cb4-87" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'charge_at_pH7'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_charge_at_pH7)</span>
<span id="cb4-88"><a href="#cb4-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-89"><a href="#cb4-89" aria-hidden="true" tabindex="-1"></a>negatives.drop(<span class="st">'negatives'</span>, axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The protein analysis tool from the BioPython package allows for some quick feature engineering on most given peptides. For this analysis, the relevant features would be hydrophobicity, molecular weight, aromaticity, isoelectric point, instability, and the charge at pH7. Publications on epitope classification hold binding affinity — the ability for a peptide to bind to the body’s MHC complex — to be a strong preditctor. The BioPython package does not come with any functionality for binding affinity prediction but IEDB database provides a tool called netMHCpan, which is the leading binding affinity prediction algorithm.</p>
<p>The IEDB website offers a GUI for using netMHCpan to predict binding affinities. However, it is only possible to run predictions on 100 peptides at a time and this analysis is examining many more than that. NetMHCpan can be downloaded and installed as a command line tool allowing more flexibility using python. Given an amino acid sequence and a MHC allele specification, netMHCpan returns a binding affinity score.</p>
<div id="65f9b7a5" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.read_csv(<span class="st">"/Users/tariq/Documents/capstone/data/ninemer_epitopes.csv"</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.drop(columns<span class="op">=</span>[<span class="st">'fullsequence'</span>, <span class="st">'mhcrestriction_name'</span>, <span class="st">'mhcrestriction_class'</span>, <span class="st">'epitope_length'</span>])</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.rename(columns<span class="op">=</span>{<span class="st">'epitope_name'</span>: <span class="st">'peptide'</span>, <span class="st">'epitope_avg_hydro'</span>: <span class="st">'peptide_avg_hydro'</span>})</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>epitopes_BA_pred <span class="op">=</span> pd.read_csv(<span class="st">"/Users/tariq/Documents/capstone/data/ninemer_epitopes_BA_pred.csv"</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> pd.read_csv(<span class="st">"/Users/tariq/Documents/capstone/data/ninemer_negatives_trimmed.csv"</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.drop(columns<span class="op">=</span>[<span class="st">'mhc'</span>, <span class="st">'peptide_length'</span>])</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.rename(columns<span class="op">=</span>{<span class="st">'peptide'</span>: <span class="st">'peptide'</span>})</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.drop_duplicates(subset<span class="op">=</span>[<span class="st">'peptide'</span>])</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>negatives_BA_pred <span class="op">=</span> pd.read_csv(<span class="st">"/Users/tariq/Documents/capstone/data/ninemer_negatives_trimmed_BA_pred.csv"</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>negatives_BA_pred <span class="op">=</span> negatives_BA_pred.drop_duplicates(subset<span class="op">=</span>[<span class="st">'peptide'</span>])</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge the 'Score_BA' column from epitopes_BA_pred into the epitopes dataframe</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.merge(epitopes, epitopes_BA_pred[[<span class="st">'peptide'</span>, <span class="st">'Score_BA'</span>]], on<span class="op">=</span><span class="st">'peptide'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> pd.merge(negatives, negatives_BA_pred[[<span class="st">'peptide'</span>, <span class="st">'Score_BA'</span>]], on<span class="op">=</span><span class="st">'peptide'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>epitopes.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="171">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">peptide</th>
<th data-quarto-table-cell-role="th">peptide_avg_hydro</th>
<th data-quarto-table-cell-role="th">molecular_weight</th>
<th data-quarto-table-cell-role="th">aromaticity</th>
<th data-quarto-table-cell-role="th">isoelectric_point</th>
<th data-quarto-table-cell-role="th">instability</th>
<th data-quarto-table-cell-role="th">charge_at_pH7</th>
<th data-quarto-table-cell-role="th">Score_BA</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>AAGIGILTV</td>
<td>2.122222</td>
<td>813.9814</td>
<td>0.000000</td>
<td>5.570017</td>
<td>11.422222</td>
<td>-0.204125</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>ADVEFCLSL</td>
<td>1.233333</td>
<td>996.1348</td>
<td>0.111111</td>
<td>4.050028</td>
<td>20.855556</td>
<td>-2.210095</td>
<td>0.190368</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>AFLPWHRLF</td>
<td>0.533333</td>
<td>1186.4061</td>
<td>0.333333</td>
<td>9.800371</td>
<td>53.400000</td>
<td>0.883039</td>
<td>0.677877</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>ALAETSYVK</td>
<td>0.155556</td>
<td>981.1004</td>
<td>0.111111</td>
<td>6.045191</td>
<td>5.688889</td>
<td>-0.203313</td>
<td>0.652230</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>ALDVYNGLL</td>
<td>0.966667</td>
<td>977.1115</td>
<td>0.111111</td>
<td>4.050028</td>
<td>-16.188889</td>
<td>-1.204004</td>
<td>0.493034</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
<section id="exploratory-analysis" class="level1">
<h1>Exploratory Analysis</h1>
<div id="3272cb5f" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare numeric features between epitopes and negatives datasets</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>numeric_features <span class="op">=</span> [<span class="st">'peptide_avg_hydro'</span>, <span class="st">'molecular_weight'</span>, <span class="st">'aromaticity'</span>, </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'isoelectric_point'</span>, <span class="st">'instability'</span>, <span class="st">'charge_at_pH7'</span>, <span class="st">'Score_BA'</span>]</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a figure with subplots for each numeric feature</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="bu">len</span>(numeric_features), <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span><span class="op">*</span><span class="bu">len</span>(numeric_features)))</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co">#fig.tight_layout(pad=5.0)</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot boxplots for each feature</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, feature <span class="kw">in</span> <span class="bu">enumerate</span>(numeric_features):</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> axes[i]</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a temporary dataframe for plotting</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    plot_data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Epitopes'</span>: epitopes[feature],</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Negatives'</span>: negatives[feature]</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create boxplot</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    sns.boxplot(data<span class="op">=</span>plot_data, ax<span class="op">=</span>ax)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add feature statistics</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    epitope_mean <span class="op">=</span> epitopes[feature].mean()</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    negative_mean <span class="op">=</span> negatives[feature].mean()</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'</span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss"> Distribution Comparison'</span>)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>    ax.text(<span class="fl">0.02</span>, <span class="fl">0.95</span>, <span class="ss">f'Epitopes mean: </span><span class="sc">{</span>epitope_mean<span class="sc">:.4f}</span><span class="ss">'</span>, transform<span class="op">=</span>ax.transAxes)</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    ax.text(<span class="fl">0.02</span>, <span class="fl">0.90</span>, <span class="ss">f'Negatives mean: </span><span class="sc">{</span>negative_mean<span class="sc">:.4f}</span><span class="ss">'</span>, transform<span class="op">=</span>ax.transAxes)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add p-value from t-test</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    t_stat, p_value <span class="op">=</span> stats.ttest_ind(</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>        epitopes[feature].dropna(), </span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>        negatives[feature].dropna(),</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>        equal_var<span class="op">=</span><span class="va">False</span>  <span class="co"># Welch's t-test (doesn't assume equal variances)</span></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>    <span class="co">#ax.text(0.02, 0.85, f'p-value: {p_value:.4e}', transform=ax.transAxes)</span></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.suptitle('Comparison of Numeric Features Between Epitopes and Negatives', fontsize=16)</span></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="blog_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>A boxplot comparison of the numerical variables reveals hardly significant differences between the epitope and non-epitope peptides. The clear outlier being the predicted binding affinity score.</p>
<div id="f3a6c5de" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot Score_BA for epitopes and negatives overlaid on the same plot</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Use density instead of raw counts to normalize the histograms</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>plt.hist(epitopes[<span class="st">'Score_BA'</span>], bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'blue'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Epitopes'</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>plt.hist(negatives[<span class="st">'Score_BA'</span>], bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'red'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, </span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Negatives'</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternative approach: use log scale for y-axis</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>plt.yscale(<span class="st">'log'</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Binding Affinity'</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density (log scale)'</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Normalized Histogram of Binding Affinity for Epitopes vs Negatives'</span>)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>plt.legend(prop<span class="op">=</span>{<span class="st">'size'</span>: <span class="dv">14</span>})  <span class="co"># Increased legend font size</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="blog_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Upon further inspection of the difference in predicted binding affinity score, we see the non-epitope peptides exhibit a right-skewed distribution with a mean of 0.07, and the epitopes show a broad, moderate-variance spread with a much higher mean of 0.56.</p>
</section>
<section id="modeling" class="level1">
<h1>Modeling</h1>
<section id="model-selection" class="level3">
<h3 class="anchored" data-anchor-id="model-selection">Model Selection</h3>
<p>To establish a baseline for performance, a random forest classifier will be fit to the following features:</p>
<ul>
<li>peptide_avg_hydro</li>
<li>molecular_weight</li>
<li>aromaticity</li>
<li>isoelectric_point</li>
<li>instability</li>
<li>charge_at_pH7</li>
<li>Score_BA</li>
</ul>
<p>Performace will be evaluated based on accuracy, precision, and recall.</p>
</section>
<section id="preprocessing-1" class="level3">
<h3 class="anchored" data-anchor-id="preprocessing-1">Preprocessing</h3>
<p>Prior to training, labels are assigned to the epitopes and non-epitopes as 1 or 0 respectively. The two samples are then concatenated, scaled, and shuffled. Finally, the data is split into training and testing sets with an 80/20 ratio.</p>
<div id="cfcb786d" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add label column to epitopes dataframe (positive class = 1)</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'label'</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Add label column to negatives dataframe (negative class = 0)</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'label'</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine the positive and negative examples</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> pd.concat([epitopes, negatives], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Shuffle the combined dataset</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> combined_data.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Define features and target</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> combined_data.drop(columns<span class="op">=</span>[<span class="st">'peptide'</span>, <span class="st">'label'</span>])</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> combined_data[<span class="st">'label'</span>]</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify numerical columns to scale (exclude one-hot encoded amino acid columns)</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>numerical_cols <span class="op">=</span> [<span class="st">'peptide_avg_hydro'</span>, <span class="st">'molecular_weight'</span>, <span class="st">'aromaticity'</span>, <span class="st">'isoelectric_point'</span>, <span class="st">'instability'</span>,<span class="st">'Score_BA'</span>, <span class="st">'charge_at_pH7'</span>]</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets (80% train, 20% test)</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Scale numerical features using StandardScaler</span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>X_train[numerical_cols] <span class="op">=</span> scaler.fit_transform(X_train[numerical_cols])</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>X_test[numerical_cols] <span class="op">=</span> scaler.transform(X_test[numerical_cols])</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the shapes to verify the split</span></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training set: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Testing set: </span><span class="sc">{</span>X_test<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in training: </span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in training: </span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in testing: </span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in testing: </span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Training set: 20502 samples
Testing set: 5126 samples
Positive samples in training: 4236
Negative samples in training: 16266
Positive samples in testing: 1059
Negative samples in testing: 4067</code></pre>
</div>
</div>
</section>
<section id="training-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="training-evaluation">Training + Evaluation</h3>
<p>The random forest classifier is fit to the training data and evaluated on the testing data.</p>
<div id="b64ba7fc" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Random Forest Classifier</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,  <span class="co"># Number of trees</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="va">None</span>,    <span class="co"># Maximum depth of trees</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X_train, y_train)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> rf_model.predict(X_test)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> rf_model.predict_proba(X_test)[:, <span class="dv">1</span>]  <span class="co"># Probability estimates for positive class</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Confusion Matrix</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, </span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>[<span class="st">'Predicted Negative'</span>, <span class="st">'Predicted Positive'</span>], </span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>            yticklabels<span class="op">=</span>[<span class="st">'Actual Negative'</span>, <span class="st">'Actual Positive'</span>])</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Label'</span>)</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Label'</span>)</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix - Random Forest'</span>)</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Random Forest Model Evaluation:"</span>)</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, y_pred)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classification Report:"</span>)</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate ROC AUC</span></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> roc_auc_score(y_test, y_pred_proba)</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">ROC AUC Score: </span><span class="sc">{</span>roc_auc<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="blog_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Random Forest Model Evaluation:
Accuracy: 0.9126

Classification Report:
              precision    recall  f1-score   support

           0       0.94      0.96      0.95      4067
           1       0.81      0.75      0.78      1059

    accuracy                           0.91      5126
   macro avg       0.88      0.85      0.86      5126
weighted avg       0.91      0.91      0.91      5126


ROC AUC Score: 0.9512</code></pre>
</div>
</div>
<p>The results show strong performance from the random forest classifier, with an overall accuracy of 91% and recall of 75% for the positive class.</p>
<div id="cell-Fig-1" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature importance</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> pd.DataFrame({</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: X_train.columns,</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: rf_model.feature_importances_</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> feature_importance.sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot top 15 features</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>top_features <span class="op">=</span> feature_importance.head(<span class="dv">15</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>plt.barh(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Importance'</span>], align<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>plt.yticks(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Feature'</span>])</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Importance'</span>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Feature Importance - Random Forest'</span>)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="blog_files/figure-html/fig-1-output-1.png" id="fig-1" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1
</figcaption>
</figure>
</div>
</div>
</div>
<p>Although the random forest classifier in <a href="#fig-1" class="quarto-xref">Figure&nbsp;1</a> is performing well, the feature importance plot reveals a concentration of importance on the predicted binding affinity score obtained from netMHCpan. This is not surprising.</p>
</section>
<section id="training-without-netmhcpan" class="level3">
<h3 class="anchored" data-anchor-id="training-without-netmhcpan">Training without netMHCpan</h3>
<div id="a7c1d0d1" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># drop the Score_BA column</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train.drop(columns<span class="op">=</span>[<span class="st">'Score_BA'</span>])</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X_test.drop(columns<span class="op">=</span>[<span class="st">'Score_BA'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="9ba695b3" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Random Forest Classifier</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,  <span class="co"># Number of trees</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="va">None</span>,    <span class="co"># Maximum depth of trees</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X_train, y_train)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> rf_model.predict(X_test)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> rf_model.predict_proba(X_test)[:, <span class="dv">1</span>]  <span class="co"># Probability estimates for positive class</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Confusion Matrix</span></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, </span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>[<span class="st">'Predicted Negative'</span>, <span class="st">'Predicted Positive'</span>], </span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>            yticklabels<span class="op">=</span>[<span class="st">'Actual Negative'</span>, <span class="st">'Actual Positive'</span>])</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Label'</span>)</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Label'</span>)</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix - Random Forest'</span>)</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Random Forest Model Evaluation:"</span>)</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, y_pred)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classification Report:"</span>)</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate ROC AUC</span></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> roc_auc_score(y_test, y_pred_proba)</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">ROC AUC Score: </span><span class="sc">{</span>roc_auc<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="blog_files/figure-html/cell-13-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Random Forest Model Evaluation:
Accuracy: 0.7877

Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.95      0.88      4067
           1       0.46      0.18      0.26      1059

    accuracy                           0.79      5126
   macro avg       0.64      0.56      0.57      5126
weighted avg       0.74      0.79      0.75      5126


ROC AUC Score: 0.6988</code></pre>
</div>
</div>
<div id="cell-Fig-2" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature importance</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> pd.DataFrame({</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: X_train.columns,</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: rf_model.feature_importances_</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> feature_importance.sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot top 15 features</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>top_features <span class="op">=</span> feature_importance.head(<span class="dv">15</span>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>plt.barh(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Importance'</span>], align<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>plt.yticks(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Feature'</span>])</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Importance'</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Feature Importance - Random Forest'</span>)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="blog_files/figure-html/fig-2-output-1.png" id="fig-2" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="basic-convolutional-neural-network" class="level3">
<h3 class="anchored" data-anchor-id="basic-convolutional-neural-network">Basic Convolutional Neural Network</h3>
<div id="116786f3" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.preprocessing.sequence <span class="im">import</span> pad_sequences</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Filter the epitopes and negatives dataframes to only contain sequences and labels</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>epitopes_filtered <span class="op">=</span> epitopes[[<span class="st">'peptide'</span>, <span class="st">'label'</span>]].copy()</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>epitopes_filtered.rename(columns<span class="op">=</span>{<span class="st">'peptide'</span>: <span class="st">'sequence'</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>negatives_filtered <span class="op">=</span> negatives[[<span class="st">'peptide'</span>, <span class="st">'label'</span>]].copy()</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>negatives_filtered.rename(columns<span class="op">=</span>{<span class="st">'peptide'</span>: <span class="st">'sequence'</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine the datasets</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> pd.concat([epitopes_filtered, negatives_filtered], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> combined_data.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of samples: </span><span class="sc">{</span>combined_data<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples: </span><span class="sc">{</span><span class="bu">sum</span>(combined_data[<span class="st">'label'</span>] <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples: </span><span class="sc">{</span><span class="bu">sum</span>(combined_data[<span class="st">'label'</span>] <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Prepare for one-hot encoding</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="co"># First, get all unique amino acids in our dataset</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>all_sequences <span class="op">=</span> combined_data[<span class="st">'sequence'</span>].values</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>unique_chars <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">set</span>(<span class="st">''</span>.join(all_sequences)))</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Unique amino acids in dataset: </span><span class="sc">{</span>unique_chars<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Create mapping dictionaries for one-hot encoding</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>char_to_index <span class="op">=</span> {char: i<span class="op">+</span><span class="dv">1</span> <span class="cf">for</span> i, char <span class="kw">in</span> <span class="bu">enumerate</span>(unique_chars)}  <span class="co"># Start from 1, reserve 0 for padding</span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>index_to_char <span class="op">=</span> {i<span class="op">+</span><span class="dv">1</span>: char <span class="cf">for</span> i, char <span class="kw">in</span> <span class="bu">enumerate</span>(unique_chars)}</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>index_to_char[<span class="dv">0</span>] <span class="op">=</span> <span class="st">''</span>  <span class="co"># Padding token</span></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Find maximum sequence length</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>max_length <span class="op">=</span> <span class="bu">max</span>(<span class="bu">len</span>(seq) <span class="cf">for</span> seq <span class="kw">in</span> all_sequences)</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Maximum sequence length: </span><span class="sc">{</span>max_length<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert sequences to integer sequences</span></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>int_sequences <span class="op">=</span> []</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> seq <span class="kw">in</span> all_sequences:</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>    int_seq <span class="op">=</span> [char_to_index[char] <span class="cf">for</span> char <span class="kw">in</span> seq]</span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>    int_sequences.append(int_seq)</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Pad sequences to have the same length</span></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>padded_sequences <span class="op">=</span> pad_sequences(int_sequences, maxlen<span class="op">=</span>max_length, padding<span class="op">=</span><span class="st">'post'</span>)</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a><span class="co"># One-hot encode the padded sequences</span></span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>num_chars <span class="op">=</span> <span class="bu">len</span>(unique_chars) <span class="op">+</span> <span class="dv">1</span>  <span class="co"># +1 for padding token</span></span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>X_onehot <span class="op">=</span> np.zeros((<span class="bu">len</span>(padded_sequences), max_length, num_chars))</span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, seq <span class="kw">in</span> <span class="bu">enumerate</span>(padded_sequences):</span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j, char_idx <span class="kw">in</span> <span class="bu">enumerate</span>(seq):</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a>        X_onehot[i, j, char_idx] <span class="op">=</span> <span class="fl">1.0</span>  <span class="co"># One-hot encode</span></span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Get labels</span></span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> combined_data[<span class="st">'label'</span>].values</span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Print shapes to verify dimensions</span></span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X_onehot shape: </span><span class="sc">{</span>X_onehot<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of unique amino acids (including padding): </span><span class="sc">{</span>num_chars<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Split data into training, validation, and testing sets (70/15/15 split)</span></span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a><span class="co"># First split into temporary train and test</span></span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a>X_temp, X_test, y_temp, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a>    X_onehot, y, test_size<span class="op">=</span><span class="fl">0.15</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y</span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-64"><a href="#cb17-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-65"><a href="#cb17-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Then split the temporary train into final train and validation</span></span>
<span id="cb17-66"><a href="#cb17-66" aria-hidden="true" tabindex="-1"></a><span class="co"># To get 70/15 split from the original data, we need to calculate the right proportion:</span></span>
<span id="cb17-67"><a href="#cb17-67" aria-hidden="true" tabindex="-1"></a><span class="co"># If test is 15% of total, then validation should be 15/85 of the remaining data (approx 17.65%)</span></span>
<span id="cb17-68"><a href="#cb17-68" aria-hidden="true" tabindex="-1"></a>X_train, X_val, y_train, y_val <span class="op">=</span> train_test_split(</span>
<span id="cb17-69"><a href="#cb17-69" aria-hidden="true" tabindex="-1"></a>    X_temp, y_temp, test_size<span class="op">=</span><span class="fl">0.1765</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y_temp</span>
<span id="cb17-70"><a href="#cb17-70" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-71"><a href="#cb17-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-72"><a href="#cb17-72" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training set shape: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>X_train<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="op">/</span>X_onehot<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss"> of total)"</span>)</span>
<span id="cb17-73"><a href="#cb17-73" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Validation set shape: </span><span class="sc">{</span>X_val<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>X_val<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="op">/</span>X_onehot<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss"> of total)"</span>)</span>
<span id="cb17-74"><a href="#cb17-74" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Testing set shape: </span><span class="sc">{</span>X_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>X_test<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="op">/</span>X_onehot<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss"> of total)"</span>)</span>
<span id="cb17-75"><a href="#cb17-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-76"><a href="#cb17-76" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in training: </span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">1</span>)<span class="op">/</span><span class="bu">len</span>(y_train)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb17-77"><a href="#cb17-77" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in training: </span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">0</span>)<span class="op">/</span><span class="bu">len</span>(y_train)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb17-78"><a href="#cb17-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-79"><a href="#cb17-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in validation: </span><span class="sc">{</span><span class="bu">sum</span>(y_val <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_val <span class="op">==</span> <span class="dv">1</span>)<span class="op">/</span><span class="bu">len</span>(y_val)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb17-80"><a href="#cb17-80" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in validation: </span><span class="sc">{</span><span class="bu">sum</span>(y_val <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_val <span class="op">==</span> <span class="dv">0</span>)<span class="op">/</span><span class="bu">len</span>(y_val)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb17-81"><a href="#cb17-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-82"><a href="#cb17-82" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in testing: </span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">1</span>)<span class="op">/</span><span class="bu">len</span>(y_test)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb17-83"><a href="#cb17-83" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in testing: </span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">0</span>)<span class="op">/</span><span class="bu">len</span>(y_test)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb17-84"><a href="#cb17-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-85"><a href="#cb17-85" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb17-86"><a href="#cb17-86" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Sequential, Model</span>
<span id="cb17-87"><a href="#cb17-87" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input, BatchNormalization</span>
<span id="cb17-88"><a href="#cb17-88" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.callbacks <span class="im">import</span> EarlyStopping, ModelCheckpoint, ReduceLROnPlateau</span>
<span id="cb17-89"><a href="#cb17-89" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.regularizers <span class="im">import</span> l2</span>
<span id="cb17-90"><a href="#cb17-90" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.optimizers <span class="im">import</span> Adam</span>
<span id="cb17-91"><a href="#cb17-91" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_curve, f1_score</span>
<span id="cb17-92"><a href="#cb17-92" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-93"><a href="#cb17-93" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb17-94"><a href="#cb17-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-95"><a href="#cb17-95" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the focal loss function to better handle class imbalance</span></span>
<span id="cb17-96"><a href="#cb17-96" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> focal_loss(gamma<span class="op">=</span><span class="fl">2.0</span>, alpha<span class="op">=</span><span class="fl">0.25</span>):</span>
<span id="cb17-97"><a href="#cb17-97" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> focal_loss_fn(y_true, y_pred):</span>
<span id="cb17-98"><a href="#cb17-98" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert one-hot encoded targets to integers</span></span>
<span id="cb17-99"><a href="#cb17-99" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> y_true.shape[<span class="op">-</span><span class="dv">1</span>] <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb17-100"><a href="#cb17-100" aria-hidden="true" tabindex="-1"></a>            y_true <span class="op">=</span> tf.squeeze(y_true, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb17-101"><a href="#cb17-101" aria-hidden="true" tabindex="-1"></a>        y_true <span class="op">=</span> tf.cast(y_true, tf.int32)</span>
<span id="cb17-102"><a href="#cb17-102" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-103"><a href="#cb17-103" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the standard sparse categorical crossentropy</span></span>
<span id="cb17-104"><a href="#cb17-104" aria-hidden="true" tabindex="-1"></a>        sce <span class="op">=</span> tf.keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">False</span>, reduction<span class="op">=</span>tf.keras.losses.Reduction.NONE)(y_true, y_pred)</span>
<span id="cb17-105"><a href="#cb17-105" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-106"><a href="#cb17-106" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the prediction probability for the true class</span></span>
<span id="cb17-107"><a href="#cb17-107" aria-hidden="true" tabindex="-1"></a>        y_pred_proba <span class="op">=</span> tf.gather_nd(y_pred, tf.stack([tf.<span class="bu">range</span>(tf.shape(y_true)[<span class="dv">0</span>]), tf.cast(y_true, tf.int32)], axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb17-108"><a href="#cb17-108" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-109"><a href="#cb17-109" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply focal loss formula</span></span>
<span id="cb17-110"><a href="#cb17-110" aria-hidden="true" tabindex="-1"></a>        <span class="co"># p_t = p if y == 1 else 1-p for class 0</span></span>
<span id="cb17-111"><a href="#cb17-111" aria-hidden="true" tabindex="-1"></a>        p_t <span class="op">=</span> y_pred_proba</span>
<span id="cb17-112"><a href="#cb17-112" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add the alpha weighing factor</span></span>
<span id="cb17-113"><a href="#cb17-113" aria-hidden="true" tabindex="-1"></a>        alpha_factor <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb17-114"><a href="#cb17-114" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> alpha <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb17-115"><a href="#cb17-115" aria-hidden="true" tabindex="-1"></a>            <span class="co"># alpha_t = alpha if y == 1 else 1-alpha for class 0</span></span>
<span id="cb17-116"><a href="#cb17-116" aria-hidden="true" tabindex="-1"></a>            alpha_t <span class="op">=</span> tf.where(tf.equal(y_true, <span class="dv">1</span>), alpha, <span class="dv">1</span><span class="op">-</span>alpha)</span>
<span id="cb17-117"><a href="#cb17-117" aria-hidden="true" tabindex="-1"></a>            alpha_factor <span class="op">=</span> alpha_t</span>
<span id="cb17-118"><a href="#cb17-118" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-119"><a href="#cb17-119" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate focal weight</span></span>
<span id="cb17-120"><a href="#cb17-120" aria-hidden="true" tabindex="-1"></a>        gamma_factor <span class="op">=</span> tf.<span class="bu">pow</span>(<span class="fl">1.0</span> <span class="op">-</span> p_t, gamma)</span>
<span id="cb17-121"><a href="#cb17-121" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-122"><a href="#cb17-122" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the final loss</span></span>
<span id="cb17-123"><a href="#cb17-123" aria-hidden="true" tabindex="-1"></a>        focal_loss <span class="op">=</span> alpha_factor <span class="op">*</span> gamma_factor <span class="op">*</span> sce</span>
<span id="cb17-124"><a href="#cb17-124" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-125"><a href="#cb17-125" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> tf.reduce_mean(focal_loss)</span>
<span id="cb17-126"><a href="#cb17-126" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-127"><a href="#cb17-127" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> focal_loss_fn</span>
<span id="cb17-128"><a href="#cb17-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-129"><a href="#cb17-129" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an optimized CNN model for sequence data</span></span>
<span id="cb17-130"><a href="#cb17-130" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_optimized_cnn_model(input_shape, num_classes<span class="op">=</span><span class="dv">2</span>, use_focal_loss<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb17-131"><a href="#cb17-131" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> Input(shape<span class="op">=</span>input_shape)</span>
<span id="cb17-132"><a href="#cb17-132" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-133"><a href="#cb17-133" aria-hidden="true" tabindex="-1"></a>    <span class="co"># First convolutional block</span></span>
<span id="cb17-134"><a href="#cb17-134" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv1D(<span class="dv">32</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">'relu'</span>, padding<span class="op">=</span><span class="st">'same'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(inputs)</span>
<span id="cb17-135"><a href="#cb17-135" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb17-136"><a href="#cb17-136" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> MaxPooling1D(pool_size<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">'same'</span>)(x)</span>
<span id="cb17-137"><a href="#cb17-137" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-138"><a href="#cb17-138" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Second convolutional block with increased filters</span></span>
<span id="cb17-139"><a href="#cb17-139" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv1D(<span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">'relu'</span>, padding<span class="op">=</span><span class="st">'same'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(x)</span>
<span id="cb17-140"><a href="#cb17-140" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb17-141"><a href="#cb17-141" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> MaxPooling1D(pool_size<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">'same'</span>)(x)</span>
<span id="cb17-142"><a href="#cb17-142" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-143"><a href="#cb17-143" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Third convolutional block with even more filters</span></span>
<span id="cb17-144"><a href="#cb17-144" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv1D(<span class="dv">128</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">'relu'</span>, padding<span class="op">=</span><span class="st">'same'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(x)</span>
<span id="cb17-145"><a href="#cb17-145" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb17-146"><a href="#cb17-146" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-147"><a href="#cb17-147" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Flatten and dense layers</span></span>
<span id="cb17-148"><a href="#cb17-148" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Flatten()(x)</span>
<span id="cb17-149"><a href="#cb17-149" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-150"><a href="#cb17-150" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add more capacity to the dense layers</span></span>
<span id="cb17-151"><a href="#cb17-151" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">'relu'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(x)</span>
<span id="cb17-152"><a href="#cb17-152" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb17-153"><a href="#cb17-153" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dropout(<span class="fl">0.4</span>)(x)</span>
<span id="cb17-154"><a href="#cb17-154" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-155"><a href="#cb17-155" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(x)</span>
<span id="cb17-156"><a href="#cb17-156" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb17-157"><a href="#cb17-157" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dropout(<span class="fl">0.3</span>)(x)</span>
<span id="cb17-158"><a href="#cb17-158" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-159"><a href="#cb17-159" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Output layer</span></span>
<span id="cb17-160"><a href="#cb17-160" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> Dense(num_classes, activation<span class="op">=</span><span class="st">'softmax'</span>)(x)</span>
<span id="cb17-161"><a href="#cb17-161" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-162"><a href="#cb17-162" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs)</span>
<span id="cb17-163"><a href="#cb17-163" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-164"><a href="#cb17-164" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use a lower learning rate for better stability</span></span>
<span id="cb17-165"><a href="#cb17-165" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> Adam(learning_rate<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb17-166"><a href="#cb17-166" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-167"><a href="#cb17-167" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use focal loss if requested, otherwise use standard cross-entropy</span></span>
<span id="cb17-168"><a href="#cb17-168" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> use_focal_loss:</span>
<span id="cb17-169"><a href="#cb17-169" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> focal_loss(gamma<span class="op">=</span><span class="fl">2.0</span>, alpha<span class="op">=</span><span class="fl">0.75</span>)  <span class="co"># Adjust alpha based on class imbalance</span></span>
<span id="cb17-170"><a href="#cb17-170" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb17-171"><a href="#cb17-171" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> <span class="st">'sparse_categorical_crossentropy'</span></span>
<span id="cb17-172"><a href="#cb17-172" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-173"><a href="#cb17-173" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(</span>
<span id="cb17-174"><a href="#cb17-174" aria-hidden="true" tabindex="-1"></a>        optimizer<span class="op">=</span>optimizer,</span>
<span id="cb17-175"><a href="#cb17-175" aria-hidden="true" tabindex="-1"></a>        loss<span class="op">=</span>loss,</span>
<span id="cb17-176"><a href="#cb17-176" aria-hidden="true" tabindex="-1"></a>        metrics<span class="op">=</span>[<span class="st">'accuracy'</span>]</span>
<span id="cb17-177"><a href="#cb17-177" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb17-178"><a href="#cb17-178" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-179"><a href="#cb17-179" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb17-180"><a href="#cb17-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-181"><a href="#cb17-181" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate class weights based on class frequencies</span></span>
<span id="cb17-182"><a href="#cb17-182" aria-hidden="true" tabindex="-1"></a><span class="co"># This gives more weight to the minority class during training</span></span>
<span id="cb17-183"><a href="#cb17-183" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_class_weights(y_train):</span>
<span id="cb17-184"><a href="#cb17-184" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Count the number of samples per class</span></span>
<span id="cb17-185"><a href="#cb17-185" aria-hidden="true" tabindex="-1"></a>    class_counts <span class="op">=</span> np.bincount(y_train)</span>
<span id="cb17-186"><a href="#cb17-186" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the weight for each class (inversely proportional to class frequency)</span></span>
<span id="cb17-187"><a href="#cb17-187" aria-hidden="true" tabindex="-1"></a>    total_samples <span class="op">=</span> <span class="bu">len</span>(y_train)</span>
<span id="cb17-188"><a href="#cb17-188" aria-hidden="true" tabindex="-1"></a>    class_weights <span class="op">=</span> {</span>
<span id="cb17-189"><a href="#cb17-189" aria-hidden="true" tabindex="-1"></a>        i: total_samples <span class="op">/</span> (<span class="bu">len</span>(class_counts) <span class="op">*</span> count) </span>
<span id="cb17-190"><a href="#cb17-190" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, count <span class="kw">in</span> <span class="bu">enumerate</span>(class_counts)</span>
<span id="cb17-191"><a href="#cb17-191" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb17-192"><a href="#cb17-192" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> class_weights</span>
<span id="cb17-193"><a href="#cb17-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-194"><a href="#cb17-194" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the class weights for our training data</span></span>
<span id="cb17-195"><a href="#cb17-195" aria-hidden="true" tabindex="-1"></a>class_weights <span class="op">=</span> compute_class_weights(y_train)</span>
<span id="cb17-196"><a href="#cb17-196" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Class weights: </span><span class="sc">{</span>class_weights<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-197"><a href="#cb17-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-198"><a href="#cb17-198" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an optimized CNN model</span></span>
<span id="cb17-199"><a href="#cb17-199" aria-hidden="true" tabindex="-1"></a>optimized_cnn_model <span class="op">=</span> create_optimized_cnn_model(input_shape<span class="op">=</span>(X_train.shape[<span class="dv">1</span>], X_train.shape[<span class="dv">2</span>]), use_focal_loss<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb17-200"><a href="#cb17-200" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(optimized_cnn_model.summary())</span>
<span id="cb17-201"><a href="#cb17-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-202"><a href="#cb17-202" aria-hidden="true" tabindex="-1"></a><span class="co"># Define more sophisticated callbacks</span></span>
<span id="cb17-203"><a href="#cb17-203" aria-hidden="true" tabindex="-1"></a>early_stopping <span class="op">=</span> EarlyStopping(</span>
<span id="cb17-204"><a href="#cb17-204" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_loss'</span>, </span>
<span id="cb17-205"><a href="#cb17-205" aria-hidden="true" tabindex="-1"></a>    patience<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb17-206"><a href="#cb17-206" aria-hidden="true" tabindex="-1"></a>    restore_best_weights<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb17-207"><a href="#cb17-207" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span></span>
<span id="cb17-208"><a href="#cb17-208" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-209"><a href="#cb17-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-210"><a href="#cb17-210" aria-hidden="true" tabindex="-1"></a>reduce_lr <span class="op">=</span> ReduceLROnPlateau(</span>
<span id="cb17-211"><a href="#cb17-211" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_loss'</span>,</span>
<span id="cb17-212"><a href="#cb17-212" aria-hidden="true" tabindex="-1"></a>    factor<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb17-213"><a href="#cb17-213" aria-hidden="true" tabindex="-1"></a>    patience<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb17-214"><a href="#cb17-214" aria-hidden="true" tabindex="-1"></a>    min_lr<span class="op">=</span><span class="fl">0.00001</span>,</span>
<span id="cb17-215"><a href="#cb17-215" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span></span>
<span id="cb17-216"><a href="#cb17-216" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-217"><a href="#cb17-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-218"><a href="#cb17-218" aria-hidden="true" tabindex="-1"></a>model_checkpoint <span class="op">=</span> ModelCheckpoint(</span>
<span id="cb17-219"><a href="#cb17-219" aria-hidden="true" tabindex="-1"></a>    <span class="st">'best_optimized_cnn_model.keras'</span>,</span>
<span id="cb17-220"><a href="#cb17-220" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_accuracy'</span>,</span>
<span id="cb17-221"><a href="#cb17-221" aria-hidden="true" tabindex="-1"></a>    save_best_only<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb17-222"><a href="#cb17-222" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span></span>
<span id="cb17-223"><a href="#cb17-223" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-224"><a href="#cb17-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-225"><a href="#cb17-225" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model with class weights</span></span>
<span id="cb17-226"><a href="#cb17-226" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> optimized_cnn_model.fit(</span>
<span id="cb17-227"><a href="#cb17-227" aria-hidden="true" tabindex="-1"></a>    X_train, y_train,</span>
<span id="cb17-228"><a href="#cb17-228" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">20</span>,  <span class="co"># Increase epochs since we have early stopping</span></span>
<span id="cb17-229"><a href="#cb17-229" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb17-230"><a href="#cb17-230" aria-hidden="true" tabindex="-1"></a>    validation_data<span class="op">=</span>(X_val, y_val),</span>
<span id="cb17-231"><a href="#cb17-231" aria-hidden="true" tabindex="-1"></a>    callbacks<span class="op">=</span>[early_stopping, reduce_lr, model_checkpoint],</span>
<span id="cb17-232"><a href="#cb17-232" aria-hidden="true" tabindex="-1"></a>    class_weight<span class="op">=</span>class_weights,  <span class="co"># Use class weights during training</span></span>
<span id="cb17-233"><a href="#cb17-233" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span></span>
<span id="cb17-234"><a href="#cb17-234" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-235"><a href="#cb17-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-236"><a href="#cb17-236" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model on test data</span></span>
<span id="cb17-237"><a href="#cb17-237" aria-hidden="true" tabindex="-1"></a>test_loss, test_accuracy <span class="op">=</span> optimized_cnn_model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb17-238"><a href="#cb17-238" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test accuracy: </span><span class="sc">{</span>test_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb17-239"><a href="#cb17-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-240"><a href="#cb17-240" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on test data</span></span>
<span id="cb17-241"><a href="#cb17-241" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> optimized_cnn_model.predict(X_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb17-242"><a href="#cb17-242" aria-hidden="true" tabindex="-1"></a>y_pred_proba_positive <span class="op">=</span> y_pred_proba[:, <span class="dv">1</span>]  <span class="co"># Probability for positive class</span></span>
<span id="cb17-243"><a href="#cb17-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-244"><a href="#cb17-244" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the optimal threshold for F1 score</span></span>
<span id="cb17-245"><a href="#cb17-245" aria-hidden="true" tabindex="-1"></a>thresholds <span class="op">=</span> np.arange(<span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="fl">0.05</span>)</span>
<span id="cb17-246"><a href="#cb17-246" aria-hidden="true" tabindex="-1"></a>f1_scores <span class="op">=</span> []</span>
<span id="cb17-247"><a href="#cb17-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-248"><a href="#cb17-248" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> threshold <span class="kw">in</span> thresholds:</span>
<span id="cb17-249"><a href="#cb17-249" aria-hidden="true" tabindex="-1"></a>    y_pred_thresholded <span class="op">=</span> (y_pred_proba_positive <span class="op">&gt;=</span> threshold).astype(<span class="bu">int</span>)</span>
<span id="cb17-250"><a href="#cb17-250" aria-hidden="true" tabindex="-1"></a>    f1 <span class="op">=</span> f1_score(y_test, y_pred_thresholded)</span>
<span id="cb17-251"><a href="#cb17-251" aria-hidden="true" tabindex="-1"></a>    f1_scores.append(f1)</span>
<span id="cb17-252"><a href="#cb17-252" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(f"Threshold: {threshold:.2f}, F1 Score: {f1:.4f}")</span></span>
<span id="cb17-253"><a href="#cb17-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-254"><a href="#cb17-254" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the best threshold</span></span>
<span id="cb17-255"><a href="#cb17-255" aria-hidden="true" tabindex="-1"></a>best_threshold_idx <span class="op">=</span> np.argmax(f1_scores)</span>
<span id="cb17-256"><a href="#cb17-256" aria-hidden="true" tabindex="-1"></a>best_threshold <span class="op">=</span> thresholds[best_threshold_idx]</span>
<span id="cb17-257"><a href="#cb17-257" aria-hidden="true" tabindex="-1"></a>best_f1 <span class="op">=</span> f1_scores[best_threshold_idx]</span>
<span id="cb17-258"><a href="#cb17-258" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Optimal threshold: </span><span class="sc">{</span>best_threshold<span class="sc">:.2f}</span><span class="ss"> with F1 Score: </span><span class="sc">{</span>best_f1<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb17-259"><a href="#cb17-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-260"><a href="#cb17-260" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the best threshold</span></span>
<span id="cb17-261"><a href="#cb17-261" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> (y_pred_proba_positive <span class="op">&gt;=</span> best_threshold).astype(<span class="bu">int</span>)</span>
<span id="cb17-262"><a href="#cb17-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-263"><a href="#cb17-263" aria-hidden="true" tabindex="-1"></a><span class="co"># Print classification report with the optimized threshold</span></span>
<span id="cb17-264"><a href="#cb17-264" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix</span>
<span id="cb17-265"><a href="#cb17-265" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classification Report with Optimized Threshold:"</span>)</span>
<span id="cb17-266"><a href="#cb17-266" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span>
<span id="cb17-267"><a href="#cb17-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-268"><a href="#cb17-268" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot confusion matrix</span></span>
<span id="cb17-269"><a href="#cb17-269" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb17-270"><a href="#cb17-270" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb17-271"><a href="#cb17-271" aria-hidden="true" tabindex="-1"></a>plt.imshow(cm, interpolation<span class="op">=</span><span class="st">'nearest'</span>, cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb17-272"><a href="#cb17-272" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix (Optimized Threshold)'</span>)</span>
<span id="cb17-273"><a href="#cb17-273" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb17-274"><a href="#cb17-274" aria-hidden="true" tabindex="-1"></a>tick_marks <span class="op">=</span> np.arange(<span class="dv">2</span>)</span>
<span id="cb17-275"><a href="#cb17-275" aria-hidden="true" tabindex="-1"></a>plt.xticks(tick_marks, [<span class="st">'Negative'</span>, <span class="st">'Positive'</span>])</span>
<span id="cb17-276"><a href="#cb17-276" aria-hidden="true" tabindex="-1"></a>plt.yticks(tick_marks, [<span class="st">'Negative'</span>, <span class="st">'Positive'</span>])</span>
<span id="cb17-277"><a href="#cb17-277" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Label'</span>)</span>
<span id="cb17-278"><a href="#cb17-278" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Label'</span>)</span>
<span id="cb17-279"><a href="#cb17-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-280"><a href="#cb17-280" aria-hidden="true" tabindex="-1"></a><span class="co"># Add text annotations to the confusion matrix</span></span>
<span id="cb17-281"><a href="#cb17-281" aria-hidden="true" tabindex="-1"></a>thresh <span class="op">=</span> cm.<span class="bu">max</span>() <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb17-282"><a href="#cb17-282" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(cm.shape[<span class="dv">0</span>]):</span>
<span id="cb17-283"><a href="#cb17-283" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(cm.shape[<span class="dv">1</span>]):</span>
<span id="cb17-284"><a href="#cb17-284" aria-hidden="true" tabindex="-1"></a>        plt.text(j, i, cm[i, j],</span>
<span id="cb17-285"><a href="#cb17-285" aria-hidden="true" tabindex="-1"></a>                 horizontalalignment<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb17-286"><a href="#cb17-286" aria-hidden="true" tabindex="-1"></a>                 color<span class="op">=</span><span class="st">"white"</span> <span class="cf">if</span> cm[i, j] <span class="op">&gt;</span> thresh <span class="cf">else</span> <span class="st">"black"</span>)</span>
<span id="cb17-287"><a href="#cb17-287" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb17-288"><a href="#cb17-288" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-289"><a href="#cb17-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-290"><a href="#cb17-290" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot training history</span></span>
<span id="cb17-291"><a href="#cb17-291" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb17-292"><a href="#cb17-292" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb17-293"><a href="#cb17-293" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'accuracy'</span>], label<span class="op">=</span><span class="st">'Training Accuracy'</span>)</span>
<span id="cb17-294"><a href="#cb17-294" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'val_accuracy'</span>], label<span class="op">=</span><span class="st">'Validation Accuracy'</span>)</span>
<span id="cb17-295"><a href="#cb17-295" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Model Accuracy'</span>)</span>
<span id="cb17-296"><a href="#cb17-296" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb17-297"><a href="#cb17-297" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb17-298"><a href="#cb17-298" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb17-299"><a href="#cb17-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-300"><a href="#cb17-300" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb17-301"><a href="#cb17-301" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'loss'</span>], label<span class="op">=</span><span class="st">'Training Loss'</span>)</span>
<span id="cb17-302"><a href="#cb17-302" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'val_loss'</span>], label<span class="op">=</span><span class="st">'Validation Loss'</span>)</span>
<span id="cb17-303"><a href="#cb17-303" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Model Loss'</span>)</span>
<span id="cb17-304"><a href="#cb17-304" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb17-305"><a href="#cb17-305" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb17-306"><a href="#cb17-306" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb17-307"><a href="#cb17-307" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb17-308"><a href="#cb17-308" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-309"><a href="#cb17-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-310"><a href="#cb17-310" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot ROC curve</span></span>
<span id="cb17-311"><a href="#cb17-311" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, auc</span>
<span id="cb17-312"><a href="#cb17-312" aria-hidden="true" tabindex="-1"></a>fpr, tpr, _ <span class="op">=</span> roc_curve(y_test, y_pred_proba_positive)</span>
<span id="cb17-313"><a href="#cb17-313" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb17-314"><a href="#cb17-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-315"><a href="#cb17-315" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb17-316"><a href="#cb17-316" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr, tpr, color<span class="op">=</span><span class="st">'darkorange'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="ss">f'ROC curve (area = </span><span class="sc">{</span>roc_auc<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb17-317"><a href="#cb17-317" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'navy'</span>, lw<span class="op">=</span><span class="dv">2</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb17-318"><a href="#cb17-318" aria-hidden="true" tabindex="-1"></a>plt.scatter(fpr[np.argmin(np.<span class="bu">abs</span>(thresholds <span class="op">-</span> best_threshold))], </span>
<span id="cb17-319"><a href="#cb17-319" aria-hidden="true" tabindex="-1"></a>            tpr[np.argmin(np.<span class="bu">abs</span>(thresholds <span class="op">-</span> best_threshold))], </span>
<span id="cb17-320"><a href="#cb17-320" aria-hidden="true" tabindex="-1"></a>            c<span class="op">=</span><span class="st">'red'</span>, marker<span class="op">=</span><span class="st">'o'</span>, s<span class="op">=</span><span class="dv">100</span>, label<span class="op">=</span><span class="ss">f'Best threshold = </span><span class="sc">{</span>best_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb17-321"><a href="#cb17-321" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="fl">0.0</span>, <span class="fl">1.0</span>])</span>
<span id="cb17-322"><a href="#cb17-322" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="fl">0.0</span>, <span class="fl">1.05</span>])</span>
<span id="cb17-323"><a href="#cb17-323" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'False Positive Rate'</span>)</span>
<span id="cb17-324"><a href="#cb17-324" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb17-325"><a href="#cb17-325" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Receiver Operating Characteristic'</span>)</span>
<span id="cb17-326"><a href="#cb17-326" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb17-327"><a href="#cb17-327" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb17-328"><a href="#cb17-328" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-329"><a href="#cb17-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-330"><a href="#cb17-330" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Precision-Recall curve</span></span>
<span id="cb17-331"><a href="#cb17-331" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_curve, average_precision_score</span>
<span id="cb17-332"><a href="#cb17-332" aria-hidden="true" tabindex="-1"></a>precision, recall, thresholds_pr <span class="op">=</span> precision_recall_curve(y_test, y_pred_proba_positive)</span>
<span id="cb17-333"><a href="#cb17-333" aria-hidden="true" tabindex="-1"></a>avg_precision <span class="op">=</span> average_precision_score(y_test, y_pred_proba_positive)</span>
<span id="cb17-334"><a href="#cb17-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-335"><a href="#cb17-335" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb17-336"><a href="#cb17-336" aria-hidden="true" tabindex="-1"></a>plt.plot(recall, precision, color<span class="op">=</span><span class="st">'blue'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="ss">f'PR curve (AP = </span><span class="sc">{</span>avg_precision<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb17-337"><a href="#cb17-337" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Recall'</span>)</span>
<span id="cb17-338"><a href="#cb17-338" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Precision'</span>)</span>
<span id="cb17-339"><a href="#cb17-339" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Precision-Recall Curve'</span>)</span>
<span id="cb17-340"><a href="#cb17-340" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"upper right"</span>)</span>
<span id="cb17-341"><a href="#cb17-341" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb17-342"><a href="#cb17-342" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-343"><a href="#cb17-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-344"><a href="#cb17-344" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare with the best threshold ROC point</span></span>
<span id="cb17-345"><a href="#cb17-345" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb17-346"><a href="#cb17-346" aria-hidden="true" tabindex="-1"></a>plt.step(recall, precision, color<span class="op">=</span><span class="st">'blue'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>, where<span class="op">=</span><span class="st">'post'</span>)</span>
<span id="cb17-347"><a href="#cb17-347" aria-hidden="true" tabindex="-1"></a>plt.fill_between(recall, precision, alpha<span class="op">=</span><span class="fl">0.2</span>, color<span class="op">=</span><span class="st">'blue'</span>, step<span class="op">=</span><span class="st">'post'</span>)</span>
<span id="cb17-348"><a href="#cb17-348" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Recall'</span>)</span>
<span id="cb17-349"><a href="#cb17-349" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Precision'</span>)</span>
<span id="cb17-350"><a href="#cb17-350" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="fl">0.0</span>, <span class="fl">1.05</span>])</span>
<span id="cb17-351"><a href="#cb17-351" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="fl">0.0</span>, <span class="fl">1.0</span>])</span>
<span id="cb17-352"><a href="#cb17-352" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Precision-Recall Curve: AP=</span><span class="sc">{0:0.2f}</span><span class="st">'</span>.<span class="bu">format</span>(avg_precision))</span>
<span id="cb17-353"><a href="#cb17-353" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-354"><a href="#cb17-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-355"><a href="#cb17-355" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot F1 Score vs Threshold</span></span>
<span id="cb17-356"><a href="#cb17-356" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb17-357"><a href="#cb17-357" aria-hidden="true" tabindex="-1"></a>plt.plot(thresholds, f1_scores, <span class="st">'b-'</span>, label<span class="op">=</span><span class="st">'F1 Score'</span>)</span>
<span id="cb17-358"><a href="#cb17-358" aria-hidden="true" tabindex="-1"></a>plt.plot([best_threshold, best_threshold], [<span class="dv">0</span>, best_f1], <span class="st">'r--'</span>, label<span class="op">=</span><span class="ss">f'Best Threshold = </span><span class="sc">{</span>best_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb17-359"><a href="#cb17-359" aria-hidden="true" tabindex="-1"></a>plt.plot(best_threshold, best_f1, <span class="st">'ro'</span>, markersize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb17-360"><a href="#cb17-360" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'F1 Score vs. Threshold'</span>)</span>
<span id="cb17-361"><a href="#cb17-361" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Threshold'</span>)</span>
<span id="cb17-362"><a href="#cb17-362" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'F1 Score'</span>)</span>
<span id="cb17-363"><a href="#cb17-363" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb17-364"><a href="#cb17-364" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb17-365"><a href="#cb17-365" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-366"><a href="#cb17-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-367"><a href="#cb17-367" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparing model performance before and after optimization</span></span>
<span id="cb17-368"><a href="#cb17-368" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Model performance comparison:"</span>)</span>
<span id="cb17-369"><a href="#cb17-369" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimal threshold: </span><span class="sc">{</span>best_threshold<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb17-370"><a href="#cb17-370" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Original model test accuracy: </span><span class="sc">{</span>test_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb17-371"><a href="#cb17-371" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimized model test accuracy (with best threshold): </span><span class="sc">{</span>accuracy_score(y_test, y_pred)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb17-372"><a href="#cb17-372" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimized model F1 score: </span><span class="sc">{</span>f1_score(y_test, y_pred)<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Number of samples: 25628
Positive samples: 5295
Negative samples: 20333
Unique amino acids in dataset: ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']
Maximum sequence length: 9
X_onehot shape: (25628, 9, 21)
Number of unique amino acids (including padding): 21
Training set shape: (17938, 9, 21) (70.0% of total)
Validation set shape: (3845, 9, 21) (15.0% of total)
Testing set shape: (3845, 9, 21) (15.0% of total)
Positive samples in training: 3707 (20.7%)
Negative samples in training: 14231 (79.3%)
Positive samples in validation: 794 (20.7%)
Negative samples in validation: 3051 (79.3%)
Positive samples in testing: 794 (20.7%)
Negative samples in testing: 3051 (79.3%)
Class weights: {0: np.float64(0.6302438338837748), 1: np.float64(2.419476665767467)}</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "functional_14"</span>
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_14 (<span style="color: #0087ff; text-decoration-color: #0087ff">InputLayer</span>)     │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">9</span>, <span style="color: #00af00; text-decoration-color: #00af00">21</span>)          │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv1d_42 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv1D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">9</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>)          │         <span style="color: #00af00; text-decoration-color: #00af00">2,048</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_70          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">9</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>)          │           <span style="color: #00af00; text-decoration-color: #00af00">128</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling1d_28 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling1D</span>) │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>)          │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv1d_43 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv1D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)          │         <span style="color: #00af00; text-decoration-color: #00af00">6,208</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_71          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">5</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)          │           <span style="color: #00af00; text-decoration-color: #00af00">256</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling1d_29 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling1D</span>) │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">3</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)          │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv1d_44 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv1D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">3</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)         │        <span style="color: #00af00; text-decoration-color: #00af00">24,704</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_72          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">3</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)         │           <span style="color: #00af00; text-decoration-color: #00af00">512</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ flatten_14 (<span style="color: #0087ff; text-decoration-color: #0087ff">Flatten</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_42 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">49,280</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_73          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)            │           <span style="color: #00af00; text-decoration-color: #00af00">512</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_28 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">128</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_43 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">8,256</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_74          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             │           <span style="color: #00af00; text-decoration-color: #00af00">256</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_29 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_44 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">2</span>)              │           <span style="color: #00af00; text-decoration-color: #00af00">130</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">92,290</span> (360.51 KB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">91,458</span> (357.26 KB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">832</span> (3.25 KB)
</pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>None
Test accuracy: 0.7771

Optimal threshold: 0.55 with F1 Score: 0.5948

Classification Report with Optimized Threshold:
              precision    recall  f1-score   support

           0       0.93      0.79      0.86      3051
           1       0.49      0.76      0.59       794

    accuracy                           0.79      3845
   macro avg       0.71      0.78      0.73      3845
weighted avg       0.84      0.79      0.80      3845
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="blog_files/figure-html/cell-15-output-8.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="blog_files/figure-html/cell-15-output-9.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="blog_files/figure-html/cell-15-output-10.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="blog_files/figure-html/cell-15-output-11.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="blog_files/figure-html/cell-15-output-12.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="blog_files/figure-html/cell-15-output-13.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Model performance comparison:
Optimal threshold: 0.55
Original model test accuracy: 0.7771
Optimized model test accuracy (with best threshold): 0.7870
Optimized model F1 score: 0.5948</code></pre>
</div>
</div>
<!-- -->


</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-AWAD20221010" class="csl-entry" role="listitem">
Awad, Mark M., Ramaswamy Govindan, Kristen N. Balogh, David R. Spigel, Edward B. Garon, Meghan E. Bushway, Asaf Poran, et al. 2022. <span>“Personalized Neoantigen Vaccine NEO-PV-01 with Chemotherapy and Anti-PD-1 as First-Line Treatment for Non-Squamous Non-Small Cell Lung Cancer.”</span> <em>Cancer Cell</em> 40 (9): 1010–1026.e11. <a href="https://doi.org/10.1016/j.ccell.2022.08.003">https://doi.org/10.1016/j.ccell.2022.08.003</a>.
</div>
<div id="ref-colu92" class="csl-entry" role="listitem">
Columbus, Christopher. 1492. <em>How <span>I</span> Discovered <span>America</span></em>. Barcelona: Hispanic Press.
</div>
<div id="ref-gree00" class="csl-entry" role="listitem">
Green, R. J., U. P. Fred, and W. P. Norbert. 1900. <span>“Things That Go Bump in the Night.”</span> <em>Psych. Today</em> 46: 345–678.
</div>
<div id="ref-phil99" class="csl-entry" role="listitem">
Phillips, T. P. 1999. <span>“Possible Influence of the Magnetosphere on <span>American</span> History.”</span> <em>J. Oddball Res.</em> 98: 1000–1003.
</div>
<div id="ref-smit54" class="csl-entry" role="listitem">
Smith, J. G., and H. K. Weston. 1954. <span>“Nothing Particular in This Year’s History.”</span> <em>J. Geophys. Res.</em> 2: 14–15.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb21" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Cancer T-Cell Epitope Classification"</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Identifying key target antigens for cancer immunotherapy"</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Tariq Alagha"</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> references.bib</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="an">number-sections:</span><span class="co"> false</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co">    theme: default</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co">    rendering: embed-resources</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="an">editor:</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="co">  render-on-save: false</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a><span class="an">nocite:</span><span class="co"> |</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a><span class="co">  @*</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a><span class="al">![@AWAD20221010](https://www.cell.com/cms/10.1016/j.ccell.2022.08.003/asset/eb36c8cd-3880-4d48-8a8b-f10accd01fba/main.assets/fx1_lrg.jpg)</span>{width=50% fig-align="center" fig-alt="End to end personalized peptide vaccine cancer treatment"}</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>Epitope classification is a critical area of immunology and vaccine development that focuses on identifying and characterizing specific regions of antigens that are recognized by the immune system. Epitopes serve as the molecular interface between pathogens and the host immune response, making their accurate identification essential for understanding immune responses and developing targeted therapeutics.</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>As shown in Figure 2, standard chemotherapy treatment targets rapidly dividing cells which can include the hosts immune system, making them counterproductive. However, effective fabrication of personalized antigens would make treatment much less physically devastating.</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a><span class="fu"># Data</span></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a><span class="fu">### Dataset</span></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>The dataset utilized for this analysis is sourced from <span class="co">[</span><span class="ot">The Immune Epitope Database (IEDB)</span><span class="co">](https://www.iedb.org/)</span>, a publicly available database of manually extracted data from published scientific research on antibody and T-cell epitopes. It was created to aggregate and centralize data on how the immune system recognizes specific molecular features, known as epitopes, on antigens.</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>The database can be queried for known epitopes, returning a list of assays — tests or experiments — that have been performed on the antigen and their results. These tests can include whether or not a particular epitope binds to the MHC complex or is capable of triggering a cytokine release to kill living cells.</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>The scope of my analysis will be limited to epitopes sourced from human cancer T-cells that were tested and found to produce an autoimmune response. While the database has a wide range of information about each antigen, I will only be utilizing the epitopes' amino acid sequence and the MHC allele it was tested against.</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>Along with these features, each epitope entry also contains a link to the antigen's full amino acid sequence. These full sequences come from the <span class="co">[</span><span class="ot">UniProt</span><span class="co">](https://www.uniprot.org/)</span> database, which contains a collection of protein sequences and their associated information. These full sequences will be used to generate negative samples for the model.</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Libraries and packages" collapse="false"}</span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a><span class="in">```{python q-collapse}</span></span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Importing libraries</span></span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> Bio</span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve</span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> Bio.SeqUtils.ProtParam <span class="im">import</span> ProteinAnalysis</span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> io <span class="im">import</span> StringIO</span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> Bio <span class="im">import</span> SeqIO</span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a><span class="fu">### Preprocessing</span></span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.read_csv(<span class="vs">r'/Users/tariq/Documents/capstone/data/epitope_table_export_1740279588</span><span class="dv">.</span><span class="vs">csv'</span>)</span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a>assays <span class="op">=</span> pd.read_csv(<span class="vs">r'/Users/tariq/Documents/capstone/data/tcell_table_export_1740279970</span><span class="dv">.</span><span class="vs">csv'</span>)</span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fetch_full_sequence(url):</span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.notna(url):  <span class="co"># Check if the URL is not NaN</span></span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a>        url <span class="op">=</span> <span class="ss">f'</span><span class="sc">{</span>url<span class="sc">}</span><span class="ss">.fasta'</span></span>
<span id="cb21-69"><a href="#cb21-69" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb21-70"><a href="#cb21-70" aria-hidden="true" tabindex="-1"></a>            response <span class="op">=</span> requests.get(url)</span>
<span id="cb21-71"><a href="#cb21-71" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> response.status_code <span class="op">==</span> <span class="dv">200</span>:</span>
<span id="cb21-72"><a href="#cb21-72" aria-hidden="true" tabindex="-1"></a>                fasta_io <span class="op">=</span> StringIO(response.text)</span>
<span id="cb21-73"><a href="#cb21-73" aria-hidden="true" tabindex="-1"></a>                records <span class="op">=</span> <span class="bu">list</span>(SeqIO.parse(fasta_io, <span class="st">"fasta"</span>))</span>
<span id="cb21-74"><a href="#cb21-74" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> records:  <span class="co"># Check if there are any records</span></span>
<span id="cb21-75"><a href="#cb21-75" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">return</span> <span class="bu">str</span>(records[<span class="dv">0</span>].seq)</span>
<span id="cb21-76"><a href="#cb21-76" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb21-77"><a href="#cb21-77" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="st">"No records found in the FASTA file."</span>)</span>
<span id="cb21-78"><a href="#cb21-78" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> requests.exceptions.RequestException <span class="im">as</span> e:</span>
<span id="cb21-79"><a href="#cb21-79" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Request failed: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-80"><a href="#cb21-80" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb21-81"><a href="#cb21-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-82"><a href="#cb21-82" aria-hidden="true" tabindex="-1"></a><span class="co">#epitopes['Full Sequence'] = epitopes['Epitope - Molecule Parent IRI'].apply(fetch_full_sequence)</span></span>
<span id="cb21-83"><a href="#cb21-83" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.read_csv(<span class="vs">r'/Users/tariq/Documents/capstone/data/epitope_full_seq</span><span class="dv">.</span><span class="vs">csv'</span>)</span>
<span id="cb21-84"><a href="#cb21-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-85"><a href="#cb21-85" aria-hidden="true" tabindex="-1"></a><span class="co"># make all the column names snake case</span></span>
<span id="cb21-86"><a href="#cb21-86" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.lower()</span>
<span id="cb21-87"><a href="#cb21-87" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.lower()</span>
<span id="cb21-88"><a href="#cb21-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-89"><a href="#cb21-89" aria-hidden="true" tabindex="-1"></a><span class="co"># remove spaces from column names</span></span>
<span id="cb21-90"><a href="#cb21-90" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">''</span>)</span>
<span id="cb21-91"><a href="#cb21-91" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.replace(<span class="st">'-'</span>, <span class="st">' '</span>)</span>
<span id="cb21-92"><a href="#cb21-92" aria-hidden="true" tabindex="-1"></a>epitopes.columns <span class="op">=</span> epitopes.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">'_'</span>)</span>
<span id="cb21-93"><a href="#cb21-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-94"><a href="#cb21-94" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">''</span>)</span>
<span id="cb21-95"><a href="#cb21-95" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.replace(<span class="st">'-'</span>, <span class="st">' '</span>)</span>
<span id="cb21-96"><a href="#cb21-96" aria-hidden="true" tabindex="-1"></a>assays.columns <span class="op">=</span> assays.columns.<span class="bu">str</span>.replace(<span class="st">' '</span>, <span class="st">'_'</span>)</span>
<span id="cb21-97"><a href="#cb21-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-98"><a href="#cb21-98" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.<span class="bu">filter</span>([<span class="st">'epitope_name'</span>, <span class="st">'fullsequence'</span>])</span>
<span id="cb21-99"><a href="#cb21-99" aria-hidden="true" tabindex="-1"></a>assays <span class="op">=</span> assays.<span class="bu">filter</span>([<span class="st">'epitope_name'</span>, <span class="st">'epitope_moluculeparent'</span>, <span class="st">'host_name'</span>, <span class="st">'host_mhcpresent'</span>, <span class="st">'assay_method'</span>,<span class="st">'assay_responsemeasured'</span>, <span class="st">'assay_qualitativemeasurement'</span>, <span class="st">'mhcrestriction_name'</span>, <span class="st">'mhcrestriction_class'</span>, <span class="st">'assayantigen_name'</span>])</span>
<span id="cb21-100"><a href="#cb21-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-101"><a href="#cb21-101" aria-hidden="true" tabindex="-1"></a><span class="co"># map mhc name and class from the assays dataframe to a new column in the epitopes dataframe based on epitope_name</span></span>
<span id="cb21-102"><a href="#cb21-102" aria-hidden="true" tabindex="-1"></a>mhc <span class="op">=</span> assays.<span class="bu">filter</span>([<span class="st">'epitope_name'</span>, <span class="st">'mhcrestriction_name'</span>, <span class="st">'mhcrestriction_class'</span>])</span>
<span id="cb21-103"><a href="#cb21-103" aria-hidden="true" tabindex="-1"></a>mhc <span class="op">=</span> mhc.drop_duplicates(subset<span class="op">=</span>[<span class="st">'epitope_name'</span>])</span>
<span id="cb21-104"><a href="#cb21-104" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.merge(mhc, on<span class="op">=</span><span class="st">'epitope_name'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb21-105"><a href="#cb21-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-106"><a href="#cb21-106" aria-hidden="true" tabindex="-1"></a>epitopes.head()</span>
<span id="cb21-107"><a href="#cb21-107" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-108"><a href="#cb21-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-109"><a href="#cb21-109" aria-hidden="true" tabindex="-1"></a>Retriving the data from IEDB was as simple as doing a search and clicking exoprt. Two files were exported, one containing 28,681 unique epitopes and another with their corresponding assays and respective results. Roughly 10% of the epitopes in the dataset came with a corresponding <span class="co">[</span><span class="ot">UniProt</span><span class="co">](https://www.uniprot.org/)</span> link. For our purposes this will be enough. Using the requests python library, the full antigen sequence was downloaded and appended to the epitope dataset. Next, simple formatting was done to standardize the column names. Finally, the epitope dataset was merged with the assays dataset on the epitope_name column and filtered to include the following columns:</span>
<span id="cb21-110"><a href="#cb21-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-111"><a href="#cb21-111" aria-hidden="true" tabindex="-1"></a><span class="fu">### Negative Sample Generation</span></span>
<span id="cb21-112"><a href="#cb21-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-113"><a href="#cb21-113" aria-hidden="true" tabindex="-1"></a><span class="in">```{python negative_sample_generation}</span></span>
<span id="cb21-114"><a href="#cb21-114" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb21-115"><a href="#cb21-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-116"><a href="#cb21-116" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_negatives(row):</span>
<span id="cb21-117"><a href="#cb21-117" aria-hidden="true" tabindex="-1"></a>    epitope <span class="op">=</span> row[<span class="st">"epitope_name"</span>]</span>
<span id="cb21-118"><a href="#cb21-118" aria-hidden="true" tabindex="-1"></a>    full_seq <span class="op">=</span> row[<span class="st">"fullsequence"</span>]</span>
<span id="cb21-119"><a href="#cb21-119" aria-hidden="true" tabindex="-1"></a>    mhc <span class="op">=</span> row[<span class="st">"mhcrestriction_name"</span>]</span>
<span id="cb21-120"><a href="#cb21-120" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-121"><a href="#cb21-121" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle missing or empty sequences</span></span>
<span id="cb21-122"><a href="#cb21-122" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pd.isnull(full_seq) <span class="kw">or</span> full_seq <span class="op">==</span> <span class="st">""</span>:</span>
<span id="cb21-123"><a href="#cb21-123" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> []</span>
<span id="cb21-124"><a href="#cb21-124" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-125"><a href="#cb21-125" aria-hidden="true" tabindex="-1"></a>    epitope <span class="op">=</span> <span class="bu">str</span>(epitope)</span>
<span id="cb21-126"><a href="#cb21-126" aria-hidden="true" tabindex="-1"></a>    full_seq <span class="op">=</span> <span class="bu">str</span>(full_seq)</span>
<span id="cb21-127"><a href="#cb21-127" aria-hidden="true" tabindex="-1"></a>    ep_len <span class="op">=</span> <span class="bu">len</span>(epitope)</span>
<span id="cb21-128"><a href="#cb21-128" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-129"><a href="#cb21-129" aria-hidden="true" tabindex="-1"></a>    negatives <span class="op">=</span> []</span>
<span id="cb21-130"><a href="#cb21-130" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(full_seq) <span class="op">-</span> ep_len <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb21-131"><a href="#cb21-131" aria-hidden="true" tabindex="-1"></a>        window <span class="op">=</span> full_seq[i:i<span class="op">+</span>ep_len]</span>
<span id="cb21-132"><a href="#cb21-132" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> window <span class="op">!=</span> epitope:</span>
<span id="cb21-133"><a href="#cb21-133" aria-hidden="true" tabindex="-1"></a>            negatives.append({<span class="st">"peptide"</span>: window, <span class="st">"mhc"</span>: mhc})</span>
<span id="cb21-134"><a href="#cb21-134" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> negatives</span>
<span id="cb21-135"><a href="#cb21-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-136"><a href="#cb21-136" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to each row</span></span>
<span id="cb21-137"><a href="#cb21-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-138"><a href="#cb21-138" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> pd.DataFrame()</span>
<span id="cb21-139"><a href="#cb21-139" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'negatives'</span>] <span class="op">=</span> epitopes.<span class="bu">apply</span>(generate_negatives, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb21-140"><a href="#cb21-140" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives[[<span class="st">"negatives"</span>]].explode(<span class="st">"negatives"</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-141"><a href="#cb21-141" aria-hidden="true" tabindex="-1"></a>negatives.dropna(subset<span class="op">=</span>[<span class="st">"negatives"</span>], inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-142"><a href="#cb21-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-143"><a href="#cb21-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-144"><a href="#cb21-144" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove duplicate peptide-mhc combinations</span></span>
<span id="cb21-145"><a href="#cb21-145" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Shape before removing duplicates: </span><span class="sc">{</span>negatives<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-146"><a href="#cb21-146" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.drop_duplicates(subset<span class="op">=</span>[<span class="st">'negatives'</span>])</span>
<span id="cb21-147"><a href="#cb21-147" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Shape after removing duplicates: </span><span class="sc">{</span>negatives<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-148"><a href="#cb21-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-149"><a href="#cb21-149" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for any remaining NaN values</span></span>
<span id="cb21-150"><a href="#cb21-150" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of NaN values in negatives: </span><span class="sc">{</span>negatives[<span class="st">'negatives'</span>]<span class="sc">.</span>isna()<span class="sc">.</span><span class="bu">sum</span>()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-151"><a href="#cb21-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-152"><a href="#cb21-152" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract peptide and mhc into separate columns</span></span>
<span id="cb21-153"><a href="#cb21-153" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'peptide'</span>] <span class="op">=</span> negatives[<span class="st">'negatives'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x[<span class="st">'peptide'</span>])</span>
<span id="cb21-154"><a href="#cb21-154" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'mhc'</span>] <span class="op">=</span> negatives[<span class="st">'negatives'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x[<span class="st">'mhc'</span>])</span>
<span id="cb21-155"><a href="#cb21-155" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-156"><a href="#cb21-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-157"><a href="#cb21-157" aria-hidden="true" tabindex="-1"></a>Although the IEDB database provided a substantial amount of epitopes, in order draw visual comparisons and create models to classify epitopes, samples of non-epitope peptides are needed. These can be generated by shuffling and sampling amino acid sequences from the full antigen sequences of the epitopes, ensuring that the sampled sequences did not overlap with the epitope sequences. </span>
<span id="cb21-158"><a href="#cb21-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-159"><a href="#cb21-159" aria-hidden="true" tabindex="-1"></a>There are pros and cons to this methodology. As opposed to generating completely random sequences of amino acids — sampling from larger sequences allows for natural patterns and physiochemical motifs to be retained. That is not to say the performance of statistical modeling or qualitative analysis will be better. Random sequences are more likely to be highly irregular, or even biologically implausible. Sampling from the full antigen sequences eliminates this potential bias.</span>
<span id="cb21-160"><a href="#cb21-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-161"><a href="#cb21-161" aria-hidden="true" tabindex="-1"></a>Conversely, it is possible for a randomly sampled peptide to be an epitope that has not been tested yet, or simply isn't in the subset of data used for this analysis — resulting in an increase in the number of false negatives in our data.</span>
<span id="cb21-162"><a href="#cb21-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-163"><a href="#cb21-163" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feature Engineering</span></span>
<span id="cb21-164"><a href="#cb21-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-167"><a href="#cb21-167" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-168"><a href="#cb21-168" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb21-169"><a href="#cb21-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-170"><a href="#cb21-170" aria-hidden="true" tabindex="-1"></a><span class="co"># Kyte-Doolittle hydrophobicity scale</span></span>
<span id="cb21-171"><a href="#cb21-171" aria-hidden="true" tabindex="-1"></a>kyte_doolittle <span class="op">=</span> {</span>
<span id="cb21-172"><a href="#cb21-172" aria-hidden="true" tabindex="-1"></a>    <span class="st">'I'</span>: <span class="fl">4.5</span>, <span class="st">'V'</span>: <span class="fl">4.2</span>, <span class="st">'L'</span>: <span class="fl">3.8</span>, <span class="st">'F'</span>: <span class="fl">2.8</span>, <span class="st">'C'</span>: <span class="fl">2.5</span>,</span>
<span id="cb21-173"><a href="#cb21-173" aria-hidden="true" tabindex="-1"></a>    <span class="st">'M'</span>: <span class="fl">1.9</span>, <span class="st">'A'</span>: <span class="fl">1.8</span>, <span class="st">'G'</span>: <span class="op">-</span><span class="fl">0.4</span>, <span class="st">'T'</span>: <span class="op">-</span><span class="fl">0.7</span>, <span class="st">'S'</span>: <span class="op">-</span><span class="fl">0.8</span>,</span>
<span id="cb21-174"><a href="#cb21-174" aria-hidden="true" tabindex="-1"></a>    <span class="st">'W'</span>: <span class="op">-</span><span class="fl">0.9</span>, <span class="st">'Y'</span>: <span class="op">-</span><span class="fl">1.3</span>, <span class="st">'P'</span>: <span class="op">-</span><span class="fl">1.6</span>, <span class="st">'H'</span>: <span class="op">-</span><span class="fl">3.2</span>, <span class="st">'E'</span>: <span class="op">-</span><span class="fl">3.5</span>,</span>
<span id="cb21-175"><a href="#cb21-175" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Q'</span>: <span class="op">-</span><span class="fl">3.5</span>, <span class="st">'D'</span>: <span class="op">-</span><span class="fl">3.5</span>, <span class="st">'N'</span>: <span class="op">-</span><span class="fl">3.5</span>, <span class="st">'K'</span>: <span class="op">-</span><span class="fl">3.9</span>, <span class="st">'R'</span>: <span class="op">-</span><span class="fl">4.5</span></span>
<span id="cb21-176"><a href="#cb21-176" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-177"><a href="#cb21-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-178"><a href="#cb21-178" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_avg_hydrophobicity(peptide):</span>
<span id="cb21-179"><a href="#cb21-179" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get hydrophobicity scores for each amino acid; default to 0 if missing</span></span>
<span id="cb21-180"><a href="#cb21-180" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> [kyte_doolittle.get(aa, <span class="dv">0</span>) <span class="cf">for</span> aa <span class="kw">in</span> peptide]</span>
<span id="cb21-181"><a href="#cb21-181" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">sum</span>(scores) <span class="op">/</span> <span class="bu">len</span>(scores) <span class="cf">if</span> scores <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb21-182"><a href="#cb21-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-183"><a href="#cb21-183" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to the 'peptide' column to create a new column 'avg_hydro'</span></span>
<span id="cb21-184"><a href="#cb21-184" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'epitope_avg_hydro'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(compute_avg_hydrophobicity)</span>
<span id="cb21-185"><a href="#cb21-185" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the molecular_weight function from Bio.SeqUtils</span></span>
<span id="cb21-186"><a href="#cb21-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-187"><a href="#cb21-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-188"><a href="#cb21-188" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_molecular_weight(peptide):</span>
<span id="cb21-189"><a href="#cb21-189" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the molecular weight of a peptide sequence using Biopython."""</span></span>
<span id="cb21-190"><a href="#cb21-190" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb21-191"><a href="#cb21-191" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb21-192"><a href="#cb21-192" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb21-193"><a href="#cb21-193" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.molecular_weight()</span>
<span id="cb21-194"><a href="#cb21-194" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb21-195"><a href="#cb21-195" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb21-196"><a href="#cb21-196" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb21-197"><a href="#cb21-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-198"><a href="#cb21-198" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb21-199"><a href="#cb21-199" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'molecular_weight'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_molecular_weight)</span>
<span id="cb21-200"><a href="#cb21-200" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_aromaticity(peptide):</span>
<span id="cb21-201"><a href="#cb21-201" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the aromaticity of a peptide sequence using Biopython."""</span></span>
<span id="cb21-202"><a href="#cb21-202" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb21-203"><a href="#cb21-203" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb21-204"><a href="#cb21-204" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb21-205"><a href="#cb21-205" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.aromaticity()</span>
<span id="cb21-206"><a href="#cb21-206" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb21-207"><a href="#cb21-207" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb21-208"><a href="#cb21-208" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb21-209"><a href="#cb21-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-210"><a href="#cb21-210" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb21-211"><a href="#cb21-211" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'aromaticity'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_aromaticity)</span>
<span id="cb21-212"><a href="#cb21-212" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_isoelectric_point(peptide):</span>
<span id="cb21-213"><a href="#cb21-213" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the isoelectric point of a peptide sequence using Biopython."""</span></span>
<span id="cb21-214"><a href="#cb21-214" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb21-215"><a href="#cb21-215" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb21-216"><a href="#cb21-216" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb21-217"><a href="#cb21-217" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.isoelectric_point()</span>
<span id="cb21-218"><a href="#cb21-218" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb21-219"><a href="#cb21-219" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb21-220"><a href="#cb21-220" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb21-221"><a href="#cb21-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-222"><a href="#cb21-222" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb21-223"><a href="#cb21-223" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'isoelectric_point'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_isoelectric_point)</span>
<span id="cb21-224"><a href="#cb21-224" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_instability(peptide):</span>
<span id="cb21-225"><a href="#cb21-225" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the instability of a peptide sequence using Biopython."""</span></span>
<span id="cb21-226"><a href="#cb21-226" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb21-227"><a href="#cb21-227" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb21-228"><a href="#cb21-228" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb21-229"><a href="#cb21-229" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.instability_index()</span>
<span id="cb21-230"><a href="#cb21-230" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb21-231"><a href="#cb21-231" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb21-232"><a href="#cb21-232" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb21-233"><a href="#cb21-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-234"><a href="#cb21-234" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb21-235"><a href="#cb21-235" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'instability'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_instability)</span>
<span id="cb21-236"><a href="#cb21-236" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_charge_at_pH7(peptide):</span>
<span id="cb21-237"><a href="#cb21-237" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the charge of a peptide sequence at pH 7 using Biopython."""</span></span>
<span id="cb21-238"><a href="#cb21-238" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb21-239"><a href="#cb21-239" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ProteinAnalysis only works with standard amino acids</span></span>
<span id="cb21-240"><a href="#cb21-240" aria-hidden="true" tabindex="-1"></a>        protein <span class="op">=</span> ProteinAnalysis(peptide)</span>
<span id="cb21-241"><a href="#cb21-241" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> protein.charge_at_pH(<span class="dv">7</span>)</span>
<span id="cb21-242"><a href="#cb21-242" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb21-243"><a href="#cb21-243" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle peptides with non-standard amino acids</span></span>
<span id="cb21-244"><a href="#cb21-244" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb21-245"><a href="#cb21-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-246"><a href="#cb21-246" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to calculate molecular weight for each epitope</span></span>
<span id="cb21-247"><a href="#cb21-247" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'charge_at_pH7'</span>] <span class="op">=</span> epitopes[<span class="st">'epitope_name'</span>].<span class="bu">apply</span>(calculate_charge_at_pH7)</span>
<span id="cb21-248"><a href="#cb21-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-249"><a href="#cb21-249" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate features on the peptide column</span></span>
<span id="cb21-250"><a href="#cb21-250" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'peptide_length'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(<span class="bu">len</span>)</span>
<span id="cb21-251"><a href="#cb21-251" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'peptide_avg_hydro'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(compute_avg_hydrophobicity)</span>
<span id="cb21-252"><a href="#cb21-252" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'molecular_weight'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_molecular_weight)</span>
<span id="cb21-253"><a href="#cb21-253" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'aromaticity'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_aromaticity)</span>
<span id="cb21-254"><a href="#cb21-254" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'isoelectric_point'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_isoelectric_point)</span>
<span id="cb21-255"><a href="#cb21-255" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'instability'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_instability)</span>
<span id="cb21-256"><a href="#cb21-256" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'charge_at_pH7'</span>] <span class="op">=</span> negatives[<span class="st">'peptide'</span>].<span class="bu">apply</span>(calculate_charge_at_pH7)</span>
<span id="cb21-257"><a href="#cb21-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-258"><a href="#cb21-258" aria-hidden="true" tabindex="-1"></a>negatives.drop(<span class="st">'negatives'</span>, axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-259"><a href="#cb21-259" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-260"><a href="#cb21-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-261"><a href="#cb21-261" aria-hidden="true" tabindex="-1"></a>The protein analysis tool from the BioPython package allows for some quick feature engineering on most given peptides. For this analysis, the relevant features would be hydrophobicity, molecular weight, aromaticity, isoelectric point, instability, and the charge at pH7. Publications on epitope classification hold binding affinity — the ability for a peptide to bind to the body's MHC complex — to be a strong preditctor. The BioPython package does not come with any functionality for binding affinity prediction but IEDB database provides a tool called netMHCpan, which is the leading binding affinity prediction algorithm.</span>
<span id="cb21-262"><a href="#cb21-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-263"><a href="#cb21-263" aria-hidden="true" tabindex="-1"></a>The IEDB website offers a GUI for using netMHCpan to predict binding affinities. However, it is only possible to run predictions on 100 peptides at a time and this analysis is examining many more than that. NetMHCpan can be downloaded and installed as a command line tool allowing more flexibility using python. Given an amino acid sequence and a MHC allele specification, netMHCpan returns a binding affinity score.</span>
<span id="cb21-264"><a href="#cb21-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-267"><a href="#cb21-267" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-268"><a href="#cb21-268" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.read_csv(<span class="st">"/Users/tariq/Documents/capstone/data/ninemer_epitopes.csv"</span>)</span>
<span id="cb21-269"><a href="#cb21-269" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.drop(columns<span class="op">=</span>[<span class="st">'fullsequence'</span>, <span class="st">'mhcrestriction_name'</span>, <span class="st">'mhcrestriction_class'</span>, <span class="st">'epitope_length'</span>])</span>
<span id="cb21-270"><a href="#cb21-270" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> epitopes.rename(columns<span class="op">=</span>{<span class="st">'epitope_name'</span>: <span class="st">'peptide'</span>, <span class="st">'epitope_avg_hydro'</span>: <span class="st">'peptide_avg_hydro'</span>})</span>
<span id="cb21-271"><a href="#cb21-271" aria-hidden="true" tabindex="-1"></a>epitopes_BA_pred <span class="op">=</span> pd.read_csv(<span class="st">"/Users/tariq/Documents/capstone/data/ninemer_epitopes_BA_pred.csv"</span>)</span>
<span id="cb21-272"><a href="#cb21-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-273"><a href="#cb21-273" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> pd.read_csv(<span class="st">"/Users/tariq/Documents/capstone/data/ninemer_negatives_trimmed.csv"</span>)</span>
<span id="cb21-274"><a href="#cb21-274" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.drop(columns<span class="op">=</span>[<span class="st">'mhc'</span>, <span class="st">'peptide_length'</span>])</span>
<span id="cb21-275"><a href="#cb21-275" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.rename(columns<span class="op">=</span>{<span class="st">'peptide'</span>: <span class="st">'peptide'</span>})</span>
<span id="cb21-276"><a href="#cb21-276" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> negatives.drop_duplicates(subset<span class="op">=</span>[<span class="st">'peptide'</span>])</span>
<span id="cb21-277"><a href="#cb21-277" aria-hidden="true" tabindex="-1"></a>negatives_BA_pred <span class="op">=</span> pd.read_csv(<span class="st">"/Users/tariq/Documents/capstone/data/ninemer_negatives_trimmed_BA_pred.csv"</span>)</span>
<span id="cb21-278"><a href="#cb21-278" aria-hidden="true" tabindex="-1"></a>negatives_BA_pred <span class="op">=</span> negatives_BA_pred.drop_duplicates(subset<span class="op">=</span>[<span class="st">'peptide'</span>])</span>
<span id="cb21-279"><a href="#cb21-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-280"><a href="#cb21-280" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge the 'Score_BA' column from epitopes_BA_pred into the epitopes dataframe</span></span>
<span id="cb21-281"><a href="#cb21-281" aria-hidden="true" tabindex="-1"></a>epitopes <span class="op">=</span> pd.merge(epitopes, epitopes_BA_pred[[<span class="st">'peptide'</span>, <span class="st">'Score_BA'</span>]], on<span class="op">=</span><span class="st">'peptide'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb21-282"><a href="#cb21-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-283"><a href="#cb21-283" aria-hidden="true" tabindex="-1"></a>negatives <span class="op">=</span> pd.merge(negatives, negatives_BA_pred[[<span class="st">'peptide'</span>, <span class="st">'Score_BA'</span>]], on<span class="op">=</span><span class="st">'peptide'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb21-284"><a href="#cb21-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-285"><a href="#cb21-285" aria-hidden="true" tabindex="-1"></a>epitopes.head()</span>
<span id="cb21-286"><a href="#cb21-286" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-287"><a href="#cb21-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-288"><a href="#cb21-288" aria-hidden="true" tabindex="-1"></a><span class="fu"># Exploratory Analysis</span></span>
<span id="cb21-289"><a href="#cb21-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-292"><a href="#cb21-292" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-293"><a href="#cb21-293" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare numeric features between epitopes and negatives datasets</span></span>
<span id="cb21-294"><a href="#cb21-294" aria-hidden="true" tabindex="-1"></a>numeric_features <span class="op">=</span> [<span class="st">'peptide_avg_hydro'</span>, <span class="st">'molecular_weight'</span>, <span class="st">'aromaticity'</span>, </span>
<span id="cb21-295"><a href="#cb21-295" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'isoelectric_point'</span>, <span class="st">'instability'</span>, <span class="st">'charge_at_pH7'</span>, <span class="st">'Score_BA'</span>]</span>
<span id="cb21-296"><a href="#cb21-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-297"><a href="#cb21-297" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a figure with subplots for each numeric feature</span></span>
<span id="cb21-298"><a href="#cb21-298" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="bu">len</span>(numeric_features), <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span><span class="op">*</span><span class="bu">len</span>(numeric_features)))</span>
<span id="cb21-299"><a href="#cb21-299" aria-hidden="true" tabindex="-1"></a><span class="co">#fig.tight_layout(pad=5.0)</span></span>
<span id="cb21-300"><a href="#cb21-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-301"><a href="#cb21-301" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot boxplots for each feature</span></span>
<span id="cb21-302"><a href="#cb21-302" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, feature <span class="kw">in</span> <span class="bu">enumerate</span>(numeric_features):</span>
<span id="cb21-303"><a href="#cb21-303" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> axes[i]</span>
<span id="cb21-304"><a href="#cb21-304" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-305"><a href="#cb21-305" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a temporary dataframe for plotting</span></span>
<span id="cb21-306"><a href="#cb21-306" aria-hidden="true" tabindex="-1"></a>    plot_data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb21-307"><a href="#cb21-307" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Epitopes'</span>: epitopes[feature],</span>
<span id="cb21-308"><a href="#cb21-308" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Negatives'</span>: negatives[feature]</span>
<span id="cb21-309"><a href="#cb21-309" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb21-310"><a href="#cb21-310" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-311"><a href="#cb21-311" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create boxplot</span></span>
<span id="cb21-312"><a href="#cb21-312" aria-hidden="true" tabindex="-1"></a>    sns.boxplot(data<span class="op">=</span>plot_data, ax<span class="op">=</span>ax)</span>
<span id="cb21-313"><a href="#cb21-313" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-314"><a href="#cb21-314" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add feature statistics</span></span>
<span id="cb21-315"><a href="#cb21-315" aria-hidden="true" tabindex="-1"></a>    epitope_mean <span class="op">=</span> epitopes[feature].mean()</span>
<span id="cb21-316"><a href="#cb21-316" aria-hidden="true" tabindex="-1"></a>    negative_mean <span class="op">=</span> negatives[feature].mean()</span>
<span id="cb21-317"><a href="#cb21-317" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-318"><a href="#cb21-318" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'</span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss"> Distribution Comparison'</span>)</span>
<span id="cb21-319"><a href="#cb21-319" aria-hidden="true" tabindex="-1"></a>    ax.text(<span class="fl">0.02</span>, <span class="fl">0.95</span>, <span class="ss">f'Epitopes mean: </span><span class="sc">{</span>epitope_mean<span class="sc">:.4f}</span><span class="ss">'</span>, transform<span class="op">=</span>ax.transAxes)</span>
<span id="cb21-320"><a href="#cb21-320" aria-hidden="true" tabindex="-1"></a>    ax.text(<span class="fl">0.02</span>, <span class="fl">0.90</span>, <span class="ss">f'Negatives mean: </span><span class="sc">{</span>negative_mean<span class="sc">:.4f}</span><span class="ss">'</span>, transform<span class="op">=</span>ax.transAxes)</span>
<span id="cb21-321"><a href="#cb21-321" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-322"><a href="#cb21-322" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add p-value from t-test</span></span>
<span id="cb21-323"><a href="#cb21-323" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb21-324"><a href="#cb21-324" aria-hidden="true" tabindex="-1"></a>    t_stat, p_value <span class="op">=</span> stats.ttest_ind(</span>
<span id="cb21-325"><a href="#cb21-325" aria-hidden="true" tabindex="-1"></a>        epitopes[feature].dropna(), </span>
<span id="cb21-326"><a href="#cb21-326" aria-hidden="true" tabindex="-1"></a>        negatives[feature].dropna(),</span>
<span id="cb21-327"><a href="#cb21-327" aria-hidden="true" tabindex="-1"></a>        equal_var<span class="op">=</span><span class="va">False</span>  <span class="co"># Welch's t-test (doesn't assume equal variances)</span></span>
<span id="cb21-328"><a href="#cb21-328" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb21-329"><a href="#cb21-329" aria-hidden="true" tabindex="-1"></a>    <span class="co">#ax.text(0.02, 0.85, f'p-value: {p_value:.4e}', transform=ax.transAxes)</span></span>
<span id="cb21-330"><a href="#cb21-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-331"><a href="#cb21-331" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.suptitle('Comparison of Numeric Features Between Epitopes and Negatives', fontsize=16)</span></span>
<span id="cb21-332"><a href="#cb21-332" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-333"><a href="#cb21-333" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-334"><a href="#cb21-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-335"><a href="#cb21-335" aria-hidden="true" tabindex="-1"></a>A boxplot comparison of the numerical variables reveals hardly significant differences between the epitope and non-epitope peptides. The clear outlier being the predicted binding affinity score.</span>
<span id="cb21-336"><a href="#cb21-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-339"><a href="#cb21-339" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-340"><a href="#cb21-340" aria-hidden="true" tabindex="-1"></a><span class="co"># plot Score_BA for epitopes and negatives overlaid on the same plot</span></span>
<span id="cb21-341"><a href="#cb21-341" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb21-342"><a href="#cb21-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-343"><a href="#cb21-343" aria-hidden="true" tabindex="-1"></a><span class="co"># Use density instead of raw counts to normalize the histograms</span></span>
<span id="cb21-344"><a href="#cb21-344" aria-hidden="true" tabindex="-1"></a>plt.hist(epitopes[<span class="st">'Score_BA'</span>], bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'blue'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, </span>
<span id="cb21-345"><a href="#cb21-345" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Epitopes'</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-346"><a href="#cb21-346" aria-hidden="true" tabindex="-1"></a>plt.hist(negatives[<span class="st">'Score_BA'</span>], bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'red'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>, </span>
<span id="cb21-347"><a href="#cb21-347" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Negatives'</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-348"><a href="#cb21-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-349"><a href="#cb21-349" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternative approach: use log scale for y-axis</span></span>
<span id="cb21-350"><a href="#cb21-350" aria-hidden="true" tabindex="-1"></a>plt.yscale(<span class="st">'log'</span>)</span>
<span id="cb21-351"><a href="#cb21-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-352"><a href="#cb21-352" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Binding Affinity'</span>)</span>
<span id="cb21-353"><a href="#cb21-353" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density (log scale)'</span>)</span>
<span id="cb21-354"><a href="#cb21-354" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Normalized Histogram of Binding Affinity for Epitopes vs Negatives'</span>)</span>
<span id="cb21-355"><a href="#cb21-355" aria-hidden="true" tabindex="-1"></a>plt.legend(prop<span class="op">=</span>{<span class="st">'size'</span>: <span class="dv">14</span>})  <span class="co"># Increased legend font size</span></span>
<span id="cb21-356"><a href="#cb21-356" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-357"><a href="#cb21-357" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-358"><a href="#cb21-358" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-359"><a href="#cb21-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-360"><a href="#cb21-360" aria-hidden="true" tabindex="-1"></a>Upon further inspection of the difference in predicted binding affinity score, we see the non-epitope peptides exhibit a right-skewed distribution with a mean of 0.07, and the epitopes show a broad, moderate-variance spread with a much higher mean of 0.56.</span>
<span id="cb21-361"><a href="#cb21-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-362"><a href="#cb21-362" aria-hidden="true" tabindex="-1"></a><span class="fu"># Modeling</span></span>
<span id="cb21-363"><a href="#cb21-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-364"><a href="#cb21-364" aria-hidden="true" tabindex="-1"></a><span class="fu">### Model Selection</span></span>
<span id="cb21-365"><a href="#cb21-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-366"><a href="#cb21-366" aria-hidden="true" tabindex="-1"></a>To establish a baseline for performance, a random forest classifier will be fit to the following features:</span>
<span id="cb21-367"><a href="#cb21-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-368"><a href="#cb21-368" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>peptide_avg_hydro</span>
<span id="cb21-369"><a href="#cb21-369" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>molecular_weight</span>
<span id="cb21-370"><a href="#cb21-370" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>aromaticity</span>
<span id="cb21-371"><a href="#cb21-371" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>isoelectric_point</span>
<span id="cb21-372"><a href="#cb21-372" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>instability</span>
<span id="cb21-373"><a href="#cb21-373" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>charge_at_pH7</span>
<span id="cb21-374"><a href="#cb21-374" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Score_BA</span>
<span id="cb21-375"><a href="#cb21-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-376"><a href="#cb21-376" aria-hidden="true" tabindex="-1"></a>Performace will be evaluated based on accuracy, precision, and recall.</span>
<span id="cb21-377"><a href="#cb21-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-378"><a href="#cb21-378" aria-hidden="true" tabindex="-1"></a><span class="fu">### Preprocessing</span></span>
<span id="cb21-379"><a href="#cb21-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-380"><a href="#cb21-380" aria-hidden="true" tabindex="-1"></a>Prior to training, labels are assigned to the epitopes and non-epitopes as 1 or 0 respectively. The two samples are then concatenated, scaled, and shuffled. Finally, the data is split into training and testing sets with an 80/20 ratio. </span>
<span id="cb21-381"><a href="#cb21-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-384"><a href="#cb21-384" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-385"><a href="#cb21-385" aria-hidden="true" tabindex="-1"></a><span class="co"># Add label column to epitopes dataframe (positive class = 1)</span></span>
<span id="cb21-386"><a href="#cb21-386" aria-hidden="true" tabindex="-1"></a>epitopes[<span class="st">'label'</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb21-387"><a href="#cb21-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-388"><a href="#cb21-388" aria-hidden="true" tabindex="-1"></a><span class="co"># Add label column to negatives dataframe (negative class = 0)</span></span>
<span id="cb21-389"><a href="#cb21-389" aria-hidden="true" tabindex="-1"></a>negatives[<span class="st">'label'</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb21-390"><a href="#cb21-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-391"><a href="#cb21-391" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine the positive and negative examples</span></span>
<span id="cb21-392"><a href="#cb21-392" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> pd.concat([epitopes, negatives], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-393"><a href="#cb21-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-394"><a href="#cb21-394" aria-hidden="true" tabindex="-1"></a><span class="co"># Shuffle the combined dataset</span></span>
<span id="cb21-395"><a href="#cb21-395" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> combined_data.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-396"><a href="#cb21-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-397"><a href="#cb21-397" aria-hidden="true" tabindex="-1"></a><span class="co"># Define features and target</span></span>
<span id="cb21-398"><a href="#cb21-398" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> combined_data.drop(columns<span class="op">=</span>[<span class="st">'peptide'</span>, <span class="st">'label'</span>])</span>
<span id="cb21-399"><a href="#cb21-399" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> combined_data[<span class="st">'label'</span>]</span>
<span id="cb21-400"><a href="#cb21-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-401"><a href="#cb21-401" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify numerical columns to scale (exclude one-hot encoded amino acid columns)</span></span>
<span id="cb21-402"><a href="#cb21-402" aria-hidden="true" tabindex="-1"></a>numerical_cols <span class="op">=</span> [<span class="st">'peptide_avg_hydro'</span>, <span class="st">'molecular_weight'</span>, <span class="st">'aromaticity'</span>, <span class="st">'isoelectric_point'</span>, <span class="st">'instability'</span>,<span class="st">'Score_BA'</span>, <span class="st">'charge_at_pH7'</span>]</span>
<span id="cb21-403"><a href="#cb21-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-404"><a href="#cb21-404" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets (80% train, 20% test)</span></span>
<span id="cb21-405"><a href="#cb21-405" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb21-406"><a href="#cb21-406" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb21-407"><a href="#cb21-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-408"><a href="#cb21-408" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb21-409"><a href="#cb21-409" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y</span>
<span id="cb21-410"><a href="#cb21-410" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-411"><a href="#cb21-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-412"><a href="#cb21-412" aria-hidden="true" tabindex="-1"></a><span class="co"># Scale numerical features using StandardScaler</span></span>
<span id="cb21-413"><a href="#cb21-413" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb21-414"><a href="#cb21-414" aria-hidden="true" tabindex="-1"></a>X_train[numerical_cols] <span class="op">=</span> scaler.fit_transform(X_train[numerical_cols])</span>
<span id="cb21-415"><a href="#cb21-415" aria-hidden="true" tabindex="-1"></a>X_test[numerical_cols] <span class="op">=</span> scaler.transform(X_test[numerical_cols])</span>
<span id="cb21-416"><a href="#cb21-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-417"><a href="#cb21-417" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the shapes to verify the split</span></span>
<span id="cb21-418"><a href="#cb21-418" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training set: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb21-419"><a href="#cb21-419" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Testing set: </span><span class="sc">{</span>X_test<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb21-420"><a href="#cb21-420" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in training: </span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-421"><a href="#cb21-421" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in training: </span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-422"><a href="#cb21-422" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in testing: </span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-423"><a href="#cb21-423" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in testing: </span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-424"><a href="#cb21-424" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-425"><a href="#cb21-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-426"><a href="#cb21-426" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training + Evaluation</span></span>
<span id="cb21-427"><a href="#cb21-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-428"><a href="#cb21-428" aria-hidden="true" tabindex="-1"></a>The random forest classifier is fit to the training data and evaluated on the testing data.</span>
<span id="cb21-429"><a href="#cb21-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-432"><a href="#cb21-432" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-433"><a href="#cb21-433" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Random Forest Classifier</span></span>
<span id="cb21-434"><a href="#cb21-434" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb21-435"><a href="#cb21-435" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,  <span class="co"># Number of trees</span></span>
<span id="cb21-436"><a href="#cb21-436" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="va">None</span>,    <span class="co"># Maximum depth of trees</span></span>
<span id="cb21-437"><a href="#cb21-437" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb21-438"><a href="#cb21-438" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb21-439"><a href="#cb21-439" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb21-440"><a href="#cb21-440" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-441"><a href="#cb21-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-442"><a href="#cb21-442" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb21-443"><a href="#cb21-443" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X_train, y_train)</span>
<span id="cb21-444"><a href="#cb21-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-445"><a href="#cb21-445" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb21-446"><a href="#cb21-446" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> rf_model.predict(X_test)</span>
<span id="cb21-447"><a href="#cb21-447" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> rf_model.predict_proba(X_test)[:, <span class="dv">1</span>]  <span class="co"># Probability estimates for positive class</span></span>
<span id="cb21-448"><a href="#cb21-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-449"><a href="#cb21-449" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb21-450"><a href="#cb21-450" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb21-451"><a href="#cb21-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-452"><a href="#cb21-452" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Confusion Matrix</span></span>
<span id="cb21-453"><a href="#cb21-453" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb21-454"><a href="#cb21-454" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, </span>
<span id="cb21-455"><a href="#cb21-455" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>[<span class="st">'Predicted Negative'</span>, <span class="st">'Predicted Positive'</span>], </span>
<span id="cb21-456"><a href="#cb21-456" aria-hidden="true" tabindex="-1"></a>            yticklabels<span class="op">=</span>[<span class="st">'Actual Negative'</span>, <span class="st">'Actual Positive'</span>])</span>
<span id="cb21-457"><a href="#cb21-457" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Label'</span>)</span>
<span id="cb21-458"><a href="#cb21-458" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Label'</span>)</span>
<span id="cb21-459"><a href="#cb21-459" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix - Random Forest'</span>)</span>
<span id="cb21-460"><a href="#cb21-460" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-461"><a href="#cb21-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-462"><a href="#cb21-462" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb21-463"><a href="#cb21-463" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Random Forest Model Evaluation:"</span>)</span>
<span id="cb21-464"><a href="#cb21-464" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, y_pred)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-465"><a href="#cb21-465" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classification Report:"</span>)</span>
<span id="cb21-466"><a href="#cb21-466" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span>
<span id="cb21-467"><a href="#cb21-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-468"><a href="#cb21-468" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate ROC AUC</span></span>
<span id="cb21-469"><a href="#cb21-469" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> roc_auc_score(y_test, y_pred_proba)</span>
<span id="cb21-470"><a href="#cb21-470" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">ROC AUC Score: </span><span class="sc">{</span>roc_auc<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-471"><a href="#cb21-471" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-472"><a href="#cb21-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-473"><a href="#cb21-473" aria-hidden="true" tabindex="-1"></a>The results show strong performance from the random forest classifier, with an overall accuracy of 91% and recall of 75% for the positive class.</span>
<span id="cb21-474"><a href="#cb21-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-477"><a href="#cb21-477" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-478"><a href="#cb21-478" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: Fig-1</span></span>
<span id="cb21-479"><a href="#cb21-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-480"><a href="#cb21-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-481"><a href="#cb21-481" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature importance</span></span>
<span id="cb21-482"><a href="#cb21-482" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> pd.DataFrame({</span>
<span id="cb21-483"><a href="#cb21-483" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: X_train.columns,</span>
<span id="cb21-484"><a href="#cb21-484" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: rf_model.feature_importances_</span>
<span id="cb21-485"><a href="#cb21-485" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb21-486"><a href="#cb21-486" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> feature_importance.sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-487"><a href="#cb21-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-488"><a href="#cb21-488" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot top 15 features</span></span>
<span id="cb21-489"><a href="#cb21-489" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb21-490"><a href="#cb21-490" aria-hidden="true" tabindex="-1"></a>top_features <span class="op">=</span> feature_importance.head(<span class="dv">15</span>)</span>
<span id="cb21-491"><a href="#cb21-491" aria-hidden="true" tabindex="-1"></a>plt.barh(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Importance'</span>], align<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb21-492"><a href="#cb21-492" aria-hidden="true" tabindex="-1"></a>plt.yticks(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Feature'</span>])</span>
<span id="cb21-493"><a href="#cb21-493" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Importance'</span>)</span>
<span id="cb21-494"><a href="#cb21-494" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Feature Importance - Random Forest'</span>)</span>
<span id="cb21-495"><a href="#cb21-495" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-496"><a href="#cb21-496" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-497"><a href="#cb21-497" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-498"><a href="#cb21-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-499"><a href="#cb21-499" aria-hidden="true" tabindex="-1"></a>Although the random forest classifier in @Fig-1 is performing well, the feature importance plot reveals a concentration of importance on the predicted binding affinity score obtained from netMHCpan. This is not surprising.</span>
<span id="cb21-500"><a href="#cb21-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-501"><a href="#cb21-501" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training without netMHCpan</span></span>
<span id="cb21-502"><a href="#cb21-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-505"><a href="#cb21-505" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-506"><a href="#cb21-506" aria-hidden="true" tabindex="-1"></a><span class="co"># drop the Score_BA column</span></span>
<span id="cb21-507"><a href="#cb21-507" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train.drop(columns<span class="op">=</span>[<span class="st">'Score_BA'</span>])</span>
<span id="cb21-508"><a href="#cb21-508" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X_test.drop(columns<span class="op">=</span>[<span class="st">'Score_BA'</span>])</span>
<span id="cb21-509"><a href="#cb21-509" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-510"><a href="#cb21-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-513"><a href="#cb21-513" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-514"><a href="#cb21-514" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Random Forest Classifier</span></span>
<span id="cb21-515"><a href="#cb21-515" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb21-516"><a href="#cb21-516" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,  <span class="co"># Number of trees</span></span>
<span id="cb21-517"><a href="#cb21-517" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="va">None</span>,    <span class="co"># Maximum depth of trees</span></span>
<span id="cb21-518"><a href="#cb21-518" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb21-519"><a href="#cb21-519" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb21-520"><a href="#cb21-520" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb21-521"><a href="#cb21-521" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-522"><a href="#cb21-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-523"><a href="#cb21-523" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb21-524"><a href="#cb21-524" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X_train, y_train)</span>
<span id="cb21-525"><a href="#cb21-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-526"><a href="#cb21-526" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb21-527"><a href="#cb21-527" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> rf_model.predict(X_test)</span>
<span id="cb21-528"><a href="#cb21-528" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> rf_model.predict_proba(X_test)[:, <span class="dv">1</span>]  <span class="co"># Probability estimates for positive class</span></span>
<span id="cb21-529"><a href="#cb21-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-530"><a href="#cb21-530" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb21-531"><a href="#cb21-531" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb21-532"><a href="#cb21-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-533"><a href="#cb21-533" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Confusion Matrix</span></span>
<span id="cb21-534"><a href="#cb21-534" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb21-535"><a href="#cb21-535" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, </span>
<span id="cb21-536"><a href="#cb21-536" aria-hidden="true" tabindex="-1"></a>            xticklabels<span class="op">=</span>[<span class="st">'Predicted Negative'</span>, <span class="st">'Predicted Positive'</span>], </span>
<span id="cb21-537"><a href="#cb21-537" aria-hidden="true" tabindex="-1"></a>            yticklabels<span class="op">=</span>[<span class="st">'Actual Negative'</span>, <span class="st">'Actual Positive'</span>])</span>
<span id="cb21-538"><a href="#cb21-538" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Label'</span>)</span>
<span id="cb21-539"><a href="#cb21-539" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Label'</span>)</span>
<span id="cb21-540"><a href="#cb21-540" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix - Random Forest'</span>)</span>
<span id="cb21-541"><a href="#cb21-541" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-542"><a href="#cb21-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-543"><a href="#cb21-543" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb21-544"><a href="#cb21-544" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Random Forest Model Evaluation:"</span>)</span>
<span id="cb21-545"><a href="#cb21-545" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, y_pred)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-546"><a href="#cb21-546" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classification Report:"</span>)</span>
<span id="cb21-547"><a href="#cb21-547" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span>
<span id="cb21-548"><a href="#cb21-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-549"><a href="#cb21-549" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate ROC AUC</span></span>
<span id="cb21-550"><a href="#cb21-550" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> roc_auc_score(y_test, y_pred_proba)</span>
<span id="cb21-551"><a href="#cb21-551" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">ROC AUC Score: </span><span class="sc">{</span>roc_auc<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-552"><a href="#cb21-552" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-553"><a href="#cb21-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-556"><a href="#cb21-556" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-557"><a href="#cb21-557" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: Fig-2</span></span>
<span id="cb21-558"><a href="#cb21-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-559"><a href="#cb21-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-560"><a href="#cb21-560" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature importance</span></span>
<span id="cb21-561"><a href="#cb21-561" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> pd.DataFrame({</span>
<span id="cb21-562"><a href="#cb21-562" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: X_train.columns,</span>
<span id="cb21-563"><a href="#cb21-563" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: rf_model.feature_importances_</span>
<span id="cb21-564"><a href="#cb21-564" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb21-565"><a href="#cb21-565" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> feature_importance.sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-566"><a href="#cb21-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-567"><a href="#cb21-567" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot top 15 features</span></span>
<span id="cb21-568"><a href="#cb21-568" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb21-569"><a href="#cb21-569" aria-hidden="true" tabindex="-1"></a>top_features <span class="op">=</span> feature_importance.head(<span class="dv">15</span>)</span>
<span id="cb21-570"><a href="#cb21-570" aria-hidden="true" tabindex="-1"></a>plt.barh(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Importance'</span>], align<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb21-571"><a href="#cb21-571" aria-hidden="true" tabindex="-1"></a>plt.yticks(np.arange(<span class="bu">len</span>(top_features)), top_features[<span class="st">'Feature'</span>])</span>
<span id="cb21-572"><a href="#cb21-572" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Importance'</span>)</span>
<span id="cb21-573"><a href="#cb21-573" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Feature Importance - Random Forest'</span>)</span>
<span id="cb21-574"><a href="#cb21-574" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-575"><a href="#cb21-575" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-576"><a href="#cb21-576" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb21-577"><a href="#cb21-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-578"><a href="#cb21-578" aria-hidden="true" tabindex="-1"></a><span class="fu">### Basic Convolutional Neural Network</span></span>
<span id="cb21-579"><a href="#cb21-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-582"><a href="#cb21-582" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb21-583"><a href="#cb21-583" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-584"><a href="#cb21-584" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.preprocessing.sequence <span class="im">import</span> pad_sequences</span>
<span id="cb21-585"><a href="#cb21-585" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb21-586"><a href="#cb21-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-587"><a href="#cb21-587" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Filter the epitopes and negatives dataframes to only contain sequences and labels</span></span>
<span id="cb21-588"><a href="#cb21-588" aria-hidden="true" tabindex="-1"></a>epitopes_filtered <span class="op">=</span> epitopes[[<span class="st">'peptide'</span>, <span class="st">'label'</span>]].copy()</span>
<span id="cb21-589"><a href="#cb21-589" aria-hidden="true" tabindex="-1"></a>epitopes_filtered.rename(columns<span class="op">=</span>{<span class="st">'peptide'</span>: <span class="st">'sequence'</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-590"><a href="#cb21-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-591"><a href="#cb21-591" aria-hidden="true" tabindex="-1"></a>negatives_filtered <span class="op">=</span> negatives[[<span class="st">'peptide'</span>, <span class="st">'label'</span>]].copy()</span>
<span id="cb21-592"><a href="#cb21-592" aria-hidden="true" tabindex="-1"></a>negatives_filtered.rename(columns<span class="op">=</span>{<span class="st">'peptide'</span>: <span class="st">'sequence'</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-593"><a href="#cb21-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-594"><a href="#cb21-594" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine the datasets</span></span>
<span id="cb21-595"><a href="#cb21-595" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> pd.concat([epitopes_filtered, negatives_filtered], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-596"><a href="#cb21-596" aria-hidden="true" tabindex="-1"></a>combined_data <span class="op">=</span> combined_data.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-597"><a href="#cb21-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-598"><a href="#cb21-598" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of samples: </span><span class="sc">{</span>combined_data<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-599"><a href="#cb21-599" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples: </span><span class="sc">{</span><span class="bu">sum</span>(combined_data[<span class="st">'label'</span>] <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-600"><a href="#cb21-600" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples: </span><span class="sc">{</span><span class="bu">sum</span>(combined_data[<span class="st">'label'</span>] <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-601"><a href="#cb21-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-602"><a href="#cb21-602" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Prepare for one-hot encoding</span></span>
<span id="cb21-603"><a href="#cb21-603" aria-hidden="true" tabindex="-1"></a><span class="co"># First, get all unique amino acids in our dataset</span></span>
<span id="cb21-604"><a href="#cb21-604" aria-hidden="true" tabindex="-1"></a>all_sequences <span class="op">=</span> combined_data[<span class="st">'sequence'</span>].values</span>
<span id="cb21-605"><a href="#cb21-605" aria-hidden="true" tabindex="-1"></a>unique_chars <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">set</span>(<span class="st">''</span>.join(all_sequences)))</span>
<span id="cb21-606"><a href="#cb21-606" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Unique amino acids in dataset: </span><span class="sc">{</span>unique_chars<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-607"><a href="#cb21-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-608"><a href="#cb21-608" aria-hidden="true" tabindex="-1"></a><span class="co"># Create mapping dictionaries for one-hot encoding</span></span>
<span id="cb21-609"><a href="#cb21-609" aria-hidden="true" tabindex="-1"></a>char_to_index <span class="op">=</span> {char: i<span class="op">+</span><span class="dv">1</span> <span class="cf">for</span> i, char <span class="kw">in</span> <span class="bu">enumerate</span>(unique_chars)}  <span class="co"># Start from 1, reserve 0 for padding</span></span>
<span id="cb21-610"><a href="#cb21-610" aria-hidden="true" tabindex="-1"></a>index_to_char <span class="op">=</span> {i<span class="op">+</span><span class="dv">1</span>: char <span class="cf">for</span> i, char <span class="kw">in</span> <span class="bu">enumerate</span>(unique_chars)}</span>
<span id="cb21-611"><a href="#cb21-611" aria-hidden="true" tabindex="-1"></a>index_to_char[<span class="dv">0</span>] <span class="op">=</span> <span class="st">''</span>  <span class="co"># Padding token</span></span>
<span id="cb21-612"><a href="#cb21-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-613"><a href="#cb21-613" aria-hidden="true" tabindex="-1"></a><span class="co"># Find maximum sequence length</span></span>
<span id="cb21-614"><a href="#cb21-614" aria-hidden="true" tabindex="-1"></a>max_length <span class="op">=</span> <span class="bu">max</span>(<span class="bu">len</span>(seq) <span class="cf">for</span> seq <span class="kw">in</span> all_sequences)</span>
<span id="cb21-615"><a href="#cb21-615" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Maximum sequence length: </span><span class="sc">{</span>max_length<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-616"><a href="#cb21-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-617"><a href="#cb21-617" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert sequences to integer sequences</span></span>
<span id="cb21-618"><a href="#cb21-618" aria-hidden="true" tabindex="-1"></a>int_sequences <span class="op">=</span> []</span>
<span id="cb21-619"><a href="#cb21-619" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> seq <span class="kw">in</span> all_sequences:</span>
<span id="cb21-620"><a href="#cb21-620" aria-hidden="true" tabindex="-1"></a>    int_seq <span class="op">=</span> [char_to_index[char] <span class="cf">for</span> char <span class="kw">in</span> seq]</span>
<span id="cb21-621"><a href="#cb21-621" aria-hidden="true" tabindex="-1"></a>    int_sequences.append(int_seq)</span>
<span id="cb21-622"><a href="#cb21-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-623"><a href="#cb21-623" aria-hidden="true" tabindex="-1"></a><span class="co"># Pad sequences to have the same length</span></span>
<span id="cb21-624"><a href="#cb21-624" aria-hidden="true" tabindex="-1"></a>padded_sequences <span class="op">=</span> pad_sequences(int_sequences, maxlen<span class="op">=</span>max_length, padding<span class="op">=</span><span class="st">'post'</span>)</span>
<span id="cb21-625"><a href="#cb21-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-626"><a href="#cb21-626" aria-hidden="true" tabindex="-1"></a><span class="co"># One-hot encode the padded sequences</span></span>
<span id="cb21-627"><a href="#cb21-627" aria-hidden="true" tabindex="-1"></a>num_chars <span class="op">=</span> <span class="bu">len</span>(unique_chars) <span class="op">+</span> <span class="dv">1</span>  <span class="co"># +1 for padding token</span></span>
<span id="cb21-628"><a href="#cb21-628" aria-hidden="true" tabindex="-1"></a>X_onehot <span class="op">=</span> np.zeros((<span class="bu">len</span>(padded_sequences), max_length, num_chars))</span>
<span id="cb21-629"><a href="#cb21-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-630"><a href="#cb21-630" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, seq <span class="kw">in</span> <span class="bu">enumerate</span>(padded_sequences):</span>
<span id="cb21-631"><a href="#cb21-631" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j, char_idx <span class="kw">in</span> <span class="bu">enumerate</span>(seq):</span>
<span id="cb21-632"><a href="#cb21-632" aria-hidden="true" tabindex="-1"></a>        X_onehot[i, j, char_idx] <span class="op">=</span> <span class="fl">1.0</span>  <span class="co"># One-hot encode</span></span>
<span id="cb21-633"><a href="#cb21-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-634"><a href="#cb21-634" aria-hidden="true" tabindex="-1"></a><span class="co"># Get labels</span></span>
<span id="cb21-635"><a href="#cb21-635" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> combined_data[<span class="st">'label'</span>].values</span>
<span id="cb21-636"><a href="#cb21-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-637"><a href="#cb21-637" aria-hidden="true" tabindex="-1"></a><span class="co"># Print shapes to verify dimensions</span></span>
<span id="cb21-638"><a href="#cb21-638" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X_onehot shape: </span><span class="sc">{</span>X_onehot<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-639"><a href="#cb21-639" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of unique amino acids (including padding): </span><span class="sc">{</span>num_chars<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-640"><a href="#cb21-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-641"><a href="#cb21-641" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Split data into training, validation, and testing sets (70/15/15 split)</span></span>
<span id="cb21-642"><a href="#cb21-642" aria-hidden="true" tabindex="-1"></a><span class="co"># First split into temporary train and test</span></span>
<span id="cb21-643"><a href="#cb21-643" aria-hidden="true" tabindex="-1"></a>X_temp, X_test, y_temp, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb21-644"><a href="#cb21-644" aria-hidden="true" tabindex="-1"></a>    X_onehot, y, test_size<span class="op">=</span><span class="fl">0.15</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y</span>
<span id="cb21-645"><a href="#cb21-645" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-646"><a href="#cb21-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-647"><a href="#cb21-647" aria-hidden="true" tabindex="-1"></a><span class="co"># Then split the temporary train into final train and validation</span></span>
<span id="cb21-648"><a href="#cb21-648" aria-hidden="true" tabindex="-1"></a><span class="co"># To get 70/15 split from the original data, we need to calculate the right proportion:</span></span>
<span id="cb21-649"><a href="#cb21-649" aria-hidden="true" tabindex="-1"></a><span class="co"># If test is 15% of total, then validation should be 15/85 of the remaining data (approx 17.65%)</span></span>
<span id="cb21-650"><a href="#cb21-650" aria-hidden="true" tabindex="-1"></a>X_train, X_val, y_train, y_val <span class="op">=</span> train_test_split(</span>
<span id="cb21-651"><a href="#cb21-651" aria-hidden="true" tabindex="-1"></a>    X_temp, y_temp, test_size<span class="op">=</span><span class="fl">0.1765</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y_temp</span>
<span id="cb21-652"><a href="#cb21-652" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-653"><a href="#cb21-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-654"><a href="#cb21-654" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training set shape: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>X_train<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="op">/</span>X_onehot<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss"> of total)"</span>)</span>
<span id="cb21-655"><a href="#cb21-655" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Validation set shape: </span><span class="sc">{</span>X_val<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>X_val<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="op">/</span>X_onehot<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss"> of total)"</span>)</span>
<span id="cb21-656"><a href="#cb21-656" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Testing set shape: </span><span class="sc">{</span>X_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>X_test<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="op">/</span>X_onehot<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss"> of total)"</span>)</span>
<span id="cb21-657"><a href="#cb21-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-658"><a href="#cb21-658" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in training: </span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">1</span>)<span class="op">/</span><span class="bu">len</span>(y_train)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb21-659"><a href="#cb21-659" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in training: </span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_train <span class="op">==</span> <span class="dv">0</span>)<span class="op">/</span><span class="bu">len</span>(y_train)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb21-660"><a href="#cb21-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-661"><a href="#cb21-661" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in validation: </span><span class="sc">{</span><span class="bu">sum</span>(y_val <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_val <span class="op">==</span> <span class="dv">1</span>)<span class="op">/</span><span class="bu">len</span>(y_val)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb21-662"><a href="#cb21-662" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in validation: </span><span class="sc">{</span><span class="bu">sum</span>(y_val <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_val <span class="op">==</span> <span class="dv">0</span>)<span class="op">/</span><span class="bu">len</span>(y_val)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb21-663"><a href="#cb21-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-664"><a href="#cb21-664" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Positive samples in testing: </span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">1</span>)<span class="op">/</span><span class="bu">len</span>(y_test)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb21-665"><a href="#cb21-665" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Negative samples in testing: </span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="bu">sum</span>(y_test <span class="op">==</span> <span class="dv">0</span>)<span class="op">/</span><span class="bu">len</span>(y_test)<span class="sc">:.1%}</span><span class="ss">)"</span>)</span>
<span id="cb21-666"><a href="#cb21-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-667"><a href="#cb21-667" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb21-668"><a href="#cb21-668" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Sequential, Model</span>
<span id="cb21-669"><a href="#cb21-669" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input, BatchNormalization</span>
<span id="cb21-670"><a href="#cb21-670" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.callbacks <span class="im">import</span> EarlyStopping, ModelCheckpoint, ReduceLROnPlateau</span>
<span id="cb21-671"><a href="#cb21-671" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.regularizers <span class="im">import</span> l2</span>
<span id="cb21-672"><a href="#cb21-672" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.optimizers <span class="im">import</span> Adam</span>
<span id="cb21-673"><a href="#cb21-673" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_curve, f1_score</span>
<span id="cb21-674"><a href="#cb21-674" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-675"><a href="#cb21-675" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb21-676"><a href="#cb21-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-677"><a href="#cb21-677" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the focal loss function to better handle class imbalance</span></span>
<span id="cb21-678"><a href="#cb21-678" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> focal_loss(gamma<span class="op">=</span><span class="fl">2.0</span>, alpha<span class="op">=</span><span class="fl">0.25</span>):</span>
<span id="cb21-679"><a href="#cb21-679" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> focal_loss_fn(y_true, y_pred):</span>
<span id="cb21-680"><a href="#cb21-680" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert one-hot encoded targets to integers</span></span>
<span id="cb21-681"><a href="#cb21-681" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> y_true.shape[<span class="op">-</span><span class="dv">1</span>] <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb21-682"><a href="#cb21-682" aria-hidden="true" tabindex="-1"></a>            y_true <span class="op">=</span> tf.squeeze(y_true, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb21-683"><a href="#cb21-683" aria-hidden="true" tabindex="-1"></a>        y_true <span class="op">=</span> tf.cast(y_true, tf.int32)</span>
<span id="cb21-684"><a href="#cb21-684" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-685"><a href="#cb21-685" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the standard sparse categorical crossentropy</span></span>
<span id="cb21-686"><a href="#cb21-686" aria-hidden="true" tabindex="-1"></a>        sce <span class="op">=</span> tf.keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">False</span>, reduction<span class="op">=</span>tf.keras.losses.Reduction.NONE)(y_true, y_pred)</span>
<span id="cb21-687"><a href="#cb21-687" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-688"><a href="#cb21-688" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the prediction probability for the true class</span></span>
<span id="cb21-689"><a href="#cb21-689" aria-hidden="true" tabindex="-1"></a>        y_pred_proba <span class="op">=</span> tf.gather_nd(y_pred, tf.stack([tf.<span class="bu">range</span>(tf.shape(y_true)[<span class="dv">0</span>]), tf.cast(y_true, tf.int32)], axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb21-690"><a href="#cb21-690" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-691"><a href="#cb21-691" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply focal loss formula</span></span>
<span id="cb21-692"><a href="#cb21-692" aria-hidden="true" tabindex="-1"></a>        <span class="co"># p_t = p if y == 1 else 1-p for class 0</span></span>
<span id="cb21-693"><a href="#cb21-693" aria-hidden="true" tabindex="-1"></a>        p_t <span class="op">=</span> y_pred_proba</span>
<span id="cb21-694"><a href="#cb21-694" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add the alpha weighing factor</span></span>
<span id="cb21-695"><a href="#cb21-695" aria-hidden="true" tabindex="-1"></a>        alpha_factor <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb21-696"><a href="#cb21-696" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> alpha <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb21-697"><a href="#cb21-697" aria-hidden="true" tabindex="-1"></a>            <span class="co"># alpha_t = alpha if y == 1 else 1-alpha for class 0</span></span>
<span id="cb21-698"><a href="#cb21-698" aria-hidden="true" tabindex="-1"></a>            alpha_t <span class="op">=</span> tf.where(tf.equal(y_true, <span class="dv">1</span>), alpha, <span class="dv">1</span><span class="op">-</span>alpha)</span>
<span id="cb21-699"><a href="#cb21-699" aria-hidden="true" tabindex="-1"></a>            alpha_factor <span class="op">=</span> alpha_t</span>
<span id="cb21-700"><a href="#cb21-700" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-701"><a href="#cb21-701" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate focal weight</span></span>
<span id="cb21-702"><a href="#cb21-702" aria-hidden="true" tabindex="-1"></a>        gamma_factor <span class="op">=</span> tf.<span class="bu">pow</span>(<span class="fl">1.0</span> <span class="op">-</span> p_t, gamma)</span>
<span id="cb21-703"><a href="#cb21-703" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-704"><a href="#cb21-704" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the final loss</span></span>
<span id="cb21-705"><a href="#cb21-705" aria-hidden="true" tabindex="-1"></a>        focal_loss <span class="op">=</span> alpha_factor <span class="op">*</span> gamma_factor <span class="op">*</span> sce</span>
<span id="cb21-706"><a href="#cb21-706" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-707"><a href="#cb21-707" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> tf.reduce_mean(focal_loss)</span>
<span id="cb21-708"><a href="#cb21-708" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-709"><a href="#cb21-709" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> focal_loss_fn</span>
<span id="cb21-710"><a href="#cb21-710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-711"><a href="#cb21-711" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an optimized CNN model for sequence data</span></span>
<span id="cb21-712"><a href="#cb21-712" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_optimized_cnn_model(input_shape, num_classes<span class="op">=</span><span class="dv">2</span>, use_focal_loss<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb21-713"><a href="#cb21-713" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> Input(shape<span class="op">=</span>input_shape)</span>
<span id="cb21-714"><a href="#cb21-714" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-715"><a href="#cb21-715" aria-hidden="true" tabindex="-1"></a>    <span class="co"># First convolutional block</span></span>
<span id="cb21-716"><a href="#cb21-716" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv1D(<span class="dv">32</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">'relu'</span>, padding<span class="op">=</span><span class="st">'same'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(inputs)</span>
<span id="cb21-717"><a href="#cb21-717" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb21-718"><a href="#cb21-718" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> MaxPooling1D(pool_size<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">'same'</span>)(x)</span>
<span id="cb21-719"><a href="#cb21-719" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-720"><a href="#cb21-720" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Second convolutional block with increased filters</span></span>
<span id="cb21-721"><a href="#cb21-721" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv1D(<span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">'relu'</span>, padding<span class="op">=</span><span class="st">'same'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(x)</span>
<span id="cb21-722"><a href="#cb21-722" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb21-723"><a href="#cb21-723" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> MaxPooling1D(pool_size<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">'same'</span>)(x)</span>
<span id="cb21-724"><a href="#cb21-724" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-725"><a href="#cb21-725" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Third convolutional block with even more filters</span></span>
<span id="cb21-726"><a href="#cb21-726" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Conv1D(<span class="dv">128</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">'relu'</span>, padding<span class="op">=</span><span class="st">'same'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(x)</span>
<span id="cb21-727"><a href="#cb21-727" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb21-728"><a href="#cb21-728" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-729"><a href="#cb21-729" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Flatten and dense layers</span></span>
<span id="cb21-730"><a href="#cb21-730" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Flatten()(x)</span>
<span id="cb21-731"><a href="#cb21-731" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-732"><a href="#cb21-732" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add more capacity to the dense layers</span></span>
<span id="cb21-733"><a href="#cb21-733" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">'relu'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(x)</span>
<span id="cb21-734"><a href="#cb21-734" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb21-735"><a href="#cb21-735" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dropout(<span class="fl">0.4</span>)(x)</span>
<span id="cb21-736"><a href="#cb21-736" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-737"><a href="#cb21-737" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>, kernel_regularizer<span class="op">=</span>l2(<span class="fl">0.001</span>))(x)</span>
<span id="cb21-738"><a href="#cb21-738" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> BatchNormalization()(x)</span>
<span id="cb21-739"><a href="#cb21-739" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dropout(<span class="fl">0.3</span>)(x)</span>
<span id="cb21-740"><a href="#cb21-740" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-741"><a href="#cb21-741" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Output layer</span></span>
<span id="cb21-742"><a href="#cb21-742" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> Dense(num_classes, activation<span class="op">=</span><span class="st">'softmax'</span>)(x)</span>
<span id="cb21-743"><a href="#cb21-743" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-744"><a href="#cb21-744" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs)</span>
<span id="cb21-745"><a href="#cb21-745" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-746"><a href="#cb21-746" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use a lower learning rate for better stability</span></span>
<span id="cb21-747"><a href="#cb21-747" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> Adam(learning_rate<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb21-748"><a href="#cb21-748" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-749"><a href="#cb21-749" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use focal loss if requested, otherwise use standard cross-entropy</span></span>
<span id="cb21-750"><a href="#cb21-750" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> use_focal_loss:</span>
<span id="cb21-751"><a href="#cb21-751" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> focal_loss(gamma<span class="op">=</span><span class="fl">2.0</span>, alpha<span class="op">=</span><span class="fl">0.75</span>)  <span class="co"># Adjust alpha based on class imbalance</span></span>
<span id="cb21-752"><a href="#cb21-752" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb21-753"><a href="#cb21-753" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> <span class="st">'sparse_categorical_crossentropy'</span></span>
<span id="cb21-754"><a href="#cb21-754" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-755"><a href="#cb21-755" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(</span>
<span id="cb21-756"><a href="#cb21-756" aria-hidden="true" tabindex="-1"></a>        optimizer<span class="op">=</span>optimizer,</span>
<span id="cb21-757"><a href="#cb21-757" aria-hidden="true" tabindex="-1"></a>        loss<span class="op">=</span>loss,</span>
<span id="cb21-758"><a href="#cb21-758" aria-hidden="true" tabindex="-1"></a>        metrics<span class="op">=</span>[<span class="st">'accuracy'</span>]</span>
<span id="cb21-759"><a href="#cb21-759" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb21-760"><a href="#cb21-760" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-761"><a href="#cb21-761" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb21-762"><a href="#cb21-762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-763"><a href="#cb21-763" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate class weights based on class frequencies</span></span>
<span id="cb21-764"><a href="#cb21-764" aria-hidden="true" tabindex="-1"></a><span class="co"># This gives more weight to the minority class during training</span></span>
<span id="cb21-765"><a href="#cb21-765" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_class_weights(y_train):</span>
<span id="cb21-766"><a href="#cb21-766" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Count the number of samples per class</span></span>
<span id="cb21-767"><a href="#cb21-767" aria-hidden="true" tabindex="-1"></a>    class_counts <span class="op">=</span> np.bincount(y_train)</span>
<span id="cb21-768"><a href="#cb21-768" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the weight for each class (inversely proportional to class frequency)</span></span>
<span id="cb21-769"><a href="#cb21-769" aria-hidden="true" tabindex="-1"></a>    total_samples <span class="op">=</span> <span class="bu">len</span>(y_train)</span>
<span id="cb21-770"><a href="#cb21-770" aria-hidden="true" tabindex="-1"></a>    class_weights <span class="op">=</span> {</span>
<span id="cb21-771"><a href="#cb21-771" aria-hidden="true" tabindex="-1"></a>        i: total_samples <span class="op">/</span> (<span class="bu">len</span>(class_counts) <span class="op">*</span> count) </span>
<span id="cb21-772"><a href="#cb21-772" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, count <span class="kw">in</span> <span class="bu">enumerate</span>(class_counts)</span>
<span id="cb21-773"><a href="#cb21-773" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb21-774"><a href="#cb21-774" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> class_weights</span>
<span id="cb21-775"><a href="#cb21-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-776"><a href="#cb21-776" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the class weights for our training data</span></span>
<span id="cb21-777"><a href="#cb21-777" aria-hidden="true" tabindex="-1"></a>class_weights <span class="op">=</span> compute_class_weights(y_train)</span>
<span id="cb21-778"><a href="#cb21-778" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Class weights: </span><span class="sc">{</span>class_weights<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-779"><a href="#cb21-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-780"><a href="#cb21-780" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an optimized CNN model</span></span>
<span id="cb21-781"><a href="#cb21-781" aria-hidden="true" tabindex="-1"></a>optimized_cnn_model <span class="op">=</span> create_optimized_cnn_model(input_shape<span class="op">=</span>(X_train.shape[<span class="dv">1</span>], X_train.shape[<span class="dv">2</span>]), use_focal_loss<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-782"><a href="#cb21-782" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(optimized_cnn_model.summary())</span>
<span id="cb21-783"><a href="#cb21-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-784"><a href="#cb21-784" aria-hidden="true" tabindex="-1"></a><span class="co"># Define more sophisticated callbacks</span></span>
<span id="cb21-785"><a href="#cb21-785" aria-hidden="true" tabindex="-1"></a>early_stopping <span class="op">=</span> EarlyStopping(</span>
<span id="cb21-786"><a href="#cb21-786" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_loss'</span>, </span>
<span id="cb21-787"><a href="#cb21-787" aria-hidden="true" tabindex="-1"></a>    patience<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb21-788"><a href="#cb21-788" aria-hidden="true" tabindex="-1"></a>    restore_best_weights<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb21-789"><a href="#cb21-789" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span></span>
<span id="cb21-790"><a href="#cb21-790" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-791"><a href="#cb21-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-792"><a href="#cb21-792" aria-hidden="true" tabindex="-1"></a>reduce_lr <span class="op">=</span> ReduceLROnPlateau(</span>
<span id="cb21-793"><a href="#cb21-793" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_loss'</span>,</span>
<span id="cb21-794"><a href="#cb21-794" aria-hidden="true" tabindex="-1"></a>    factor<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb21-795"><a href="#cb21-795" aria-hidden="true" tabindex="-1"></a>    patience<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb21-796"><a href="#cb21-796" aria-hidden="true" tabindex="-1"></a>    min_lr<span class="op">=</span><span class="fl">0.00001</span>,</span>
<span id="cb21-797"><a href="#cb21-797" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span></span>
<span id="cb21-798"><a href="#cb21-798" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-799"><a href="#cb21-799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-800"><a href="#cb21-800" aria-hidden="true" tabindex="-1"></a>model_checkpoint <span class="op">=</span> ModelCheckpoint(</span>
<span id="cb21-801"><a href="#cb21-801" aria-hidden="true" tabindex="-1"></a>    <span class="st">'best_optimized_cnn_model.keras'</span>,</span>
<span id="cb21-802"><a href="#cb21-802" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_accuracy'</span>,</span>
<span id="cb21-803"><a href="#cb21-803" aria-hidden="true" tabindex="-1"></a>    save_best_only<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb21-804"><a href="#cb21-804" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span></span>
<span id="cb21-805"><a href="#cb21-805" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-806"><a href="#cb21-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-807"><a href="#cb21-807" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model with class weights</span></span>
<span id="cb21-808"><a href="#cb21-808" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> optimized_cnn_model.fit(</span>
<span id="cb21-809"><a href="#cb21-809" aria-hidden="true" tabindex="-1"></a>    X_train, y_train,</span>
<span id="cb21-810"><a href="#cb21-810" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">20</span>,  <span class="co"># Increase epochs since we have early stopping</span></span>
<span id="cb21-811"><a href="#cb21-811" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb21-812"><a href="#cb21-812" aria-hidden="true" tabindex="-1"></a>    validation_data<span class="op">=</span>(X_val, y_val),</span>
<span id="cb21-813"><a href="#cb21-813" aria-hidden="true" tabindex="-1"></a>    callbacks<span class="op">=</span>[early_stopping, reduce_lr, model_checkpoint],</span>
<span id="cb21-814"><a href="#cb21-814" aria-hidden="true" tabindex="-1"></a>    class_weight<span class="op">=</span>class_weights,  <span class="co"># Use class weights during training</span></span>
<span id="cb21-815"><a href="#cb21-815" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span></span>
<span id="cb21-816"><a href="#cb21-816" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-817"><a href="#cb21-817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-818"><a href="#cb21-818" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model on test data</span></span>
<span id="cb21-819"><a href="#cb21-819" aria-hidden="true" tabindex="-1"></a>test_loss, test_accuracy <span class="op">=</span> optimized_cnn_model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb21-820"><a href="#cb21-820" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test accuracy: </span><span class="sc">{</span>test_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-821"><a href="#cb21-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-822"><a href="#cb21-822" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on test data</span></span>
<span id="cb21-823"><a href="#cb21-823" aria-hidden="true" tabindex="-1"></a>y_pred_proba <span class="op">=</span> optimized_cnn_model.predict(X_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb21-824"><a href="#cb21-824" aria-hidden="true" tabindex="-1"></a>y_pred_proba_positive <span class="op">=</span> y_pred_proba[:, <span class="dv">1</span>]  <span class="co"># Probability for positive class</span></span>
<span id="cb21-825"><a href="#cb21-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-826"><a href="#cb21-826" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the optimal threshold for F1 score</span></span>
<span id="cb21-827"><a href="#cb21-827" aria-hidden="true" tabindex="-1"></a>thresholds <span class="op">=</span> np.arange(<span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="fl">0.05</span>)</span>
<span id="cb21-828"><a href="#cb21-828" aria-hidden="true" tabindex="-1"></a>f1_scores <span class="op">=</span> []</span>
<span id="cb21-829"><a href="#cb21-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-830"><a href="#cb21-830" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> threshold <span class="kw">in</span> thresholds:</span>
<span id="cb21-831"><a href="#cb21-831" aria-hidden="true" tabindex="-1"></a>    y_pred_thresholded <span class="op">=</span> (y_pred_proba_positive <span class="op">&gt;=</span> threshold).astype(<span class="bu">int</span>)</span>
<span id="cb21-832"><a href="#cb21-832" aria-hidden="true" tabindex="-1"></a>    f1 <span class="op">=</span> f1_score(y_test, y_pred_thresholded)</span>
<span id="cb21-833"><a href="#cb21-833" aria-hidden="true" tabindex="-1"></a>    f1_scores.append(f1)</span>
<span id="cb21-834"><a href="#cb21-834" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(f"Threshold: {threshold:.2f}, F1 Score: {f1:.4f}")</span></span>
<span id="cb21-835"><a href="#cb21-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-836"><a href="#cb21-836" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the best threshold</span></span>
<span id="cb21-837"><a href="#cb21-837" aria-hidden="true" tabindex="-1"></a>best_threshold_idx <span class="op">=</span> np.argmax(f1_scores)</span>
<span id="cb21-838"><a href="#cb21-838" aria-hidden="true" tabindex="-1"></a>best_threshold <span class="op">=</span> thresholds[best_threshold_idx]</span>
<span id="cb21-839"><a href="#cb21-839" aria-hidden="true" tabindex="-1"></a>best_f1 <span class="op">=</span> f1_scores[best_threshold_idx]</span>
<span id="cb21-840"><a href="#cb21-840" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Optimal threshold: </span><span class="sc">{</span>best_threshold<span class="sc">:.2f}</span><span class="ss"> with F1 Score: </span><span class="sc">{</span>best_f1<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-841"><a href="#cb21-841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-842"><a href="#cb21-842" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the best threshold</span></span>
<span id="cb21-843"><a href="#cb21-843" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> (y_pred_proba_positive <span class="op">&gt;=</span> best_threshold).astype(<span class="bu">int</span>)</span>
<span id="cb21-844"><a href="#cb21-844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-845"><a href="#cb21-845" aria-hidden="true" tabindex="-1"></a><span class="co"># Print classification report with the optimized threshold</span></span>
<span id="cb21-846"><a href="#cb21-846" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix</span>
<span id="cb21-847"><a href="#cb21-847" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classification Report with Optimized Threshold:"</span>)</span>
<span id="cb21-848"><a href="#cb21-848" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span>
<span id="cb21-849"><a href="#cb21-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-850"><a href="#cb21-850" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot confusion matrix</span></span>
<span id="cb21-851"><a href="#cb21-851" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb21-852"><a href="#cb21-852" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb21-853"><a href="#cb21-853" aria-hidden="true" tabindex="-1"></a>plt.imshow(cm, interpolation<span class="op">=</span><span class="st">'nearest'</span>, cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb21-854"><a href="#cb21-854" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix (Optimized Threshold)'</span>)</span>
<span id="cb21-855"><a href="#cb21-855" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb21-856"><a href="#cb21-856" aria-hidden="true" tabindex="-1"></a>tick_marks <span class="op">=</span> np.arange(<span class="dv">2</span>)</span>
<span id="cb21-857"><a href="#cb21-857" aria-hidden="true" tabindex="-1"></a>plt.xticks(tick_marks, [<span class="st">'Negative'</span>, <span class="st">'Positive'</span>])</span>
<span id="cb21-858"><a href="#cb21-858" aria-hidden="true" tabindex="-1"></a>plt.yticks(tick_marks, [<span class="st">'Negative'</span>, <span class="st">'Positive'</span>])</span>
<span id="cb21-859"><a href="#cb21-859" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Label'</span>)</span>
<span id="cb21-860"><a href="#cb21-860" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Label'</span>)</span>
<span id="cb21-861"><a href="#cb21-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-862"><a href="#cb21-862" aria-hidden="true" tabindex="-1"></a><span class="co"># Add text annotations to the confusion matrix</span></span>
<span id="cb21-863"><a href="#cb21-863" aria-hidden="true" tabindex="-1"></a>thresh <span class="op">=</span> cm.<span class="bu">max</span>() <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb21-864"><a href="#cb21-864" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(cm.shape[<span class="dv">0</span>]):</span>
<span id="cb21-865"><a href="#cb21-865" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(cm.shape[<span class="dv">1</span>]):</span>
<span id="cb21-866"><a href="#cb21-866" aria-hidden="true" tabindex="-1"></a>        plt.text(j, i, cm[i, j],</span>
<span id="cb21-867"><a href="#cb21-867" aria-hidden="true" tabindex="-1"></a>                 horizontalalignment<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb21-868"><a href="#cb21-868" aria-hidden="true" tabindex="-1"></a>                 color<span class="op">=</span><span class="st">"white"</span> <span class="cf">if</span> cm[i, j] <span class="op">&gt;</span> thresh <span class="cf">else</span> <span class="st">"black"</span>)</span>
<span id="cb21-869"><a href="#cb21-869" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-870"><a href="#cb21-870" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-871"><a href="#cb21-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-872"><a href="#cb21-872" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot training history</span></span>
<span id="cb21-873"><a href="#cb21-873" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb21-874"><a href="#cb21-874" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb21-875"><a href="#cb21-875" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'accuracy'</span>], label<span class="op">=</span><span class="st">'Training Accuracy'</span>)</span>
<span id="cb21-876"><a href="#cb21-876" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'val_accuracy'</span>], label<span class="op">=</span><span class="st">'Validation Accuracy'</span>)</span>
<span id="cb21-877"><a href="#cb21-877" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Model Accuracy'</span>)</span>
<span id="cb21-878"><a href="#cb21-878" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb21-879"><a href="#cb21-879" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb21-880"><a href="#cb21-880" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb21-881"><a href="#cb21-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-882"><a href="#cb21-882" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb21-883"><a href="#cb21-883" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'loss'</span>], label<span class="op">=</span><span class="st">'Training Loss'</span>)</span>
<span id="cb21-884"><a href="#cb21-884" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'val_loss'</span>], label<span class="op">=</span><span class="st">'Validation Loss'</span>)</span>
<span id="cb21-885"><a href="#cb21-885" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Model Loss'</span>)</span>
<span id="cb21-886"><a href="#cb21-886" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb21-887"><a href="#cb21-887" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb21-888"><a href="#cb21-888" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb21-889"><a href="#cb21-889" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-890"><a href="#cb21-890" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-891"><a href="#cb21-891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-892"><a href="#cb21-892" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot ROC curve</span></span>
<span id="cb21-893"><a href="#cb21-893" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, auc</span>
<span id="cb21-894"><a href="#cb21-894" aria-hidden="true" tabindex="-1"></a>fpr, tpr, _ <span class="op">=</span> roc_curve(y_test, y_pred_proba_positive)</span>
<span id="cb21-895"><a href="#cb21-895" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb21-896"><a href="#cb21-896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-897"><a href="#cb21-897" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb21-898"><a href="#cb21-898" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr, tpr, color<span class="op">=</span><span class="st">'darkorange'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="ss">f'ROC curve (area = </span><span class="sc">{</span>roc_auc<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb21-899"><a href="#cb21-899" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'navy'</span>, lw<span class="op">=</span><span class="dv">2</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb21-900"><a href="#cb21-900" aria-hidden="true" tabindex="-1"></a>plt.scatter(fpr[np.argmin(np.<span class="bu">abs</span>(thresholds <span class="op">-</span> best_threshold))], </span>
<span id="cb21-901"><a href="#cb21-901" aria-hidden="true" tabindex="-1"></a>            tpr[np.argmin(np.<span class="bu">abs</span>(thresholds <span class="op">-</span> best_threshold))], </span>
<span id="cb21-902"><a href="#cb21-902" aria-hidden="true" tabindex="-1"></a>            c<span class="op">=</span><span class="st">'red'</span>, marker<span class="op">=</span><span class="st">'o'</span>, s<span class="op">=</span><span class="dv">100</span>, label<span class="op">=</span><span class="ss">f'Best threshold = </span><span class="sc">{</span>best_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb21-903"><a href="#cb21-903" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="fl">0.0</span>, <span class="fl">1.0</span>])</span>
<span id="cb21-904"><a href="#cb21-904" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="fl">0.0</span>, <span class="fl">1.05</span>])</span>
<span id="cb21-905"><a href="#cb21-905" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'False Positive Rate'</span>)</span>
<span id="cb21-906"><a href="#cb21-906" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb21-907"><a href="#cb21-907" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Receiver Operating Characteristic'</span>)</span>
<span id="cb21-908"><a href="#cb21-908" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb21-909"><a href="#cb21-909" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-910"><a href="#cb21-910" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-911"><a href="#cb21-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-912"><a href="#cb21-912" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Precision-Recall curve</span></span>
<span id="cb21-913"><a href="#cb21-913" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_curve, average_precision_score</span>
<span id="cb21-914"><a href="#cb21-914" aria-hidden="true" tabindex="-1"></a>precision, recall, thresholds_pr <span class="op">=</span> precision_recall_curve(y_test, y_pred_proba_positive)</span>
<span id="cb21-915"><a href="#cb21-915" aria-hidden="true" tabindex="-1"></a>avg_precision <span class="op">=</span> average_precision_score(y_test, y_pred_proba_positive)</span>
<span id="cb21-916"><a href="#cb21-916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-917"><a href="#cb21-917" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb21-918"><a href="#cb21-918" aria-hidden="true" tabindex="-1"></a>plt.plot(recall, precision, color<span class="op">=</span><span class="st">'blue'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="ss">f'PR curve (AP = </span><span class="sc">{</span>avg_precision<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb21-919"><a href="#cb21-919" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Recall'</span>)</span>
<span id="cb21-920"><a href="#cb21-920" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Precision'</span>)</span>
<span id="cb21-921"><a href="#cb21-921" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Precision-Recall Curve'</span>)</span>
<span id="cb21-922"><a href="#cb21-922" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"upper right"</span>)</span>
<span id="cb21-923"><a href="#cb21-923" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-924"><a href="#cb21-924" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-925"><a href="#cb21-925" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-926"><a href="#cb21-926" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare with the best threshold ROC point</span></span>
<span id="cb21-927"><a href="#cb21-927" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb21-928"><a href="#cb21-928" aria-hidden="true" tabindex="-1"></a>plt.step(recall, precision, color<span class="op">=</span><span class="st">'blue'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>, where<span class="op">=</span><span class="st">'post'</span>)</span>
<span id="cb21-929"><a href="#cb21-929" aria-hidden="true" tabindex="-1"></a>plt.fill_between(recall, precision, alpha<span class="op">=</span><span class="fl">0.2</span>, color<span class="op">=</span><span class="st">'blue'</span>, step<span class="op">=</span><span class="st">'post'</span>)</span>
<span id="cb21-930"><a href="#cb21-930" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Recall'</span>)</span>
<span id="cb21-931"><a href="#cb21-931" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Precision'</span>)</span>
<span id="cb21-932"><a href="#cb21-932" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="fl">0.0</span>, <span class="fl">1.05</span>])</span>
<span id="cb21-933"><a href="#cb21-933" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="fl">0.0</span>, <span class="fl">1.0</span>])</span>
<span id="cb21-934"><a href="#cb21-934" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Precision-Recall Curve: AP=</span><span class="sc">{0:0.2f}</span><span class="st">'</span>.<span class="bu">format</span>(avg_precision))</span>
<span id="cb21-935"><a href="#cb21-935" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-936"><a href="#cb21-936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-937"><a href="#cb21-937" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot F1 Score vs Threshold</span></span>
<span id="cb21-938"><a href="#cb21-938" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb21-939"><a href="#cb21-939" aria-hidden="true" tabindex="-1"></a>plt.plot(thresholds, f1_scores, <span class="st">'b-'</span>, label<span class="op">=</span><span class="st">'F1 Score'</span>)</span>
<span id="cb21-940"><a href="#cb21-940" aria-hidden="true" tabindex="-1"></a>plt.plot([best_threshold, best_threshold], [<span class="dv">0</span>, best_f1], <span class="st">'r--'</span>, label<span class="op">=</span><span class="ss">f'Best Threshold = </span><span class="sc">{</span>best_threshold<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb21-941"><a href="#cb21-941" aria-hidden="true" tabindex="-1"></a>plt.plot(best_threshold, best_f1, <span class="st">'ro'</span>, markersize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb21-942"><a href="#cb21-942" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'F1 Score vs. Threshold'</span>)</span>
<span id="cb21-943"><a href="#cb21-943" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Threshold'</span>)</span>
<span id="cb21-944"><a href="#cb21-944" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'F1 Score'</span>)</span>
<span id="cb21-945"><a href="#cb21-945" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-946"><a href="#cb21-946" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb21-947"><a href="#cb21-947" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-948"><a href="#cb21-948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-949"><a href="#cb21-949" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparing model performance before and after optimization</span></span>
<span id="cb21-950"><a href="#cb21-950" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Model performance comparison:"</span>)</span>
<span id="cb21-951"><a href="#cb21-951" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimal threshold: </span><span class="sc">{</span>best_threshold<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb21-952"><a href="#cb21-952" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Original model test accuracy: </span><span class="sc">{</span>test_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-953"><a href="#cb21-953" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimized model test accuracy (with best threshold): </span><span class="sc">{</span>accuracy_score(y_test, y_pred)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-954"><a href="#cb21-954" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimized model F1 score: </span><span class="sc">{</span>f1_score(y_test, y_pred)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-955"><a href="#cb21-955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-956"><a href="#cb21-956" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>